#!/usr/bin/env python3
"""
æµ‹è¯•EPAMæ¥å£ä¿®å¤ - éªŒè¯gtå‚æ•°æ­£ç¡®ä¼ é€’ç»™backboneè€Œä¸æ˜¯head
"""
import torch
from mmaction.models.backbones import EPAMBackbone
from mmaction.models.heads import RGBPoseHead
from mmaction.models.recognizers import EPAMRecognizer

print("=" * 80)
print("æµ‹è¯•EPAMæ¥å£ä¿®å¤")
print("=" * 80)

# æµ‹è¯•1: éªŒè¯EPAMBackboneæ¥å—gtå‚æ•°
print("\n[æµ‹è¯•1] EPAMBackboneæ¥å—gtå’Œgt_coarseå‚æ•°...")
try:
    backbone = EPAMBackbone(
        num_classes=60,
        attention_type='CBAM_spatial_efficient_temporal',
        return_both_streams=True
    )
    backbone.init_weights()
    
    rgb = torch.randn(2, 3, 16, 224, 224)
    pose = torch.randn(2, 17, 48, 56, 56)
    gt = torch.randint(0, 60, (2,))
    gt_coarse = torch.randint(0, 8, (2,))
    
    with torch.no_grad():
        rgb_feat, pose_feat = backbone(rgb, pose, gt, gt_coarse)
    
    print(f"âœ… Backboneæ¥å—gtå‚æ•°")
    print(f"   è¾“å‡º: RGB {rgb_feat.shape}, Pose {pose_feat.shape}")
except Exception as e:
    print(f"âŒ å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# æµ‹è¯•2: éªŒè¯RGBPoseHead.forward()ä¸æ¥å—gtå‚æ•°
print("\n[æµ‹è¯•2] RGBPoseHead.forward()ä¸æ¥å—é¢å¤–å‚æ•°...")
try:
    head = RGBPoseHead(
        num_classes=60,
        num_coarse_classes=8,
        in_channels=[432, 216],
        loss_components=['rgb', 'pose'],
        loss_weights=[1.0, 1.2, 0.5, 0.9],
        average_clips='prob'
    )
    
    rgb_feat = torch.randn(2, 432, 16, 7, 7)
    pose_feat = torch.randn(2, 216, 48, 7, 7)
    feats = [rgb_feat, pose_feat]
    
    with torch.no_grad():
        # RGBPoseHead.forward()åªæ¥å—featså‚æ•°
        cls_scores = head(feats)
    
    print(f"âœ… Headæ­£ç¡®å·¥ä½œï¼ˆä¸éœ€è¦gtå‚æ•°ï¼‰")
    print(f"   è¾“å‡º: {list(cls_scores.keys())}")
except Exception as e:
    print(f"âŒ å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# æµ‹è¯•3: éªŒè¯å®Œæ•´æµç¨‹
print("\n[æµ‹è¯•3] å®Œæ•´EPAMRecognizeræµç¨‹...")
try:
    from mmengine.structures import LabelData
    from mmaction.structures import ActionDataSample
    
    # æ„å»ºrecognizer
    recognizer = EPAMRecognizer(
        backbone=dict(
            type='EPAMBackbone',
            num_classes=60,
            attention_type='CBAM_spatial_efficient_temporal',
            return_both_streams=True
        ),
        cls_head=dict(
            type='RGBPoseHead',
            num_classes=60,
            num_coarse_classes=8,
            in_channels=[432, 216],
            loss_components=['rgb', 'pose'],
            loss_weights=[1.0, 1.2, 0.5, 0.9],
            average_clips='prob'
        ),
        data_preprocessor=dict(
            type='MultiModalDataPreprocessor',
            preprocessors=dict(
                imgs=dict(
                    type='ActionDataPreprocessor',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    format_shape='NCTHW'),
                heatmap_imgs=dict(type='ActionDataPreprocessor')
            )
        )
    )
    
    recognizer.eval()
    
    # å‡†å¤‡è¾“å…¥
    inputs = {
        'imgs': torch.randn(2, 1, 3, 16, 224, 224),
        'heatmap_imgs': torch.randn(2, 1, 17, 48, 56, 56)
    }
    
    # å‡†å¤‡data_samplesï¼ˆç”¨äºlossè®¡ç®—ï¼‰
    data_samples = []
    for i in range(2):
        data_sample = ActionDataSample()
        gt_labels = LabelData()
        gt_labels.item = [torch.tensor(i % 60)]
        data_sample.gt_labels = gt_labels
        data_samples.append(data_sample)
    
    # æµ‹è¯•lossæ¨¡å¼ï¼ˆè¿™æ˜¯æŠ¥é”™çš„åœ°æ–¹ï¼‰
    recognizer.train()
    with torch.no_grad():
        loss = recognizer(inputs, data_samples=data_samples, mode='loss')
    
    print(f"âœ… Lossè®¡ç®—æˆåŠŸ")
    print(f"   æŸå¤±é”®: {list(loss.keys())}")
    
    # æµ‹è¯•predictæ¨¡å¼
    recognizer.eval()
    with torch.no_grad():
        predictions = recognizer(inputs, data_samples=data_samples, mode='predict')
    
    print(f"âœ… PredictæˆåŠŸ")
    print(f"   é¢„æµ‹æ•°é‡: {len(predictions)}")
    
except Exception as e:
    print(f"âŒ å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print("\n" + "=" * 80)
print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä¿®å¤æˆåŠŸï¼")
print("=" * 80)
print("\nç°åœ¨å¯ä»¥é‡æ–°è¿è¡Œè®­ç»ƒå‘½ä»¤:")
print("CUDA_VISIBLE_DEVICES=1,2 bash tools/dist_train.sh \\")
print("    configs/skeleton/posec3d/rgbpose_conv3d/epam_ntu60_baseline.py \\")
print("    2 \\")
print("    --work-dir work_dirs/epam_ntu60_baseline_2gpu")
print("=" * 80)

