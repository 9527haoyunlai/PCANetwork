# æ¨¡å‹åœ¨ntud60æ•°æ®é›†ä¸Šçš„é€‚ç”¨æ€§
_Exported on 11/21/2025 at 02:26:09 GMT+8 from Cursor (2.0.77)_

---

**User**

æˆ‘å¯¹æ¨¡å‹çš„ç½‘ç»œç»“æ„å¤§è‡´äº†è§£äº†ï¼Œç°åœ¨æˆ‘æƒ³è¯·é—®ä¸€ä¸‹ï¼Œè¿™ä¸ªç½‘ç»œæ¨¡å‹å¦‚æœè·‘ntud60çš„æ•°æ®é›†ï¼Œå¯ä»¥åšåˆ°å—ï¼Ÿå¦‚æœå¯ä»¥éœ€è¦åšå“ªäº›å‡†å¤‡å’Œè°ƒæ•´å‘¢ï¼Œå› ä¸ºntuæ•°æ®é›†æ˜¯ä¸å­˜åœ¨ç²—åˆ†ç±»çš„ï¼ŒåŒ…æ‹¬è¿™ä¸ªéª¨æ¶åºåˆ—ï¼Œå› ä¸ºntuçš„éª¨æ¶ç‚¹æ˜¯17æˆ–è€…25ä¸ªï¼Œè€Œè¿™ä¸ªè®ºæ–‡ä¸­ä½¿ç”¨çš„ma52æ•°æ®é›†çš„éª¨æ¶éƒ¨åˆ†æ•°æ®åˆ™æ˜¯28ä¸ªéª¨éª¼ç‚¹å‘¢ï¼Œå› æ­¤å¦‚æœè¯¥æ¨¡å‹è·‘ntu60æ•°æ®é›†çš„è¯æ•´ä½“å˜åŒ–å¤§ä¸å¤§ï¼Ÿ@mmaction2 @PACNæ¨¡å‹è§£é‡Š.md 

---

**Cursor**

å¥½é—®é¢˜ï¼è®©æˆ‘å¸®ä½ åˆ†æPCANæ¨¡å‹å¦‚ä½•é€‚é…NTU-RGB+D 60æ•°æ®é›†ã€‚é¦–å…ˆè®©æˆ‘æŸ¥çœ‹ä¸€ä¸‹ç›¸å…³é…ç½®å’Œä»£ç ç»“æ„ã€‚

éå¸¸å¥½çš„é—®é¢˜ï¼è®©æˆ‘è¯¦ç»†åˆ†æPCANæ¨¡å‹åœ¨NTU-RGB+D 60æ•°æ®é›†ä¸Šçš„é€‚é…æ–¹æ¡ˆã€‚

## ğŸ“Š å…³é”®å·®å¼‚å¯¹æ¯”

| ç»´åº¦ | MA-52ï¼ˆå½“å‰ï¼‰ | NTU-RGB+D 60 | å·®å¼‚ç¨‹åº¦ |
|------|--------------|--------------|---------|
| **ç±»åˆ«æ•°** | 52ç±»ï¼ˆactionï¼‰+ 7ç±»ï¼ˆbodyï¼‰ | 60ç±»ï¼ˆæ— å±‚æ¬¡ï¼‰ | âš ï¸ ä¸­ç­‰ |
| **éª¨æ¶ç‚¹æ•°** | 28ç‚¹ï¼ˆOpenPoseï¼‰ | 25ç‚¹ï¼ˆKinect v2ï¼‰ | âš ï¸ ä¸­ç­‰ |
| **å±‚æ¬¡æ ‡ç­¾** | âœ“ æœ‰ç²—ç²’åº¦æ ‡ç­¾ | âŒ æ— å±‚æ¬¡ç»“æ„ | âŒ é‡å¤§ |
| **æ•°æ®è§„æ¨¡** | ~24Kæ ·æœ¬ | ~40Kæ ·æœ¬ï¼ˆXSubï¼‰ | âœ“ æ— å½±å“ |

## âœ… å¯è¡Œæ€§åˆ†æ

**ç­”æ¡ˆï¼šå¯ä»¥ï¼Œä½†éœ€è¦é€‚åº¦ä¿®æ”¹**

### ä¿®æ”¹ç¨‹åº¦ä¼°è®¡

```
æ•´ä½“å˜åŒ–ï¼šâ­â­â­â˜†â˜† (ä¸­ç­‰)

å¿…é¡»ä¿®æ”¹çš„éƒ¨åˆ†ï¼š
  ğŸ”´ éª¨æ¶ç‚¹æ•°ï¼šin_channels (28â†’25)
  ğŸ”´ ç±»åˆ«æ•°ï¼šnum_classes (52â†’60)
  ğŸ”´ ç²—åˆ†ç±»å¤„ç†ï¼šç§»é™¤æˆ–è™šæ‹ŸåŒ–
  ğŸ”´ TreeLossï¼šå»æ‰æˆ–ä¿®æ”¹

å¯é€‰ä¿®æ”¹çš„éƒ¨åˆ†ï¼š
  ğŸŸ¡ åŸå‹æ•°é‡ï¼šè‡ªåŠ¨é€‚é…60ç±»
  ğŸŸ¢ Backboneï¼šæ— éœ€ä¿®æ”¹
  ğŸŸ¢ åŒæµæ¶æ„ï¼šä¿æŒä¸å˜
```

## ğŸ”§ è¯¦ç»†é€‚é…æ–¹æ¡ˆ

### æ–¹æ¡ˆAï¼šå®Œå…¨å»é™¤PCANç‰¹æ€§ï¼ˆæœ€ç®€å•ï¼Œä¸æ¨èï¼‰

è¿™æ ·å°±é€€åŒ–æˆåŸºç¡€çš„RGBPoseConv3Dï¼Œå¤±å»äº†PCANçš„ä¼˜åŠ¿ã€‚

### æ–¹æ¡ˆBï¼šä¿ç•™PCANï¼Œè™šæ‹ŸåŒ–ç²—åˆ†ç±»ï¼ˆæ¨èï¼‰â­

ä¸ºNTU-60åˆ›å»ºè™šæ‹Ÿçš„ç²—åˆ†ç±»æ ‡ç­¾ã€‚

### æ–¹æ¡ˆCï¼šè‡ªå®šä¹‰NTUçš„ç²—åˆ†ç±»ï¼ˆæœ€ä¼˜ï¼Œä½†å·¥ä½œé‡å¤§ï¼‰

æ ¹æ®NTU-60çš„åŠ¨ä½œè¯­ä¹‰å®šä¹‰å±‚æ¬¡ç»“æ„ã€‚

---

## ğŸ“ æ–¹æ¡ˆBå®æ–½æŒ‡å—ï¼ˆæ¨èï¼‰

### ç¬¬1æ­¥ï¼šä¿®æ”¹é…ç½®æ–‡ä»¶

åˆ›å»º `configs/skeleton/posec3d/rgbpose_conv3d/rgbpose_conv3d_ntu60.py`ï¼š

```python
_base_ = '../../../_base_/default_runtime.py'

# ========== ä¿®æ”¹1: Backboneé…ç½® ==========
backbone_cfg = dict(
    type='RGBPoseConv3D',
    speed_ratio=4,
    channel_ratio=4,
    rgb_pathway=dict(
        num_stages=4,
        lateral=True,
        lateral_infl=1,
        lateral_activate=[0, 0, 1, 1],
        fusion_kernel=7,
        base_channels=64,
        conv1_kernel=(1, 7, 7),
        inflate=(0, 0, 1, 1),
        with_pool2=False),
    pose_pathway=dict(
        num_stages=3,
        stage_blocks=(4, 6, 3),
        lateral=True,
        lateral_inv=True,
        lateral_infl=16,
        lateral_activate=(0, 1, 1),
        fusion_kernel=7,
        in_channels=25,  # â† æ”¹ä¸º25 (NTUéª¨æ¶ç‚¹æ•°)
        base_channels=32,
        out_indices=(2, ),
        conv1_kernel=(1, 7, 7),
        conv1_stride_s=1,
        conv1_stride_t=1,
        pool1_stride_s=1,
        pool1_stride_t=1,
        inflate=(0, 1, 1),
        spatial_strides=(2, 2, 2),
        temporal_strides=(1, 1, 1),
        dilations=(1, 1, 1),
        with_pool2=False))

# ========== ä¿®æ”¹2: Headé…ç½® ==========
head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,  # â† æ”¹ä¸º60ç±»
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose'],
    loss_weights=[1., 1.],
    average_clips='prob')

data_preprocessor = dict(
    type='MultiModalDataPreprocessor',
    preprocessors=dict(
        imgs=dict(
            type='ActionDataPreprocessor',
            mean=[123.675, 116.28, 103.53],
            std=[58.395, 57.12, 57.375],
            format_shape='NCTHW'),
        heatmap_imgs=dict(type='ActionDataPreprocessor')))

model = dict(
    type='MMRecognizer3D',
    backbone=backbone_cfg,
    cls_head=head_cfg,
    data_preprocessor=data_preprocessor)

# ========== ä¿®æ”¹3: æ•°æ®é…ç½® ==========
dataset_type = 'PoseDataset'
data_root = 'data/nturgbd_videos/'
ann_file = 'data/skeleton/ntu60_3d.pkl'  # æˆ– ntu60_2d.pkl

# NTU-60çš„éª¨æ¶ç‚¹å®šä¹‰ï¼ˆ25ä¸ªå…³èŠ‚ç‚¹ï¼‰
left_kp = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23]
right_kp = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]

train_pipeline = [
    dict(
        type='MMUniformSampleFrames',
        clip_len=dict(RGB=8, Pose=32),
        num_clips=1),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(type='RandomResizedCrop', area_range=(0.56, 1.0)),
    dict(type='Resize', scale=(224, 224), keep_ratio=False),
    dict(type='Flip', flip_ratio=0.5, left_kp=left_kp, right_kp=right_kp),
    dict(
        type='GeneratePoseTarget',
        sigma=0.7,
        use_score=True,
        with_kp=True,
        with_limb=False,
        scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

# ... å…¶ä»–pipelineå’Œdataloaderé…ç½®ç±»ä¼¼ ...

train_cfg = dict(
    type='EpochBasedTrainLoop', max_epochs=30, val_begin=3, val_interval=1)

optim_wrapper = dict(
    optimizer=dict(type='SGD', lr=0.0075, momentum=0.9, weight_decay=0.0001),
    clip_grad=dict(max_norm=40, norm_type=2))

param_scheduler = [
    dict(
        type='MultiStepLR',
        begin=0,
        end=30,
        by_epoch=True,
        milestones=[10, 20],
        gamma=0.1)
]
```

### ç¬¬2æ­¥ï¼šä¿®æ”¹Headä»£ç ä»¥æ”¯æŒæ— ç²—åˆ†ç±»æ¨¡å¼

éœ€è¦ä¿®æ”¹ `mmaction/models/heads/rgbpose_head.py`ï¼š

```python
# ========== ä¿®æ”¹1: __init__æ–¹æ³•ï¼ˆçº¦ç¬¬520è¡Œï¼‰==========
def __init__(self,
             num_classes: int,
             in_channels: Tuple[int],
             loss_cls: Dict = dict(type='CrossEntropyLoss'),
             loss_components: List[str] = ['rgb', 'pose'],
             loss_weights: Union[float, Tuple[float]] = 1.,
             dropout: float = 0.5,
             init_std: float = 0.01,
             use_coarse: bool = True,  # â† æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨ç²—åˆ†ç±»
             num_coarse_classes: int = 7,  # â† æ–°å¢ï¼šç²—åˆ†ç±»æ•°é‡
             **kwargs) -> None:
    
    super().__init__(num_classes, in_channels, loss_cls, **kwargs)
    
    # ... åŸæœ‰ä»£ç  ...
    
    self.fc_rgb = nn.Linear(self.in_channels[0], num_classes)
    self.fc_pose = nn.Linear(self.in_channels[1], num_classes)
    
    # æ ¹æ®use_coarseå†³å®šæ˜¯å¦åˆ›å»ºç²—åˆ†ç±»ç›¸å…³æ¨¡å—
    self.use_coarse = use_coarse
    if self.use_coarse:
        self.fc_rgb_coarse = nn.Linear(self.in_channels[0], num_coarse_classes)
        self.fc_pose_coarse = nn.Linear(self.in_channels[1], num_coarse_classes)
        
        self.fr_coarse_rgb = ST_RenovateNet(
            2048, 8, n_class=num_coarse_classes, h_channel=128)
        self.fr_coarse_pose = ST_RenovateNet(
            512, 32, n_class=num_coarse_classes, h_channel=128)
        
        self.tree_loss_rgb = TreeLoss()
        self.tree_loss_pose = TreeLoss()
    
    # ç»†ç²’åº¦RenovateNetï¼ˆæ°¸è¿œéœ€è¦ï¼‰
    self.fr_rgb = ST_RenovateNet_Fine(
        2048, n_class=num_classes, version='V0', use_p_map=True)
    self.fr_pose = ST_RenovateNet_Fine(
        512, n_class=num_classes, version='V0', use_p_map=True)


# ========== ä¿®æ”¹2: forwardæ–¹æ³•ï¼ˆçº¦ç¬¬576è¡Œï¼‰==========
def forward(self, x: List[torch.Tensor]) -> Dict:
    x_rgb, x_pose = self.avg_pool(x[0]), self.avg_pool(x[1])
    x_rgb = x_rgb.view(x_rgb.size(0), -1)
    x_pose = x_pose.view(x_pose.size(0), -1)
    
    x_rgb = self.dropout_rgb(x_rgb)
    x_pose = self.dropout_pose(x_pose)
    
    cls_scores = dict()
    logits_rgb = self.fc_rgb(x_rgb)
    logits_pose = self.fc_pose(x_pose)
    
    if self.training:
        cls_scores['rgb'] = logits_rgb
        cls_scores['pose'] = logits_pose
        
        x_rgb1, x_pose1 = x[2], x[3]
        gt = x[4]
        
        x_rgb1 = x_rgb1.mean(dim=2)
        x_pose1 = x_pose1.mean(dim=2)
        
        if self.use_coarse:
            # æœ‰ç²—åˆ†ç±»çš„æƒ…å†µï¼ˆMA-52ï¼‰
            gt_coarse = x[5]
            logits_coarse_rgb = self.fc_rgb_coarse(x_rgb)
            logits_coarse_pose = self.fc_pose_coarse(x_pose)
            
            cls_scores['rgb_coarse'] = logits_coarse_rgb
            cls_scores['pose_coarse'] = logits_coarse_pose
            
            # ç²—åˆ†ç±»çš„FR loss
            coarse_fr_loss_rgb = self.fr_coarse_rgb(
                x_rgb1, gt_coarse.detach(), logits_coarse_rgb)
            coarse_fr_loss_pose = self.fr_coarse_pose(
                x_pose1, gt_coarse.detach(), logits_coarse_pose)
            
            # ç»†åˆ†ç±»çš„FR lossï¼ˆéœ€è¦ç²—åˆ†ç±»æ ‡ç­¾ï¼‰
            fr_loss_rgb = self.fr_rgb(
                x_rgb1, gt_coarse.detach(), gt.detach(), 
                logits_coarse_rgb, logits_rgb)
            fr_loss_pose = self.fr_pose(
                x_pose1, gt_coarse.detach(), gt.detach(),
                logits_coarse_pose, logits_pose)
            
            # Tree loss
            hierarchy_loss_rgb = self.tree_loss_rgb(
                logits_coarse_rgb, logits_rgb, gt_coarse.detach(), gt.detach())
            hierarchy_loss_pose = self.tree_loss_pose(
                logits_coarse_pose, logits_pose, gt_coarse.detach(), gt.detach())
            
            cls_scores['fr_loss_rgb_coarse'] = coarse_fr_loss_rgb
            cls_scores['fr_loss_pose_coarse'] = coarse_fr_loss_pose
            cls_scores['hierarchy_loss_rgb'] = hierarchy_loss_rgb
            cls_scores['hierarchy_loss_pose'] = hierarchy_loss_pose
        else:
            # æ— ç²—åˆ†ç±»çš„æƒ…å†µï¼ˆNTU-60ï¼‰
            # åˆ›å»ºè™šæ‹Ÿçš„ç²—åˆ†ç±»æ ‡ç­¾ï¼ˆå…¨éƒ¨æ˜ å°„åˆ°ç±»åˆ«0ï¼‰
            gt_coarse = torch.zeros_like(gt)
            logits_coarse_rgb = torch.zeros(x_rgb.size(0), 1).to(x_rgb.device)
            logits_coarse_pose = torch.zeros(x_pose.size(0), 1).to(x_pose.device)
            
            # ç®€åŒ–çš„FR lossï¼ˆåªç”¨ç»†åˆ†ç±»ï¼‰
            fr_loss_rgb = self.fr_rgb.forward_simple(
                x_rgb1, gt.detach(), logits_rgb)  # éœ€è¦æ·»åŠ simpleç‰ˆæœ¬
            fr_loss_pose = self.fr_pose.forward_simple(
                x_pose1, gt.detach(), logits_pose)
        
        cls_scores['fr_loss_rgb'] = fr_loss_rgb
        cls_scores['fr_loss_pose'] = fr_loss_pose
    
    if not self.training:
        # æµ‹è¯•é˜¶æ®µçš„åŸå‹ä¿®æ­£ï¼ˆæ— éœ€ç²—åˆ†ç±»ï¼‰
        with torch.no_grad():
            rgb_proto = self.fr_rgb.spatio_cl_net.avg_f.permute(1, 0).cuda()
            pose_proto = self.fr_pose.spatio_cl_net.avg_f.permute(1, 0).cuda()
            
            logits_rgb_proto = self.fr_rgb.spatio_cl_net.cl_fc(x_rgb)
            logits_pose_proto = self.fr_pose.spatio_cl_net.cl_fc(x_pose)
            
            cos_sim_rgb = F.cosine_similarity(
                logits_rgb_proto.unsqueeze(1), rgb_proto.unsqueeze(0), dim=2)
            cos_sim_pose = F.cosine_similarity(
                logits_pose_proto.unsqueeze(1), pose_proto.unsqueeze(0), dim=2)
            
            cls_scores['rgb'] = logits_rgb + cos_sim_rgb * 5
            cls_scores['pose'] = logits_pose + cos_sim_pose * 1
    
    return cls_scores
```

### ç¬¬3æ­¥ï¼šä¿®æ”¹RenovateNetæ”¯æŒæ— ç²—åˆ†ç±»æ¨¡å¼

åœ¨ `rgbpose_head.py` çš„ `RenovateNet_Fine` ç±»ä¸­æ·»åŠ ç®€åŒ–ç‰ˆforwardï¼š

```python
def forward_simple(self, feature, lbl, logit):
    """
    æ— ç²—åˆ†ç±»çš„ç®€åŒ–ç‰ˆæœ¬
    åªä½¿ç”¨ç»†åˆ†ç±»æ ‡ç­¾è¿›è¡ŒåŸå‹å­¦ä¹ 
    """
    # ç‰¹å¾æŠ•å½±
    feature = self.cl_fc(feature)
    feature = F.normalize(feature.permute(0, 2, 3, 1), dim=3)
    feature = feature.reshape(-1, self.h_channel)
    
    # ä½¿ç”¨argmaxä½œä¸ºè™šæ‹Ÿçš„ç²—åˆ†ç±»é¢„æµ‹
    lbl_one_coarse = F.one_hot(torch.zeros_like(lbl), 1).to(torch.float32)
    pred_one_coarse = F.one_hot(torch.zeros_like(lbl), 1).to(torch.float32)
    
    # ç»†åˆ†ç±»çš„one-hot
    lbl_one = F.one_hot(lbl.to(torch.int64), self.n_class).to(torch.float32)
    pred_one = F.one_hot(logit.argmax(1), self.n_class).to(torch.float32)
    
    # è®¡ç®—TP/FN/FPï¼ˆåªåŸºäºç»†åˆ†ç±»ï¼‰
    mask, fn, fp = self.get_mask_fn_fp(
        lbl_one_coarse, lbl_one, 
        pred_one_coarse, pred_one,
        torch.zeros_like(logit), logit)
    
    # å…¶ä½™è®¡ç®—ä¿æŒä¸å˜
    f_mem, f_fn_1, f_fn_2, f_fn_3, f_fp = self.local_avg_tp_fn_fp(
        feature, mask, fn[0], fn[1], fn[2], fp)
    
    score_cl_fn, score_cl_fp = self.get_score(
        feature, f_mem, f_fn_1, f_fn_2, f_fn_3, f_fp,
        lbl_one, pred_one, lbl, use_p_map=self.use_p_map)
    
    return (self.loss(score_cl_fn, lbl) + self.loss(score_cl_fp, lbl)).mean()
```

### ç¬¬4æ­¥ï¼šä¿®æ”¹MMRecognizer3Då¤„ç†è™šæ‹Ÿç²—åˆ†ç±»

åœ¨ `mmaction/models/recognizers/recognizer3d_mm.py` ä¸­ï¼ˆçº¦ç¬¬56-65è¡Œï¼‰ï¼š

```python
def extract_feat(self, inputs: torch.Tensor, stage: str = 'neck',
                 data_samples: OptSampleList = None,
                 test_mode: bool = False, **kwargs):
    # ... existing code ...
    
    if self.with_neck:
        if stage == 'backbone':
            return x
        gts = [data.gt_labels.item for data in data_samples]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç²—åˆ†ç±»æ ‡ç­¾
        if hasattr(self.cls_head, 'use_coarse') and not self.cls_head.use_coarse:
            # NTU-60æ¨¡å¼ï¼šä½¿ç”¨è™šæ‹Ÿç²—åˆ†ç±»
            gts_coarse = torch.zeros_like(torch.tensor(gts))
        else:
            # MA-52æ¨¡å¼ï¼šä»ç»†åˆ†ç±»æ˜ å°„åˆ°ç²—åˆ†ç±»
            temp = torch.tensor(gts).to(torch.int32)
            gts_coarse = [fine2coarse(i) for i in temp]
        
        inputs['gt'] = gts
        inputs['gt_coarse'] = gts_coarse
        x = self.backbone(**inputs)
        # ... rest of code ...
```

---

## ğŸ¯ æ–¹æ¡ˆCï¼šè‡ªå®šä¹‰NTU-60çš„ç²—åˆ†ç±»ï¼ˆæœ€ä½³æ•ˆæœï¼‰

### å®šä¹‰NTU-60çš„å±‚æ¬¡ç»“æ„

æ ¹æ®NTU-60çš„åŠ¨ä½œè¯­ä¹‰ï¼Œå¯ä»¥å®šä¹‰ä¸º8ä¸ªç²—ç±»ï¼š

```python
# åœ¨rgbpose_head.pyå¼€å¤´æ·»åŠ 
def action2body_ntu60(x):
    """NTU-60çš„å±‚æ¬¡æ˜ å°„"""
    if 0 <= x <= 11:
        return 0  # Daily Actions (drink, eat, brush teeth...)
    elif 12 <= x <= 23:
        return 1  # Interaction (handshake, hug, punch...)
    elif 24 <= x <= 35:
        return 2  # Health (sneeze, headache, chest pain...)
    elif 36 <= x <= 47:
        return 3  # Gesture (point, thumb up, ok sign...)
    elif 48 <= x <= 50:
        return 4  # Hand movements (typing, writing...)
    elif 51 <= x <= 55:
        return 5  # Body movements (walk, sit, stand...)
    elif 56 <= x <= 58:
        return 6  # Fall related
    else:
        return 7  # Other
```

ç„¶åä¿®æ”¹é…ç½®ï¼š

```python
head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,
    num_coarse_classes=8,  # NTUè‡ªå®šä¹‰8ç±»
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose', 'rgb_coarse', 'pose_coarse'],
    loss_weights=[1., 1., 0.5, 0.5],
    average_clips='prob',
    use_coarse=True,
    action2body_func='action2body_ntu60')  # æŒ‡å®šä½¿ç”¨NTUçš„æ˜ å°„
```

---

## ğŸ“Š æ€§èƒ½é¢„æœŸ

### åŸºäºç°æœ‰ç»“æœæ¨æµ‹

```
åŸºç¡€RGBPoseConv3D (NTU-60 XSub):
  â€¢ Top-1: 96.2-96.4% (READMEä¸­æŠ¥å‘Š)

åŠ å…¥PCANåé¢„æœŸæå‡:
  â€¢ åŸå‹å­¦ä¹ : +1-2%
  â€¢ FN/FPæ ¡å‡†: +0.5-1%
  â€¢ é¢„æœŸTop-1: 97.5-98.0%
  
âš ï¸ æ³¨æ„ï¼š
  â€¢ æ²¡æœ‰TreeLossï¼ˆå› ä¸ºè‡ªå®šä¹‰ç²—åˆ†ç±»ä¸å¤Ÿç²¾å‡†ï¼‰
  â€¢ æå‡å¹…åº¦å¯èƒ½ä¸å¦‚MA-52ï¼ˆNTU-60ç±»åˆ«è¾ƒå°‘ï¼Œæ··æ·†åº¦ä½ï¼‰
```

---

## ğŸ”„ å®Œæ•´çš„ä¿®æ”¹æ¸…å•

### å¿…é¡»ä¿®æ”¹çš„æ–‡ä»¶

| æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ | éš¾åº¦ |
|------|---------|------|
| `rgbpose_conv3d.py` | in_channels: 28â†’25, num_classes: 52â†’60 | â­ ç®€å• |
| `rgbpose_head.py` | æ·»åŠ use_coarseå‚æ•°æ”¯æŒ | â­â­ ä¸­ç­‰ |
| `recognizer3d_mm.py` | è™šæ‹Ÿç²—åˆ†ç±»æ ‡ç­¾ç”Ÿæˆ | â­â­ ä¸­ç­‰ |
| `action2bodyå‡½æ•°` | åˆ›å»ºNTUç‰ˆæœ¬ï¼ˆå¯é€‰ï¼‰ | â­â­â­ è¾ƒéš¾ |

### æ•°æ®å‡†å¤‡

```bash
# 1. å‡†å¤‡NTU-60æ•°æ®é›†
# ä¸‹è½½RGBè§†é¢‘å’Œéª¨æ¶æ ‡æ³¨
cd data
mkdir -p skeleton nturgbd_videos

# 2. å‡†å¤‡éª¨æ¶æ•°æ®ï¼ˆpklæ ¼å¼ï¼‰
# å‚è€ƒï¼šhttps://github.com/open-mmlab/mmaction2/blob/main/tools/data/skeleton/README.md

# 3. éª¨æ¶æ•°æ®æ ¼å¼ï¼ˆ25ä¸ªå…³é”®ç‚¹ï¼‰
# NTUéª¨æ¶ç‚¹ç´¢å¼•ï¼š0-24
# éœ€è¦è½¬æ¢ä¸ºä¸MA-52ç›¸åŒçš„æ•°æ®æ ¼å¼
```

---

## âš ï¸ ä¸»è¦æŒ‘æˆ˜å’Œè§£å†³æ–¹æ¡ˆ

### æŒ‘æˆ˜1ï¼šéª¨æ¶ç‚¹æ•°ä¸åŒï¼ˆ28 vs 25ï¼‰

**å½±å“**ï¼šè½»å¾®ï¼ˆåªéœ€æ”¹é…ç½®ï¼‰

```python
# MA-52: 28ä¸ªç‚¹ï¼ˆOpenPose-28ï¼‰
# NTU-60: 25ä¸ªç‚¹ï¼ˆKinect v2ï¼‰

è§£å†³ï¼š
  pose_pathway=dict(
      in_channels=25,  # ä¿®æ”¹è¿™é‡Œ
      # å…¶ä»–å‚æ•°ä¿æŒä¸å˜
  )
```

### æŒ‘æˆ˜2ï¼šæ²¡æœ‰ç²—åˆ†ç±»æ ‡ç­¾

**å½±å“**ï¼šä¸­ç­‰ï¼ˆéœ€è¦ä¿®æ”¹ä»£ç é€»è¾‘ï¼‰

**è§£å†³æ–¹æ¡ˆå¯¹æ¯”**ï¼š

| æ–¹æ¡ˆ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é¢„æœŸæ•ˆæœ |
|------|------|------|---------|
| å»é™¤PCAN | ç®€å• | å¤±å»åŸå‹å­¦ä¹ ä¼˜åŠ¿ | +0% |
| è™šæ‹Ÿç²—åˆ†ç±» | ä¿ç•™åŸå‹å­¦ä¹  | TreeLossæ— æ•ˆ | +1-1.5% |
| è‡ªå®šä¹‰ç²—åˆ†ç±» | ä¿ç•™æ‰€æœ‰PCANç‰¹æ€§ | éœ€è¦æ‰‹åŠ¨æ ‡æ³¨ | +1.5-2.5% |

### æŒ‘æˆ˜3ï¼šTreeLossä¾èµ–å›ºå®šçš„å±‚æ¬¡ç»“æ„

**å½±å“**ï¼šé‡å¤§ï¼ˆç¡¬ç¼–ç äº†52ç±»åˆ°7ç±»çš„æ˜ å°„ï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# æ–¹æ¡ˆ1ï¼šå»é™¤TreeLossï¼ˆç®€å•ï¼‰
# åœ¨forwardä¸­è·³è¿‡hierarchy_lossçš„è®¡ç®—

# æ–¹æ¡ˆ2ï¼šæ”¹å†™TreeLossä»¥æ”¯æŒè‡ªå®šä¹‰æ˜ å°„ï¼ˆæ¨èï¼‰
class TreeLoss(nn.Module):
    def __init__(self, num_actions=52, num_bodies=7, 
                 action2body_fn=None):
        super().__init__()
        self.num_actions = num_actions
        self.num_bodies = num_bodies
        self.action2body_fn = action2body_fn or action2body
        self.stateSpace = self.generateStateSpace().cuda()
    
    def generateStateSpace(self):
        stat_list = np.eye(self.num_bodies + self.num_actions)
        for i in range(self.num_bodies, 
                      self.num_bodies + self.num_actions):
            action_id = i - self.num_bodies
            coarse_id = self.action2body_fn(action_id)
            stat_list[i][coarse_id] = 1
        return torch.tensor(stat_list)
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆæœ€å°ä¿®æ”¹æ–¹æ¡ˆï¼‰

å¦‚æœä½ æƒ³å¿«é€Ÿæµ‹è¯•ï¼Œç”¨è¿™ä¸ª**æœ€ç®€é…ç½®**ï¼š

### åˆ›å»º `ntu60_simple.py`

```python
_base_ = './rgbpose_conv3d.py'

# åªä¿®æ”¹å…³é”®å‚æ•°
backbone_cfg = dict(
    type='RGBPoseConv3D',
    pose_pathway=dict(in_channels=25))  # 25ä¸ªéª¨æ¶ç‚¹

head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,  # 60ä¸ªç±»åˆ«
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose'],  # åªç”¨RGBå’ŒPoseï¼Œå»æ‰coarse
    loss_weights=[1., 1.],
    average_clips='prob')

model = dict(
    backbone=backbone_cfg,
    cls_head=head_cfg)

# æ•°æ®é›†é…ç½®
dataset_type = 'PoseDataset'
data_root = 'data/nturgbd_videos/'
ann_file_train = 'data/skeleton/ntu60_3d.pkl'
ann_file_val = 'data/skeleton/ntu60_3d.pkl'

# å·¦å³éª¨æ¶ç‚¹ï¼ˆNTU-60ï¼‰
left_kp = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23]
right_kp = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]

# ... pipelineé…ç½®ä¿æŒç±»ä¼¼ ...
```

**è¿™ä¸ªæ–¹æ¡ˆçš„é™åˆ¶**ï¼š
- âŒ æ— æ³•ä½¿ç”¨ç²—åˆ†ç±»çš„FR loss
- âŒ æ— æ³•ä½¿ç”¨TreeLoss
- âœ… ä¿ç•™ç»†åˆ†ç±»çš„åŸå‹å­¦ä¹ 
- âœ… ä¿ç•™æµ‹è¯•æ—¶çš„åŸå‹ä¿®æ­£
- âœ… ä¿ç•™FeatureInteraction

**é¢„æœŸæ•ˆæœ**ï¼šçº¦**+0.5-1%**çš„æå‡ï¼ˆç›¸æ¯”åŸºç¡€RGBPoseConv3Dï¼‰

---

## ğŸ“ˆ å®Œæ•´æ–¹æ¡ˆçš„å·¥ä½œé‡è¯„ä¼°

| ä»»åŠ¡ | é¢„è®¡å·¥ä½œé‡ | ä¼˜å…ˆçº§ |
|------|----------|--------|
| ä¿®æ”¹éª¨æ¶ç‚¹æ•° | 5åˆ†é’Ÿ | ğŸ”´ å¿…é¡» |
| ä¿®æ”¹ç±»åˆ«æ•° | 5åˆ†é’Ÿ | ğŸ”´ å¿…é¡» |
| å»é™¤ç²—åˆ†ç±»ä¾èµ– | 1-2å°æ—¶ | ğŸŸ¡ æ¨è |
| è‡ªå®šä¹‰NTUç²—åˆ†ç±» | 4-8å°æ—¶ | ğŸŸ¢ å¯é€‰ |
| æ”¹å†™TreeLoss | 2-3å°æ—¶ | ğŸŸ¢ å¯é€‰ |
| é‡æ–°è®­ç»ƒinitæƒé‡ | 8-12å°æ—¶Ã—2 | ğŸŸ¡ æ¨è |

### æ€»å·¥ä½œé‡

- **æœ€å°å¯è¡Œæ–¹æ¡ˆ**ï¼š2-3å°æ—¶ï¼ˆä¿®æ”¹é…ç½®+ç®€å•ä»£ç è°ƒæ•´ï¼‰
- **å®Œæ•´PCANæ–¹æ¡ˆ**ï¼š2-3å¤©ï¼ˆåŒ…æ‹¬è‡ªå®šä¹‰åˆ†å±‚+é‡æ–°è®­ç»ƒï¼‰

---

## ğŸ’¡ æ¨èå®æ–½è·¯çº¿

### é˜¶æ®µ1ï¼šå¿«é€ŸéªŒè¯ï¼ˆ1å¤©ï¼‰

```bash
# 1. ä¿®æ”¹é…ç½®æ–‡ä»¶
# 2. å»é™¤ç²—åˆ†ç±»ä¾èµ–ï¼ˆä»£ç å±‚é¢ç®€åŒ–å¤„ç†ï¼‰
# 3. ç›´æ¥æµ‹è¯•åŸºç¡€æ€§èƒ½

é¢„æœŸï¼šèƒ½è·‘é€šï¼Œæ€§èƒ½çº¦+0.5-1%
```

### é˜¶æ®µ2ï¼šä¼˜åŒ–æå‡ï¼ˆ2-3å¤©ï¼‰

```bash
# 1. è®¾è®¡NTU-60çš„ç²—åˆ†ç±»ä½“ç³»
# 2. å®ç°å®Œæ•´çš„PCANåŠŸèƒ½
# 3. é‡æ–°è®­ç»ƒæ‰€æœ‰æƒé‡

é¢„æœŸï¼šæœ€ä¼˜æ€§èƒ½ï¼Œ+1.5-2.5%
```

### é˜¶æ®µ3ï¼šå¯¹æ¯”å®éªŒï¼ˆ1å¤©ï¼‰

```bash
# 1. å¯¹æ¯”å»é™¤PCAN vs ç®€åŒ–PCAN vs å®Œæ•´PCAN
# 2. æ¶ˆèå®éªŒ
# 3. å‘è®ºæ–‡ :)
```

---

## ğŸ¯ æ€»ç»“

### å¯ä»¥åœ¨NTU-60ä¸Šè¿è¡Œå—ï¼Ÿ

**âœ… å¯ä»¥ï¼** ä½†éœ€è¦ä¿®æ”¹ã€‚

### æ•´ä½“å˜åŒ–å¤§å—ï¼Ÿ

**â­â­â­â˜†â˜† ä¸­ç­‰å˜åŒ–**

- **æ¶æ„å±‚é¢**ï¼šæ— éœ€æ”¹å˜ï¼ˆåŒæµ+åŸå‹å­¦ä¹ æ ¸å¿ƒæ€æƒ³ä¿ç•™ï¼‰
- **å®ç°å±‚é¢**ï¼šéœ€è¦é€‚åº¦ä¿®æ”¹ï¼ˆå»é™¤æˆ–è™šæ‹ŸåŒ–ç²—åˆ†ç±»ï¼‰
- **æ€§èƒ½é¢„æœŸ**ï¼šä»ç„¶ä¼šæœ‰æå‡ï¼ˆ+0.5-2.5%ï¼‰

### æœ€å¿«çš„æ–¹æ¡ˆ

**ä½¿ç”¨ç®€åŒ–PCAN**ï¼š
- ä¿ç•™åŸå‹å­¦ä¹ å’Œæµ‹è¯•ä¿®æ­£
- å»é™¤ç²—åˆ†ç±»å’ŒTreeLoss
- åªæ”¹é…ç½®æ–‡ä»¶å’Œå°‘é‡ä»£ç 
- 2-3å°æ—¶å®Œæˆ

### æœ€ä¼˜çš„æ–¹æ¡ˆ

**å®Œæ•´é€‚é…PCAN**ï¼š
- è‡ªå®šä¹‰NTU-60çš„ç²—åˆ†ç±»
- ä¿ç•™æ‰€æœ‰PCANç‰¹æ€§
- é‡æ–°è®­ç»ƒæƒé‡
- 2-3å¤©å®Œæˆ

éœ€è¦æˆ‘è¯¦ç»†å±•å¼€æŸä¸ªæ–¹æ¡ˆçš„å…·ä½“ä»£ç å—ï¼Ÿæˆ–è€…æœ‰å…¶ä»–ç–‘é—®ï¼Ÿ

```plaintext
æ•´ä½“å˜åŒ–ï¼šâ­â­â­â˜†â˜† (ä¸­ç­‰)

å¿…é¡»ä¿®æ”¹çš„éƒ¨åˆ†ï¼š
  ğŸ”´ éª¨æ¶ç‚¹æ•°ï¼šin_channels (28â†’25)
  ğŸ”´ ç±»åˆ«æ•°ï¼šnum_classes (52â†’60)
  ğŸ”´ ç²—åˆ†ç±»å¤„ç†ï¼šç§»é™¤æˆ–è™šæ‹ŸåŒ–
  ğŸ”´ TreeLossï¼šå»æ‰æˆ–ä¿®æ”¹

å¯é€‰ä¿®æ”¹çš„éƒ¨åˆ†ï¼š
  ğŸŸ¡ åŸå‹æ•°é‡ï¼šè‡ªåŠ¨é€‚é…60ç±»
  ğŸŸ¢ Backboneï¼šæ— éœ€ä¿®æ”¹
  ğŸŸ¢ åŒæµæ¶æ„ï¼šä¿æŒä¸å˜
```

```python
_base_ = '../../../_base_/default_runtime.py'

# ========== ä¿®æ”¹1: Backboneé…ç½® ==========
backbone_cfg = dict(
    type='RGBPoseConv3D',
    speed_ratio=4,
    channel_ratio=4,
    rgb_pathway=dict(
        num_stages=4,
        lateral=True,
        lateral_infl=1,
        lateral_activate=[0, 0, 1, 1],
        fusion_kernel=7,
        base_channels=64,
        conv1_kernel=(1, 7, 7),
        inflate=(0, 0, 1, 1),
        with_pool2=False),
    pose_pathway=dict(
        num_stages=3,
        stage_blocks=(4, 6, 3),
        lateral=True,
        lateral_inv=True,
        lateral_infl=16,
        lateral_activate=(0, 1, 1),
        fusion_kernel=7,
        in_channels=25,  # â† æ”¹ä¸º25 (NTUéª¨æ¶ç‚¹æ•°)
        base_channels=32,
        out_indices=(2, ),
        conv1_kernel=(1, 7, 7),
        conv1_stride_s=1,
        conv1_stride_t=1,
        pool1_stride_s=1,
        pool1_stride_t=1,
        inflate=(0, 1, 1),
        spatial_strides=(2, 2, 2),
        temporal_strides=(1, 1, 1),
        dilations=(1, 1, 1),
        with_pool2=False))

# ========== ä¿®æ”¹2: Headé…ç½® ==========
head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,  # â† æ”¹ä¸º60ç±»
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose'],
    loss_weights=[1., 1.],
    average_clips='prob')

data_preprocessor = dict(
    type='MultiModalDataPreprocessor',
    preprocessors=dict(
        imgs=dict(
            type='ActionDataPreprocessor',
            mean=[123.675, 116.28, 103.53],
            std=[58.395, 57.12, 57.375],
            format_shape='NCTHW'),
        heatmap_imgs=dict(type='ActionDataPreprocessor')))

model = dict(
    type='MMRecognizer3D',
    backbone=backbone_cfg,
    cls_head=head_cfg,
    data_preprocessor=data_preprocessor)

# ========== ä¿®æ”¹3: æ•°æ®é…ç½® ==========
dataset_type = 'PoseDataset'
data_root = 'data/nturgbd_videos/'
ann_file = 'data/skeleton/ntu60_3d.pkl'  # æˆ– ntu60_2d.pkl

# NTU-60çš„éª¨æ¶ç‚¹å®šä¹‰ï¼ˆ25ä¸ªå…³èŠ‚ç‚¹ï¼‰
left_kp = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23]
right_kp = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]

train_pipeline = [
    dict(
        type='MMUniformSampleFrames',
        clip_len=dict(RGB=8, Pose=32),
        num_clips=1),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(type='RandomResizedCrop', area_range=(0.56, 1.0)),
    dict(type='Resize', scale=(224, 224), keep_ratio=False),
    dict(type='Flip', flip_ratio=0.5, left_kp=left_kp, right_kp=right_kp),
    dict(
        type='GeneratePoseTarget',
        sigma=0.7,
        use_score=True,
        with_kp=True,
        with_limb=False,
        scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

# ... å…¶ä»–pipelineå’Œdataloaderé…ç½®ç±»ä¼¼ ...

train_cfg = dict(
    type='EpochBasedTrainLoop', max_epochs=30, val_begin=3, val_interval=1)

optim_wrapper = dict(
    optimizer=dict(type='SGD', lr=0.0075, momentum=0.9, weight_decay=0.0001),
    clip_grad=dict(max_norm=40, norm_type=2))

param_scheduler = [
    dict(
        type='MultiStepLR',
        begin=0,
        end=30,
        by_epoch=True,
        milestones=[10, 20],
        gamma=0.1)
]
```

```python
# ========== ä¿®æ”¹1: __init__æ–¹æ³•ï¼ˆçº¦ç¬¬520è¡Œï¼‰==========
def __init__(self,
             num_classes: int,
             in_channels: Tuple[int],
             loss_cls: Dict = dict(type='CrossEntropyLoss'),
             loss_components: List[str] = ['rgb', 'pose'],
             loss_weights: Union[float, Tuple[float]] = 1.,
             dropout: float = 0.5,
             init_std: float = 0.01,
             use_coarse: bool = True,  # â† æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨ç²—åˆ†ç±»
             num_coarse_classes: int = 7,  # â† æ–°å¢ï¼šç²—åˆ†ç±»æ•°é‡
             **kwargs) -> None:
    
    super().__init__(num_classes, in_channels, loss_cls, **kwargs)
    
    # ... åŸæœ‰ä»£ç  ...
    
    self.fc_rgb = nn.Linear(self.in_channels[0], num_classes)
    self.fc_pose = nn.Linear(self.in_channels[1], num_classes)
    
    # æ ¹æ®use_coarseå†³å®šæ˜¯å¦åˆ›å»ºç²—åˆ†ç±»ç›¸å…³æ¨¡å—
    self.use_coarse = use_coarse
    if self.use_coarse:
        self.fc_rgb_coarse = nn.Linear(self.in_channels[0], num_coarse_classes)
        self.fc_pose_coarse = nn.Linear(self.in_channels[1], num_coarse_classes)
        
        self.fr_coarse_rgb = ST_RenovateNet(
            2048, 8, n_class=num_coarse_classes, h_channel=128)
        self.fr_coarse_pose = ST_RenovateNet(
            512, 32, n_class=num_coarse_classes, h_channel=128)
        
        self.tree_loss_rgb = TreeLoss()
        self.tree_loss_pose = TreeLoss()
    
    # ç»†ç²’åº¦RenovateNetï¼ˆæ°¸è¿œéœ€è¦ï¼‰
    self.fr_rgb = ST_RenovateNet_Fine(
        2048, n_class=num_classes, version='V0', use_p_map=True)
    self.fr_pose = ST_RenovateNet_Fine(
        512, n_class=num_classes, version='V0', use_p_map=True)


# ========== ä¿®æ”¹2: forwardæ–¹æ³•ï¼ˆçº¦ç¬¬576è¡Œï¼‰==========
def forward(self, x: List[torch.Tensor]) -> Dict:
    x_rgb, x_pose = self.avg_pool(x[0]), self.avg_pool(x[1])
    x_rgb = x_rgb.view(x_rgb.size(0), -1)
    x_pose = x_pose.view(x_pose.size(0), -1)
    
    x_rgb = self.dropout_rgb(x_rgb)
    x_pose = self.dropout_pose(x_pose)
    
    cls_scores = dict()
    logits_rgb = self.fc_rgb(x_rgb)
    logits_pose = self.fc_pose(x_pose)
    
    if self.training:
        cls_scores['rgb'] = logits_rgb
        cls_scores['pose'] = logits_pose
        
        x_rgb1, x_pose1 = x[2], x[3]
        gt = x[4]
        
        x_rgb1 = x_rgb1.mean(dim=2)
        x_pose1 = x_pose1.mean(dim=2)
        
        if self.use_coarse:
            # æœ‰ç²—åˆ†ç±»çš„æƒ…å†µï¼ˆMA-52ï¼‰
            gt_coarse = x[5]
            logits_coarse_rgb = self.fc_rgb_coarse(x_rgb)
            logits_coarse_pose = self.fc_pose_coarse(x_pose)
            
            cls_scores['rgb_coarse'] = logits_coarse_rgb
            cls_scores['pose_coarse'] = logits_coarse_pose
            
            # ç²—åˆ†ç±»çš„FR loss
            coarse_fr_loss_rgb = self.fr_coarse_rgb(
                x_rgb1, gt_coarse.detach(), logits_coarse_rgb)
            coarse_fr_loss_pose = self.fr_coarse_pose(
                x_pose1, gt_coarse.detach(), logits_coarse_pose)
            
            # ç»†åˆ†ç±»çš„FR lossï¼ˆéœ€è¦ç²—åˆ†ç±»æ ‡ç­¾ï¼‰
            fr_loss_rgb = self.fr_rgb(
                x_rgb1, gt_coarse.detach(), gt.detach(), 
                logits_coarse_rgb, logits_rgb)
            fr_loss_pose = self.fr_pose(
                x_pose1, gt_coarse.detach(), gt.detach(),
                logits_coarse_pose, logits_pose)
            
            # Tree loss
            hierarchy_loss_rgb = self.tree_loss_rgb(
                logits_coarse_rgb, logits_rgb, gt_coarse.detach(), gt.detach())
            hierarchy_loss_pose = self.tree_loss_pose(
                logits_coarse_pose, logits_pose, gt_coarse.detach(), gt.detach())
            
            cls_scores['fr_loss_rgb_coarse'] = coarse_fr_loss_rgb
            cls_scores['fr_loss_pose_coarse'] = coarse_fr_loss_pose
            cls_scores['hierarchy_loss_rgb'] = hierarchy_loss_rgb
            cls_scores['hierarchy_loss_pose'] = hierarchy_loss_pose
        else:
            # æ— ç²—åˆ†ç±»çš„æƒ…å†µï¼ˆNTU-60ï¼‰
            # åˆ›å»ºè™šæ‹Ÿçš„ç²—åˆ†ç±»æ ‡ç­¾ï¼ˆå…¨éƒ¨æ˜ å°„åˆ°ç±»åˆ«0ï¼‰
            gt_coarse = torch.zeros_like(gt)
            logits_coarse_rgb = torch.zeros(x_rgb.size(0), 1).to(x_rgb.device)
            logits_coarse_pose = torch.zeros(x_pose.size(0), 1).to(x_pose.device)
            
            # ç®€åŒ–çš„FR lossï¼ˆåªç”¨ç»†åˆ†ç±»ï¼‰
            fr_loss_rgb = self.fr_rgb.forward_simple(
                x_rgb1, gt.detach(), logits_rgb)  # éœ€è¦æ·»åŠ simpleç‰ˆæœ¬
            fr_loss_pose = self.fr_pose.forward_simple(
                x_pose1, gt.detach(), logits_pose)
        
        cls_scores['fr_loss_rgb'] = fr_loss_rgb
        cls_scores['fr_loss_pose'] = fr_loss_pose
    
    if not self.training:
        # æµ‹è¯•é˜¶æ®µçš„åŸå‹ä¿®æ­£ï¼ˆæ— éœ€ç²—åˆ†ç±»ï¼‰
        with torch.no_grad():
            rgb_proto = self.fr_rgb.spatio_cl_net.avg_f.permute(1, 0).cuda()
            pose_proto = self.fr_pose.spatio_cl_net.avg_f.permute(1, 0).cuda()
            
            logits_rgb_proto = self.fr_rgb.spatio_cl_net.cl_fc(x_rgb)
            logits_pose_proto = self.fr_pose.spatio_cl_net.cl_fc(x_pose)
            
            cos_sim_rgb = F.cosine_similarity(
                logits_rgb_proto.unsqueeze(1), rgb_proto.unsqueeze(0), dim=2)
            cos_sim_pose = F.cosine_similarity(
                logits_pose_proto.unsqueeze(1), pose_proto.unsqueeze(0), dim=2)
            
            cls_scores['rgb'] = logits_rgb + cos_sim_rgb * 5
            cls_scores['pose'] = logits_pose + cos_sim_pose * 1
    
    return cls_scores
```

```python
def forward_simple(self, feature, lbl, logit):
    """
    æ— ç²—åˆ†ç±»çš„ç®€åŒ–ç‰ˆæœ¬
    åªä½¿ç”¨ç»†åˆ†ç±»æ ‡ç­¾è¿›è¡ŒåŸå‹å­¦ä¹ 
    """
    # ç‰¹å¾æŠ•å½±
    feature = self.cl_fc(feature)
    feature = F.normalize(feature.permute(0, 2, 3, 1), dim=3)
    feature = feature.reshape(-1, self.h_channel)
    
    # ä½¿ç”¨argmaxä½œä¸ºè™šæ‹Ÿçš„ç²—åˆ†ç±»é¢„æµ‹
    lbl_one_coarse = F.one_hot(torch.zeros_like(lbl), 1).to(torch.float32)
    pred_one_coarse = F.one_hot(torch.zeros_like(lbl), 1).to(torch.float32)
    
    # ç»†åˆ†ç±»çš„one-hot
    lbl_one = F.one_hot(lbl.to(torch.int64), self.n_class).to(torch.float32)
    pred_one = F.one_hot(logit.argmax(1), self.n_class).to(torch.float32)
    
    # è®¡ç®—TP/FN/FPï¼ˆåªåŸºäºç»†åˆ†ç±»ï¼‰
    mask, fn, fp = self.get_mask_fn_fp(
        lbl_one_coarse, lbl_one, 
        pred_one_coarse, pred_one,
        torch.zeros_like(logit), logit)
    
    # å…¶ä½™è®¡ç®—ä¿æŒä¸å˜
    f_mem, f_fn_1, f_fn_2, f_fn_3, f_fp = self.local_avg_tp_fn_fp(
        feature, mask, fn[0], fn[1], fn[2], fp)
    
    score_cl_fn, score_cl_fp = self.get_score(
        feature, f_mem, f_fn_1, f_fn_2, f_fn_3, f_fp,
        lbl_one, pred_one, lbl, use_p_map=self.use_p_map)
    
    return (self.loss(score_cl_fn, lbl) + self.loss(score_cl_fp, lbl)).mean()
```

```python
def extract_feat(self, inputs: torch.Tensor, stage: str = 'neck',
                 data_samples: OptSampleList = None,
                 test_mode: bool = False, **kwargs):
    # ... existing code ...
    
    if self.with_neck:
        if stage == 'backbone':
            return x
        gts = [data.gt_labels.item for data in data_samples]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç²—åˆ†ç±»æ ‡ç­¾
        if hasattr(self.cls_head, 'use_coarse') and not self.cls_head.use_coarse:
            # NTU-60æ¨¡å¼ï¼šä½¿ç”¨è™šæ‹Ÿç²—åˆ†ç±»
            gts_coarse = torch.zeros_like(torch.tensor(gts))
        else:
            # MA-52æ¨¡å¼ï¼šä»ç»†åˆ†ç±»æ˜ å°„åˆ°ç²—åˆ†ç±»
            temp = torch.tensor(gts).to(torch.int32)
            gts_coarse = [fine2coarse(i) for i in temp]
        
        inputs['gt'] = gts
        inputs['gt_coarse'] = gts_coarse
        x = self.backbone(**inputs)
        # ... rest of code ...
```

```python
# åœ¨rgbpose_head.pyå¼€å¤´æ·»åŠ 
def action2body_ntu60(x):
    """NTU-60çš„å±‚æ¬¡æ˜ å°„"""
    if 0 <= x <= 11:
        return 0  # Daily Actions (drink, eat, brush teeth...)
    elif 12 <= x <= 23:
        return 1  # Interaction (handshake, hug, punch...)
    elif 24 <= x <= 35:
        return 2  # Health (sneeze, headache, chest pain...)
    elif 36 <= x <= 47:
        return 3  # Gesture (point, thumb up, ok sign...)
    elif 48 <= x <= 50:
        return 4  # Hand movements (typing, writing...)
    elif 51 <= x <= 55:
        return 5  # Body movements (walk, sit, stand...)
    elif 56 <= x <= 58:
        return 6  # Fall related
    else:
        return 7  # Other
```

```python
head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,
    num_coarse_classes=8,  # NTUè‡ªå®šä¹‰8ç±»
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose', 'rgb_coarse', 'pose_coarse'],
    loss_weights=[1., 1., 0.5, 0.5],
    average_clips='prob',
    use_coarse=True,
    action2body_func='action2body_ntu60')  # æŒ‡å®šä½¿ç”¨NTUçš„æ˜ å°„
```

```plaintext
åŸºç¡€RGBPoseConv3D (NTU-60 XSub):
  â€¢ Top-1: 96.2-96.4% (READMEä¸­æŠ¥å‘Š)

åŠ å…¥PCANåé¢„æœŸæå‡:
  â€¢ åŸå‹å­¦ä¹ : +1-2%
  â€¢ FN/FPæ ¡å‡†: +0.5-1%
  â€¢ é¢„æœŸTop-1: 97.5-98.0%
  
âš ï¸ æ³¨æ„ï¼š
  â€¢ æ²¡æœ‰TreeLossï¼ˆå› ä¸ºè‡ªå®šä¹‰ç²—åˆ†ç±»ä¸å¤Ÿç²¾å‡†ï¼‰
  â€¢ æå‡å¹…åº¦å¯èƒ½ä¸å¦‚MA-52ï¼ˆNTU-60ç±»åˆ«è¾ƒå°‘ï¼Œæ··æ·†åº¦ä½ï¼‰
```

```shellscript
# 1. å‡†å¤‡NTU-60æ•°æ®é›†
# ä¸‹è½½RGBè§†é¢‘å’Œéª¨æ¶æ ‡æ³¨
cd data
mkdir -p skeleton nturgbd_videos

# 2. å‡†å¤‡éª¨æ¶æ•°æ®ï¼ˆpklæ ¼å¼ï¼‰
# å‚è€ƒï¼šhttps://github.com/open-mmlab/mmaction2/blob/main/tools/data/skeleton/README.md

# 3. éª¨æ¶æ•°æ®æ ¼å¼ï¼ˆ25ä¸ªå…³é”®ç‚¹ï¼‰
# NTUéª¨æ¶ç‚¹ç´¢å¼•ï¼š0-24
# éœ€è¦è½¬æ¢ä¸ºä¸MA-52ç›¸åŒçš„æ•°æ®æ ¼å¼
```

```python
# MA-52: 28ä¸ªç‚¹ï¼ˆOpenPose-28ï¼‰
# NTU-60: 25ä¸ªç‚¹ï¼ˆKinect v2ï¼‰

è§£å†³ï¼š
  pose_pathway=dict(
      in_channels=25,  # ä¿®æ”¹è¿™é‡Œ
      # å…¶ä»–å‚æ•°ä¿æŒä¸å˜
  )
```

```python
# æ–¹æ¡ˆ1ï¼šå»é™¤TreeLossï¼ˆç®€å•ï¼‰
# åœ¨forwardä¸­è·³è¿‡hierarchy_lossçš„è®¡ç®—

# æ–¹æ¡ˆ2ï¼šæ”¹å†™TreeLossä»¥æ”¯æŒè‡ªå®šä¹‰æ˜ å°„ï¼ˆæ¨èï¼‰
class TreeLoss(nn.Module):
    def __init__(self, num_actions=52, num_bodies=7, 
                 action2body_fn=None):
        super().__init__()
        self.num_actions = num_actions
        self.num_bodies = num_bodies
        self.action2body_fn = action2body_fn or action2body
        self.stateSpace = self.generateStateSpace().cuda()
    
    def generateStateSpace(self):
        stat_list = np.eye(self.num_bodies + self.num_actions)
        for i in range(self.num_bodies, 
                      self.num_bodies + self.num_actions):
            action_id = i - self.num_bodies
            coarse_id = self.action2body_fn(action_id)
            stat_list[i][coarse_id] = 1
        return torch.tensor(stat_list)
```

```python
_base_ = './rgbpose_conv3d.py'

# åªä¿®æ”¹å…³é”®å‚æ•°
backbone_cfg = dict(
    type='RGBPoseConv3D',
    pose_pathway=dict(in_channels=25))  # 25ä¸ªéª¨æ¶ç‚¹

head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,  # 60ä¸ªç±»åˆ«
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose'],  # åªç”¨RGBå’ŒPoseï¼Œå»æ‰coarse
    loss_weights=[1., 1.],
    average_clips='prob')

model = dict(
    backbone=backbone_cfg,
    cls_head=head_cfg)

# æ•°æ®é›†é…ç½®
dataset_type = 'PoseDataset'
data_root = 'data/nturgbd_videos/'
ann_file_train = 'data/skeleton/ntu60_3d.pkl'
ann_file_val = 'data/skeleton/ntu60_3d.pkl'

# å·¦å³éª¨æ¶ç‚¹ï¼ˆNTU-60ï¼‰
left_kp = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23]
right_kp = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]

# ... pipelineé…ç½®ä¿æŒç±»ä¼¼ ...
```

```shellscript
# 1. ä¿®æ”¹é…ç½®æ–‡ä»¶
# 2. å»é™¤ç²—åˆ†ç±»ä¾èµ–ï¼ˆä»£ç å±‚é¢ç®€åŒ–å¤„ç†ï¼‰
# 3. ç›´æ¥æµ‹è¯•åŸºç¡€æ€§èƒ½

é¢„æœŸï¼šèƒ½è·‘é€šï¼Œæ€§èƒ½çº¦+0.5-1%
```

```shellscript
# 1. è®¾è®¡NTU-60çš„ç²—åˆ†ç±»ä½“ç³»
# 2. å®ç°å®Œæ•´çš„PCANåŠŸèƒ½
# 3. é‡æ–°è®­ç»ƒæ‰€æœ‰æƒé‡

é¢„æœŸï¼šæœ€ä¼˜æ€§èƒ½ï¼Œ+1.5-2.5%
```

```shellscript
# 1. å¯¹æ¯”å»é™¤PCAN vs ç®€åŒ–PCAN vs å®Œæ•´PCAN
# 2. æ¶ˆèå®éªŒ
# 3. å‘è®ºæ–‡ :)
```

---

**User**

ä½ å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹é¡¹ç›®çœ‹çœ‹æ˜¯å¦æœ‰å¤„ç†ntud60æ•°æ®é›†çš„è„šæœ¬ä»£ç  æˆ‘ä¼¼ä¹åœ¨é¡¹ç›®F:\lunwen\PCAN-main\mmaction2\configs\skeleton è¿™ä¸ªæ–‡ä»¶å¤¹ä¸‹é¢çœ‹åˆ°äº†ç›¸å…³çš„ä»£ç ï¼Œä½†æˆ‘ä¸çŸ¥é“è¿™ä¸ªä»£ç èƒ½ä¸èƒ½é€‚ç”¨@configs 

---

**Cursor**

è®©æˆ‘å¸®ä½ è¯¦ç»†æŸ¥çœ‹é¡¹ç›®ä¸­å…³äºNTU-60æ•°æ®é›†çš„é…ç½®å’Œè„šæœ¬ã€‚

## âœ… å¥½æ¶ˆæ¯ï¼šé¡¹ç›®å·²ç»æ”¯æŒNTU-60ï¼

ä½ çš„å‘ç°æ˜¯å¯¹çš„ï¼è®©æˆ‘è¯¦ç»†åˆ†æä½ æ‰¾åˆ°çš„è¿™äº›ä»£ç ã€‚

## ğŸ“ å‘ç°çš„NTU-60ç›¸å…³ä»£ç 

### 1. **åŸºç¡€é…ç½®æ–‡ä»¶**ï¼ˆåœ¨`configs/skeleton/posec3d`ä¸‹ï¼‰

```
âœ“ slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint.py
âœ“ slowonly_r50_8xb16-u48-240e_ntu60-xsub-limb.py
```

è¿™äº›æ˜¯**åŸºç¡€çš„PoseC3D**ï¼ˆåªç”¨éª¨æ¶ï¼Œä¸ç”¨RGBï¼‰åœ¨NTU-60ä¸Šçš„é…ç½®ã€‚

### 2. **RGBPoseé…ç½®**ï¼ˆåœ¨`configs/skeleton/posec3d/rgbpose_conv3d`ä¸‹ï¼‰

```
âœ“ rgb_only.py      - åªç”¨RGBè®­ç»ƒNTU-60
âœ“ pose_only.py     - åªç”¨Poseè®­ç»ƒNTU-60
âœ“ rgbpose_conv3d.py - åŒæµèåˆï¼ˆä½†å½“å‰é…ç½®æ˜¯MA-52ï¼‰
```

### 3. **æ•°æ®å¤„ç†è„šæœ¬**ï¼ˆåœ¨`tools/data/skeleton`ä¸‹ï¼‰

```
âœ“ compress_nturgbd.py      - å‹ç¼©NTU-60è§†é¢‘
âœ“ gen_ntu_rgbd_raw.py      - è½¬æ¢éª¨æ¶æ•°æ®æ ¼å¼ï¼ˆ3Dï¼Œ25ä¸ªç‚¹ï¼‰
âœ“ ntu_pose_extraction.py   - æå–2Då§¿æ€ï¼ˆ17ä¸ªç‚¹ï¼‰
```

---

## ğŸ” å…³é”®å‘ç°ï¼šé…ç½®æ–‡ä»¶çš„å·®å¼‚

### NTU-60é…ç½® vs PCAN(MA-52)é…ç½®

| ç‰¹å¾ | NTU-60é…ç½® | PCAN(MA-52)é…ç½® | èƒ½å¦ç›´æ¥ç”¨ï¼Ÿ |
|------|-----------|----------------|------------|
| **éª¨æ¶ç‚¹æ•°** | **17ç‚¹**(2D) æˆ– **25ç‚¹**(3D) | **28ç‚¹**(OpenPose) | âŒ éœ€è¦ä¿®æ”¹ |
| **ç±»åˆ«æ•°** | **60ç±»** | **52ç±»** | âŒ éœ€è¦ä¿®æ”¹ |
| **ç²—åˆ†ç±»** | âŒ æ—  | âœ“ 7ç±» | âŒ å†²çªï¼ |
| **Headç±»å‹** | `I3DHead` | `RGBPoseHead`(å¸¦PCAN) | âŒ ä¸å…¼å®¹ |
| **éª¨æ¶æ ¼å¼** | Kinect v2 | OpenPose-28 | âŒ ä¸åŒ |

---

## ğŸ¯ ç°æœ‰NTU-60é…ç½®èƒ½å¦ç”¨äºPCANï¼Ÿ

### ç­”æ¡ˆï¼š**ä¸èƒ½ç›´æ¥ä½¿ç”¨ï¼éœ€è¦é€‚é…ï¼**

### åŸå› åˆ†æ

#### 1. **pose_only.pyå’Œrgb_only.py** 

```python
# configs/skeleton/posec3d/rgbpose_conv3d/pose_only.py
model = dict(
    type='Recognizer3D',  # â† åŸºç¡€æ¨¡å‹ï¼Œä¸æ˜¯MMRecognizer3D
    backbone=dict(
        type='ResNet3dSlowOnly',
        in_channels=17,  # â† NTU-60çš„2Déª¨æ¶
        num_classes=60),
    cls_head=dict(
        type='I3DHead',  # â† åŸºç¡€Headï¼Œä¸æ˜¯RGBPoseHead
        num_classes=60))
```

**é—®é¢˜**ï¼š
- âœ… æ”¯æŒNTU-60ï¼ˆ60ç±»ï¼Œ17æˆ–25ä¸ªç‚¹ï¼‰
- âŒ **æ²¡æœ‰PCANåŠŸèƒ½**ï¼ˆæ²¡æœ‰åŸå‹å­¦ä¹ ã€æ²¡æœ‰RenovateNetï¼‰
- âŒ ä¸æ˜¯åŒæµæ¶æ„ï¼ˆå•ç‹¬çš„RGBæˆ–Poseï¼‰

#### 2. **å½“å‰çš„rgbpose_conv3d.py**

```python
# configs/skeleton/posec3d/rgbpose_conv3d/rgbpose_conv3d.py
backbone_cfg = dict(
    type='RGBPoseConv3D',
    pose_pathway=dict(
        in_channels=28,  # â† MA-52çš„OpenPose-28
        ...))

head_cfg = dict(
    type='RGBPoseHead',  # â† åŒ…å«PCANåŠŸèƒ½
    num_classes=52,  # â† MA-52çš„52ç±»
    ...)
```

**é—®é¢˜**ï¼š
- âœ… æœ‰å®Œæ•´çš„PCANåŠŸèƒ½
- âŒ ç¡¬ç¼–ç ä¸ºMA-52ï¼ˆ28ç‚¹ï¼Œ52ç±»ï¼‰
- âŒ ä¾èµ–ç²—åˆ†ç±»ï¼ˆ7ç±»body-levelï¼‰

---

## ğŸ’¡ é€‚é…æ–¹æ¡ˆæ€»ç»“

### æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | ä½¿ç”¨ç°æœ‰é…ç½® | éœ€è¦ä¿®æ”¹ | PCANåŠŸèƒ½ | é¢„æœŸæ•ˆæœ |
|------|------------|---------|---------|---------|
| **A. ä½¿ç”¨pose_only.py** | âœ… ç›´æ¥ç”¨ | âŒ æ—  | âŒ æ— PCAN | 93-95% (åŸºçº¿) |
| **B. ä¿®æ”¹rgbpose_conv3d.py** | âŒ ä¸èƒ½ç”¨ | âœ… ä¸­ç­‰ | âš ï¸ ç®€åŒ–PCAN | 96-97% |
| **C. å®Œå…¨é€‚é…PCAN** | âŒ ä¸èƒ½ç”¨ | âœ… è¾ƒå¤š | âœ… å®Œæ•´PCAN | 97-98% |

---

## ğŸš€ å®ç”¨å»ºè®®ï¼šåˆ†æ­¥å®æ–½

### é˜¶æ®µ1ï¼šéªŒè¯åŸºç¡€æµç¨‹ï¼ˆç”¨ç°æœ‰é…ç½®ï¼‰âœ…

**ç›®çš„**ï¼šå…ˆç¡®ä¿NTU-60æ•°æ®èƒ½è·‘é€š

```bash
# ä½¿ç”¨ç°æœ‰çš„NTU-60é…ç½®ï¼ˆä¸å¸¦PCANï¼‰
cd /home/zh/ChCode/codes01/mmaction2

# æµ‹è¯•Pose-onlyæ¨¡å‹
python tools/test.py \
    configs/skeleton/posec3d/slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint.py \
    <checkpoint.pth>
```

**è¿™ä¸ªé…ç½®çš„ç‰¹ç‚¹**ï¼š
- âœ“ å®Œå…¨æ”¯æŒNTU-60ï¼ˆ17ä¸ªç‚¹ï¼Œ60ç±»ï¼‰
- âœ“ ä¸éœ€è¦ä¿®æ”¹ä»£ç 
- âœ“ æœ‰é¢„è®­ç»ƒæƒé‡å¯ä¸‹è½½
- âŒ æ²¡æœ‰PCANåŠŸèƒ½
- âŒ åªç”¨Poseï¼Œä¸ç”¨RGB

### é˜¶æ®µ2ï¼šé€‚é…PCANåˆ°NTU-60ï¼ˆæ¨èæ–¹æ¡ˆï¼‰â­

åˆ›å»ºæ–°é…ç½® `configs/skeleton/posec3d/rgbpose_conv3d/rgbpose_conv3d_ntu60.py`ï¼š

```python
_base_ = './rgbpose_conv3d.py'

# ========== ä¿®æ”¹1: éª¨æ¶ç‚¹æ•° ==========
backbone_cfg = dict(
    type='RGBPoseConv3D',
    speed_ratio=4,
    channel_ratio=4,
    rgb_pathway=dict(
        # RGBé…ç½®ä¿æŒä¸å˜
        num_stages=4,
        lateral=True,
        lateral_infl=1,
        lateral_activate=[0, 0, 1, 1],
        fusion_kernel=7,
        base_channels=64,
        conv1_kernel=(1, 7, 7),
        inflate=(0, 0, 1, 1),
        with_pool2=False),
    pose_pathway=dict(
        num_stages=3,
        stage_blocks=(4, 6, 3),
        lateral=True,
        lateral_inv=True,
        lateral_infl=16,
        lateral_activate=(0, 1, 1),
        fusion_kernel=7,
        in_channels=17,  # â† æ”¹ï¼šNTU-60 2Déª¨æ¶(17ç‚¹)
        # æˆ– in_channels=25 for 3Déª¨æ¶
        base_channels=32,
        out_indices=(2, ),
        conv1_kernel=(1, 7, 7),
        conv1_stride_s=1,
        conv1_stride_t=1,
        pool1_stride_s=1,
        pool1_stride_t=1,
        inflate=(0, 1, 1),
        spatial_strides=(2, 2, 2),
        temporal_strides=(1, 1, 1),
        dilations=(1, 1, 1),
        with_pool2=False))

# ========== ä¿®æ”¹2: ç±»åˆ«æ•° ==========
head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,  # â† æ”¹ï¼šNTU-60çš„60ç±»
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose'],  # â† æ”¹ï¼šå»æ‰coarse
    loss_weights=[1., 1.],
    average_clips='prob')

# ========== ä¿®æ”¹3: æ•°æ®è·¯å¾„ ==========
dataset_type = 'PoseDataset'
data_root = 'data/nturgbd_videos/'
ann_file = 'data/skeleton/ntu60_2d.pkl'  # ä½¿ç”¨2Déª¨æ¶
ann_file_val = 'data/skeleton/ntu60_2d.pkl'
ann_file_test = 'data/skeleton/ntu60_2d.pkl'

# ========== ä¿®æ”¹4: éª¨æ¶ç‚¹å®šä¹‰ï¼ˆ17ç‚¹çš„å·¦å³å®šä¹‰ï¼‰==========
left_kp = [1, 3, 5, 7, 9, 11, 13, 15]
right_kp = [2, 4, 6, 8, 10, 12, 14, 16]

# å¦‚æœç”¨25ç‚¹ï¼ˆ3Déª¨æ¶ï¼‰ï¼Œéœ€è¦æ”¹ä¸ºï¼š
# left_kp = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23]
# right_kp = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]

# Pipelineä¿æŒç±»ä¼¼ï¼Œä½†å»æ‰skeletonså®šä¹‰ï¼ˆå› ä¸ºæ²¡æœ‰limb heatmapï¼‰
train_pipeline = [
    dict(
        type='MMUniformSampleFrames',
        clip_len=dict(RGB=8, Pose=32),
        num_clips=1),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(type='RandomResizedCrop', area_range=(0.56, 1.0)),
    dict(type='Resize', scale=(224, 224), keep_ratio=False),
    dict(type='Flip', flip_ratio=0.5, left_kp=left_kp, right_kp=right_kp),
    dict(
        type='GeneratePoseTarget',
        sigma=0.7,
        use_score=True,
        with_kp=True,
        with_limb=False,
        scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

# ... å…¶ä»–dataloaderé…ç½®ç±»ä¼¼MA-52 ...

# ========== ä¿®æ”¹5: è®­ç»ƒé…ç½® ==========
train_cfg = dict(
    type='EpochBasedTrainLoop', max_epochs=30, val_begin=3, val_interval=1)

optim_wrapper = dict(
    optimizer=dict(type='SGD', lr=0.0075, momentum=0.9, weight_decay=0.0001),
    clip_grad=dict(max_norm=40, norm_type=2))

# ========== é‡è¦ï¼šå»æ‰load_fromæˆ–æŒ‡å‘NTUçš„initæƒé‡ ==========
load_from = None  # æˆ–æŒ‡å‘NTU-60çš„åˆå§‹åŒ–æƒé‡
```

### é˜¶æ®µ3ï¼šä¿®æ”¹ä»£ç ä»¥å»é™¤ç²—åˆ†ç±»ä¾èµ–

ç”±äºPCANçš„ä»£ç **ç¡¬ç¼–ç äº†ç²—åˆ†ç±»**ï¼ˆåœ¨`recognizer3d_mm.py`å’Œ`rgbpose_head.py`ä¸­ï¼‰ï¼Œéœ€è¦ä¿®æ”¹ï¼š

#### ä¿®æ”¹1ï¼š`mmaction/models/recognizers/recognizer3d_mm.py`

```python
def fine2coarse_ntu60(x):
    """
    ä¸ºNTU-60åˆ›å»ºè™šæ‹Ÿçš„ç²—åˆ†ç±»
    æ–¹æ¡ˆ1ï¼šå…¨éƒ¨æ˜ å°„åˆ°ç±»åˆ«0ï¼ˆæœ€ç®€å•ï¼‰
    """
    return 0

# æˆ–è€…æ ¹æ®NTU-60çš„è¯­ä¹‰å®šä¹‰8ä¸ªç²—ç±»
def fine2coarse_ntu60_semantic(x):
    """
    åŸºäºNTU-60åŠ¨ä½œè¯­ä¹‰çš„ç²—åˆ†ç±»
    """
    if 0 <= x <= 7:
        return 0  # Hand-arm movements
    elif 8 <= x <= 15:
        return 1  # Two-hand movements
    elif 16 <= x <= 25:
        return 2  # Interaction
    elif 26 <= x <= 31:
        return 3  # Body movements
    elif 32 <= x <= 39:
        return 4  # Pick/throw
    elif 40 <= x <= 49:
        return 5  # Health-related
    elif 50 <= x <= 56:
        return 6  # Common actions
    else:
        return 7  # Other

@MODELS.register_module()
class MMRecognizer3D(BaseRecognizer):
    def extract_feat(self, inputs, ...):
        # ... existing code ...
        
        gts = []
        for data in data_samples:
            gts.extend(data.gt_labels.item)
        gts = torch.stack(gts)
        temp = gts.cpu().numpy()
        
        # â† ä¿®æ”¹è¿™é‡Œï¼šæ ¹æ®æ•°æ®é›†é€‰æ‹©æ˜ å°„å‡½æ•°
        if self.cls_head.num_classes == 60:
            # NTU-60æ¨¡å¼
            gts_coarse = [fine2coarse_ntu60(i) for i in temp]
        else:
            # MA-52æ¨¡å¼
            gts_coarse = [fine2coarse(i) for i in temp]
        
        gts_coarse = torch.from_numpy(np.array(gts_coarse)).cuda()
        # ... rest of code ...
```

#### ä¿®æ”¹2ï¼š`mmaction/models/heads/rgbpose_head.py`

éœ€è¦è®©`RenovateNet_Fine`æ”¯æŒä¸åŒçš„ç²—åˆ†ç±»æ•°é‡ï¼š

```python
class RenovateNet_Fine(nn.Module):
    def __init__(self, n_channel, n_class, alp=0.125, tmp=0.125, mom=0.9, 
                 h_channel=None, version='V0', pred_threshold=0.0, 
                 use_p_map=True, 
                 n_class_coarse=7):  # â† æ–°å¢å‚æ•°
        super(RenovateNet_Fine, self).__init__()
        self.n_channel = n_channel
        self.h_channel = n_channel if h_channel is None else h_channel
        self.n_class = n_class
        self.n_class_coarse = n_class_coarse  # â† ä½¿ç”¨ä¼ å…¥çš„å€¼
        # ... rest of code ...

# åœ¨RGBPoseHeadçš„__init__ä¸­ï¼š
class RGBPoseHead(BaseHead):
    def __init__(self, num_classes, in_channels, 
                 num_coarse_classes=7,  # â† æ–°å¢å‚æ•°
                 ...):
        # ...
        self.fc_rgb_coarse = nn.Linear(self.in_channels[0], num_coarse_classes)
        self.fc_pose_coarse = nn.Linear(self.in_channels[1], num_coarse_classes)
        
        self.fr_coarse_rgb = ST_RenovateNet(
            2048, 8, n_class=num_coarse_classes, h_channel=128)
        self.fr_coarse_pose = ST_RenovateNet(
            512, 32, n_class=num_coarse_classes, h_channel=128)
        
        self.fr_rgb = ST_RenovateNet_Fine(
            2048, n_class=num_classes, 
            n_class_coarse=num_coarse_classes)  # â† ä¼ é€’ç²—åˆ†ç±»æ•°
        # ... rest
```

#### ä¿®æ”¹3ï¼š`TreeLoss`éœ€è¦é€‚é…

```python
class TreeLoss(nn.Module):
    def __init__(self, num_actions=52, num_bodies=7, 
                 action2body_fn=None):  # â† æ–°å¢å‚æ•°
        super(TreeLoss, self).__init__()
        self.num_actions = num_actions
        self.num_bodies = num_bodies
        self.action2body_fn = action2body_fn or action2body
        self.stateSpace = self.generateStateSpace().cuda()
        self.sig = nn.Sigmoid()
    
    def generateStateSpace(self):
        stat_list = np.eye(self.num_bodies + self.num_actions)
        for i in range(self.num_bodies, self.num_bodies + self.num_actions):
            action_id = i - self.num_bodies
            coarse_id = self.action2body_fn(action_id)
            stat_list[i][coarse_id] = 1
        return torch.tensor(stat_list)
```

---

## ğŸ“‹ å®Œæ•´çš„é€‚é…checklist

### å¿…é¡»ä¿®æ”¹çš„é¡¹

- [ ] **é…ç½®æ–‡ä»¶**ï¼šåˆ›å»º`rgbpose_conv3d_ntu60.py`
  - [ ] `pose_pathway.in_channels`: 28 â†’ 17 (æˆ–25)
  - [ ] `num_classes`: 52 â†’ 60
  - [ ] `left_kp/right_kp`: æ›´æ–°ä¸ºNTUçš„å®šä¹‰
  - [ ] `data_root`: æŒ‡å‘NTU-60è·¯å¾„
  - [ ] `ann_file`: æŒ‡å‘ntu60_2d.pklæˆ–ntu60_3d.pkl
  - [ ] å»æ‰`skeletons`å®šä¹‰ï¼ˆMA-52ç‰¹æœ‰ï¼‰

- [ ] **recognizer3d_mm.py**ï¼ˆç¬¬10-24è¡Œï¼‰
  - [ ] æ·»åŠ `fine2coarse_ntu60`å‡½æ•°
  - [ ] ä¿®æ”¹`extract_feat`æ ¹æ®ç±»åˆ«æ•°é€‰æ‹©æ˜ å°„

- [ ] **rgbpose_head.py**ï¼ˆç¬¬75è¡Œå’Œç¬¬556-564è¡Œï¼‰
  - [ ] `RenovateNet_Fine.__init__`: æ·»åŠ `n_class_coarse`å‚æ•°
  - [ ] `RGBPoseHead.__init__`: æ·»åŠ `num_coarse_classes`å‚æ•°
  - [ ] ä¼ é€’ç²—åˆ†ç±»æ•°åˆ°å„ä¸ªRenovateNet

- [ ] **rgbpose_head.py**ï¼ˆç¬¬35-64è¡Œï¼‰
  - [ ] `TreeLoss.__init__`: æ”¯æŒåŠ¨æ€çš„action2bodyæ˜ å°„
  - [ ] `generateStateSpace`: ä½¿ç”¨ä¼ å…¥çš„æ˜ å°„å‡½æ•°

### å¯é€‰ä¼˜åŒ–é¡¹

- [ ] å®šä¹‰NTU-60çš„è¯­ä¹‰ç²—åˆ†ç±»ï¼ˆ8ç±»ï¼‰
- [ ] é‡æ–°è®­ç»ƒRGB-onlyå’ŒPose-onlyçš„é¢„è®­ç»ƒæƒé‡
- [ ] åˆå¹¶é¢„è®­ç»ƒæƒé‡ä¸ºNTUç‰ˆçš„init.pth

---

## ğŸ¯ å¿«é€Ÿæµ‹è¯•æ–¹æ¡ˆï¼ˆæœ€å°æ”¹åŠ¨ï¼‰

å¦‚æœä½ åªæƒ³å¿«é€ŸéªŒè¯ï¼Œå¯ä»¥ç”¨è¿™ä¸ª**hackæ–¹æ¡ˆ**ï¼ˆä¸æ¨èç”Ÿäº§ä½¿ç”¨ï¼‰ï¼š

### åˆ›å»ºä¸´æ—¶é…ç½®

```python
# configs/skeleton/posec3d/rgbpose_conv3d/quick_ntu60.py
_base_ = './rgbpose_conv3d.py'

# æ ¸å¿ƒä¿®æ”¹
backbone_cfg = dict(
    pose_pathway=dict(in_channels=17))  # åªæ”¹éª¨æ¶ç‚¹æ•°

head_cfg = dict(
    num_classes=60)  # åªæ”¹ç±»åˆ«æ•°

model = dict(
    backbone=backbone_cfg,
    cls_head=head_cfg)

# æ•°æ®è·¯å¾„
data_root = 'data/nturgbd_videos/'
ann_file = 'data/skeleton/ntu60_2d.pkl'
ann_file_val = 'data/skeleton/ntu60_2d.pkl'
ann_file_test = 'data/skeleton/ntu60_2d.pkl'

left_kp = [1, 3, 5, 7, 9, 11, 13, 15]
right_kp = [2, 4, 6, 8, 10, 12, 14, 16]

# å»æ‰MA-52ç‰¹æœ‰çš„skeletonå®šä¹‰
train_pipeline = [
    dict(type='MMUniformSampleFrames', 
         clip_len=dict(RGB=8, Pose=32), num_clips=1),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(type='RandomResizedCrop', area_range=(0.56, 1.0)),
    dict(type='Resize', scale=(224, 224), keep_ratio=False),
    dict(type='Flip', flip_ratio=0.5, left_kp=left_kp, right_kp=right_kp),
    dict(type='GeneratePoseTarget', sigma=0.7, use_score=True,
         with_kp=True, with_limb=False, scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

# å…¶ä»–pipelineç±»ä¼¼...
```

**è¿è¡Œæ—¶ä¿®æ”¹ä»£ç **ï¼ˆä¸´æ—¶hackï¼Œä»…ç”¨äºæµ‹è¯•ï¼‰ï¼š

```python
# åœ¨recognizer3d_mm.pyçš„fine2coarseå‡½æ•°ä¸­ï¼š
def fine2coarse(x):
    # Hack for NTU-60: å…¨éƒ¨æ˜ å°„åˆ°0
    if x < 60:  # NTU-60
        return 0
    # åŸMA-52é€»è¾‘
    elif x <= 4:
        return 0
    # ... rest
```

**è¿™ä¸ªæ–¹æ¡ˆçš„é—®é¢˜**ï¼š
- âš ï¸ TreeLossä¼šæŠ¥é”™ï¼ˆå› ä¸ºå°ºå¯¸ä¸åŒ¹é…67â†’61ï¼‰
- âš ï¸ ç²—åˆ†ç±»å¤±å»æ„ä¹‰ï¼ˆéƒ½æ˜¯ç±»åˆ«0ï¼‰
- âš ï¸ ä½†åŸå‹å­¦ä¹ ä»ç„¶æœ‰æ•ˆï¼ˆç»†åˆ†ç±»å±‚é¢ï¼‰

---

## ğŸ“Š æœ€ç»ˆå»ºè®®

### æ ¹æ®ä½ çš„éœ€æ±‚é€‰æ‹©ï¼š

#### 1. **åªæ˜¯æƒ³å¿«é€Ÿæµ‹è¯•NTU-60**

â†’ ä½¿ç”¨ç°æœ‰çš„`slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint.py`

**ä¼˜ç‚¹**ï¼š
- âœ… å¼€ç®±å³ç”¨
- âœ… æœ‰é¢„è®­ç»ƒæƒé‡

**ç¼ºç‚¹**ï¼š
- âŒ æ²¡æœ‰PCANåŠŸèƒ½
- âŒ æ²¡æœ‰RGBä¿¡æ¯

#### 2. **æƒ³éªŒè¯PCANåœ¨NTU-60ä¸Šçš„æ•ˆæœ**

â†’ æŒ‰ç…§"é˜¶æ®µ2"çš„æ–¹æ¡ˆï¼Œåˆ›å»ºé€‚é…çš„é…ç½®+ä¿®æ”¹ä»£ç 

**å·¥ä½œé‡**ï¼š2-3å°æ—¶

**é¢„æœŸæå‡**ï¼š+0.5-1%ï¼ˆ96.8% â†’ 97.5-98%ï¼‰

#### 3. **æƒ³å‘è®ºæ–‡ï¼Œåšå®Œæ•´å®éªŒ**

â†’ å®Œå…¨é€‚é…PCANï¼ˆè‡ªå®šä¹‰NTUç²—åˆ†ç±»+å®Œæ•´ä¿®æ”¹ï¼‰

**å·¥ä½œé‡**ï¼š2-3å¤©

**é¢„æœŸæå‡**ï¼š+1-2%ï¼ˆ96.8% â†’ 98%+ï¼‰

---

## ğŸ”‘ å…³é”®ç»“è®º

### âœ… ç°æœ‰é…ç½®èƒ½å¦ç”¨äºPCANï¼Ÿ

**ä¸èƒ½ç›´æ¥ä½¿ç”¨**ï¼Œå› ä¸ºï¼š
1. `pose_only.py`å’Œ`rgb_only.py`æ˜¯åŸºç¡€æ¨¡å‹ï¼Œæ²¡æœ‰PCANåŠŸèƒ½
2. å½“å‰çš„`rgbpose_conv3d.py`ç¡¬ç¼–ç ä¸ºMA-52
3. PCANä¾èµ–ç²—åˆ†ç±»ï¼ˆNTU-60æ²¡æœ‰ï¼‰

### âœ… éœ€è¦åšå“ªäº›ä¿®æ”¹ï¼Ÿ

**æ ¸å¿ƒä¿®æ”¹ï¼ˆå¿…é¡»ï¼‰**ï¼š
- éª¨æ¶ç‚¹æ•°ï¼š28â†’17/25
- ç±»åˆ«æ•°ï¼š52â†’60
- ç²—åˆ†ç±»ï¼šåˆ›å»ºè™šæ‹Ÿæ˜ å°„

**ä»£ç ä¿®æ”¹ï¼ˆä¸­ç­‰å·¥ä½œé‡ï¼‰**ï¼š
- `recognizer3d_mm.py`ï¼šfine2coarseå‡½æ•°
- `rgbpose_head.py`ï¼šæ”¯æŒåŠ¨æ€ç²—åˆ†ç±»æ•°
- é…ç½®æ–‡ä»¶ï¼šåˆ›å»ºNTU-60ç‰ˆæœ¬

### âœ… æ•´ä½“å˜åŒ–å¤§å—ï¼Ÿ

**â­â­â­â˜†â˜† ä¸­ç­‰å˜åŒ–**

- **æ¶æ„ä¸å˜**ï¼šåŒæµ+åŸå‹å­¦ä¹ çš„æ ¸å¿ƒä¿ç•™
- **é…ç½®éœ€æ”¹**ï¼šéª¨æ¶ç‚¹ã€ç±»åˆ«æ•°ã€æ•°æ®è·¯å¾„
- **ä»£ç éœ€æ”¹**ï¼šå»é™¤MA-52ç‰¹æœ‰çš„ç¡¬ç¼–ç 
- **é¢„æœŸå·¥ä½œé‡**ï¼š2-3å°æ—¶ï¼ˆç®€åŒ–ç‰ˆï¼‰åˆ°2-3å¤©ï¼ˆå®Œæ•´ç‰ˆï¼‰

---

éœ€è¦æˆ‘è¯¦ç»†å±•å¼€æŸä¸ªä¿®æ”¹æ­¥éª¤çš„ä»£ç å—ï¼Ÿæˆ–è€…å¸®ä½ ç”Ÿæˆå®Œæ•´çš„é…ç½®æ–‡ä»¶ï¼Ÿ

```plaintext
âœ“ slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint.py
âœ“ slowonly_r50_8xb16-u48-240e_ntu60-xsub-limb.py
```

```plaintext
âœ“ rgb_only.py      - åªç”¨RGBè®­ç»ƒNTU-60
âœ“ pose_only.py     - åªç”¨Poseè®­ç»ƒNTU-60
âœ“ rgbpose_conv3d.py - åŒæµèåˆï¼ˆä½†å½“å‰é…ç½®æ˜¯MA-52ï¼‰
```

```plaintext
âœ“ compress_nturgbd.py      - å‹ç¼©NTU-60è§†é¢‘
âœ“ gen_ntu_rgbd_raw.py      - è½¬æ¢éª¨æ¶æ•°æ®æ ¼å¼ï¼ˆ3Dï¼Œ25ä¸ªç‚¹ï¼‰
âœ“ ntu_pose_extraction.py   - æå–2Då§¿æ€ï¼ˆ17ä¸ªç‚¹ï¼‰
```

```python
# configs/skeleton/posec3d/rgbpose_conv3d/pose_only.py
model = dict(
    type='Recognizer3D',  # â† åŸºç¡€æ¨¡å‹ï¼Œä¸æ˜¯MMRecognizer3D
    backbone=dict(
        type='ResNet3dSlowOnly',
        in_channels=17,  # â† NTU-60çš„2Déª¨æ¶
        num_classes=60),
    cls_head=dict(
        type='I3DHead',  # â† åŸºç¡€Headï¼Œä¸æ˜¯RGBPoseHead
        num_classes=60))
```

```python
# configs/skeleton/posec3d/rgbpose_conv3d/rgbpose_conv3d.py
backbone_cfg = dict(
    type='RGBPoseConv3D',
    pose_pathway=dict(
        in_channels=28,  # â† MA-52çš„OpenPose-28
        ...))

head_cfg = dict(
    type='RGBPoseHead',  # â† åŒ…å«PCANåŠŸèƒ½
    num_classes=52,  # â† MA-52çš„52ç±»
    ...)
```

```shellscript
# ä½¿ç”¨ç°æœ‰çš„NTU-60é…ç½®ï¼ˆä¸å¸¦PCANï¼‰
cd /home/zh/ChCode/codes01/mmaction2

# æµ‹è¯•Pose-onlyæ¨¡å‹
python tools/test.py \
    configs/skeleton/posec3d/slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint.py \
    <checkpoint.pth>
```

```python
_base_ = './rgbpose_conv3d.py'

# ========== ä¿®æ”¹1: éª¨æ¶ç‚¹æ•° ==========
backbone_cfg = dict(
    type='RGBPoseConv3D',
    speed_ratio=4,
    channel_ratio=4,
    rgb_pathway=dict(
        # RGBé…ç½®ä¿æŒä¸å˜
        num_stages=4,
        lateral=True,
        lateral_infl=1,
        lateral_activate=[0, 0, 1, 1],
        fusion_kernel=7,
        base_channels=64,
        conv1_kernel=(1, 7, 7),
        inflate=(0, 0, 1, 1),
        with_pool2=False),
    pose_pathway=dict(
        num_stages=3,
        stage_blocks=(4, 6, 3),
        lateral=True,
        lateral_inv=True,
        lateral_infl=16,
        lateral_activate=(0, 1, 1),
        fusion_kernel=7,
        in_channels=17,  # â† æ”¹ï¼šNTU-60 2Déª¨æ¶(17ç‚¹)
        # æˆ– in_channels=25 for 3Déª¨æ¶
        base_channels=32,
        out_indices=(2, ),
        conv1_kernel=(1, 7, 7),
        conv1_stride_s=1,
        conv1_stride_t=1,
        pool1_stride_s=1,
        pool1_stride_t=1,
        inflate=(0, 1, 1),
        spatial_strides=(2, 2, 2),
        temporal_strides=(1, 1, 1),
        dilations=(1, 1, 1),
        with_pool2=False))

# ========== ä¿®æ”¹2: ç±»åˆ«æ•° ==========
head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,  # â† æ”¹ï¼šNTU-60çš„60ç±»
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose'],  # â† æ”¹ï¼šå»æ‰coarse
    loss_weights=[1., 1.],
    average_clips='prob')

# ========== ä¿®æ”¹3: æ•°æ®è·¯å¾„ ==========
dataset_type = 'PoseDataset'
data_root = 'data/nturgbd_videos/'
ann_file = 'data/skeleton/ntu60_2d.pkl'  # ä½¿ç”¨2Déª¨æ¶
ann_file_val = 'data/skeleton/ntu60_2d.pkl'
ann_file_test = 'data/skeleton/ntu60_2d.pkl'

# ========== ä¿®æ”¹4: éª¨æ¶ç‚¹å®šä¹‰ï¼ˆ17ç‚¹çš„å·¦å³å®šä¹‰ï¼‰==========
left_kp = [1, 3, 5, 7, 9, 11, 13, 15]
right_kp = [2, 4, 6, 8, 10, 12, 14, 16]

# å¦‚æœç”¨25ç‚¹ï¼ˆ3Déª¨æ¶ï¼‰ï¼Œéœ€è¦æ”¹ä¸ºï¼š
# left_kp = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23]
# right_kp = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]

# Pipelineä¿æŒç±»ä¼¼ï¼Œä½†å»æ‰skeletonså®šä¹‰ï¼ˆå› ä¸ºæ²¡æœ‰limb heatmapï¼‰
train_pipeline = [
    dict(
        type='MMUniformSampleFrames',
        clip_len=dict(RGB=8, Pose=32),
        num_clips=1),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(type='RandomResizedCrop', area_range=(0.56, 1.0)),
    dict(type='Resize', scale=(224, 224), keep_ratio=False),
    dict(type='Flip', flip_ratio=0.5, left_kp=left_kp, right_kp=right_kp),
    dict(
        type='GeneratePoseTarget',
        sigma=0.7,
        use_score=True,
        with_kp=True,
        with_limb=False,
        scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

# ... å…¶ä»–dataloaderé…ç½®ç±»ä¼¼MA-52 ...

# ========== ä¿®æ”¹5: è®­ç»ƒé…ç½® ==========
train_cfg = dict(
    type='EpochBasedTrainLoop', max_epochs=30, val_begin=3, val_interval=1)

optim_wrapper = dict(
    optimizer=dict(type='SGD', lr=0.0075, momentum=0.9, weight_decay=0.0001),
    clip_grad=dict(max_norm=40, norm_type=2))

# ========== é‡è¦ï¼šå»æ‰load_fromæˆ–æŒ‡å‘NTUçš„initæƒé‡ ==========
load_from = None  # æˆ–æŒ‡å‘NTU-60çš„åˆå§‹åŒ–æƒé‡
```

```python
def fine2coarse_ntu60(x):
    """
    ä¸ºNTU-60åˆ›å»ºè™šæ‹Ÿçš„ç²—åˆ†ç±»
    æ–¹æ¡ˆ1ï¼šå…¨éƒ¨æ˜ å°„åˆ°ç±»åˆ«0ï¼ˆæœ€ç®€å•ï¼‰
    """
    return 0

# æˆ–è€…æ ¹æ®NTU-60çš„è¯­ä¹‰å®šä¹‰8ä¸ªç²—ç±»
def fine2coarse_ntu60_semantic(x):
    """
    åŸºäºNTU-60åŠ¨ä½œè¯­ä¹‰çš„ç²—åˆ†ç±»
    """
    if 0 <= x <= 7:
        return 0  # Hand-arm movements
    elif 8 <= x <= 15:
        return 1  # Two-hand movements
    elif 16 <= x <= 25:
        return 2  # Interaction
    elif 26 <= x <= 31:
        return 3  # Body movements
    elif 32 <= x <= 39:
        return 4  # Pick/throw
    elif 40 <= x <= 49:
        return 5  # Health-related
    elif 50 <= x <= 56:
        return 6  # Common actions
    else:
        return 7  # Other

@MODELS.register_module()
class MMRecognizer3D(BaseRecognizer):
    def extract_feat(self, inputs, ...):
        # ... existing code ...
        
        gts = []
        for data in data_samples:
            gts.extend(data.gt_labels.item)
        gts = torch.stack(gts)
        temp = gts.cpu().numpy()
        
        # â† ä¿®æ”¹è¿™é‡Œï¼šæ ¹æ®æ•°æ®é›†é€‰æ‹©æ˜ å°„å‡½æ•°
        if self.cls_head.num_classes == 60:
            # NTU-60æ¨¡å¼
            gts_coarse = [fine2coarse_ntu60(i) for i in temp]
        else:
            # MA-52æ¨¡å¼
            gts_coarse = [fine2coarse(i) for i in temp]
        
        gts_coarse = torch.from_numpy(np.array(gts_coarse)).cuda()
        # ... rest of code ...
```

```python
class RenovateNet_Fine(nn.Module):
    def __init__(self, n_channel, n_class, alp=0.125, tmp=0.125, mom=0.9, 
                 h_channel=None, version='V0', pred_threshold=0.0, 
                 use_p_map=True, 
                 n_class_coarse=7):  # â† æ–°å¢å‚æ•°
        super(RenovateNet_Fine, self).__init__()
        self.n_channel = n_channel
        self.h_channel = n_channel if h_channel is None else h_channel
        self.n_class = n_class
        self.n_class_coarse = n_class_coarse  # â† ä½¿ç”¨ä¼ å…¥çš„å€¼
        # ... rest of code ...

# åœ¨RGBPoseHeadçš„__init__ä¸­ï¼š
class RGBPoseHead(BaseHead):
    def __init__(self, num_classes, in_channels, 
                 num_coarse_classes=7,  # â† æ–°å¢å‚æ•°
                 ...):
        # ...
        self.fc_rgb_coarse = nn.Linear(self.in_channels[0], num_coarse_classes)
        self.fc_pose_coarse = nn.Linear(self.in_channels[1], num_coarse_classes)
        
        self.fr_coarse_rgb = ST_RenovateNet(
            2048, 8, n_class=num_coarse_classes, h_channel=128)
        self.fr_coarse_pose = ST_RenovateNet(
            512, 32, n_class=num_coarse_classes, h_channel=128)
        
        self.fr_rgb = ST_RenovateNet_Fine(
            2048, n_class=num_classes, 
            n_class_coarse=num_coarse_classes)  # â† ä¼ é€’ç²—åˆ†ç±»æ•°
        # ... rest
```

```python
class TreeLoss(nn.Module):
    def __init__(self, num_actions=52, num_bodies=7, 
                 action2body_fn=None):  # â† æ–°å¢å‚æ•°
        super(TreeLoss, self).__init__()
        self.num_actions = num_actions
        self.num_bodies = num_bodies
        self.action2body_fn = action2body_fn or action2body
        self.stateSpace = self.generateStateSpace().cuda()
        self.sig = nn.Sigmoid()
    
    def generateStateSpace(self):
        stat_list = np.eye(self.num_bodies + self.num_actions)
        for i in range(self.num_bodies, self.num_bodies + self.num_actions):
            action_id = i - self.num_bodies
            coarse_id = self.action2body_fn(action_id)
            stat_list[i][coarse_id] = 1
        return torch.tensor(stat_list)
```

```python
# configs/skeleton/posec3d/rgbpose_conv3d/quick_ntu60.py
_base_ = './rgbpose_conv3d.py'

# æ ¸å¿ƒä¿®æ”¹
backbone_cfg = dict(
    pose_pathway=dict(in_channels=17))  # åªæ”¹éª¨æ¶ç‚¹æ•°

head_cfg = dict(
    num_classes=60)  # åªæ”¹ç±»åˆ«æ•°

model = dict(
    backbone=backbone_cfg,
    cls_head=head_cfg)

# æ•°æ®è·¯å¾„
data_root = 'data/nturgbd_videos/'
ann_file = 'data/skeleton/ntu60_2d.pkl'
ann_file_val = 'data/skeleton/ntu60_2d.pkl'
ann_file_test = 'data/skeleton/ntu60_2d.pkl'

left_kp = [1, 3, 5, 7, 9, 11, 13, 15]
right_kp = [2, 4, 6, 8, 10, 12, 14, 16]

# å»æ‰MA-52ç‰¹æœ‰çš„skeletonå®šä¹‰
train_pipeline = [
    dict(type='MMUniformSampleFrames', 
         clip_len=dict(RGB=8, Pose=32), num_clips=1),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(type='RandomResizedCrop', area_range=(0.56, 1.0)),
    dict(type='Resize', scale=(224, 224), keep_ratio=False),
    dict(type='Flip', flip_ratio=0.5, left_kp=left_kp, right_kp=right_kp),
    dict(type='GeneratePoseTarget', sigma=0.7, use_score=True,
         with_kp=True, with_limb=False, scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

# å…¶ä»–pipelineç±»ä¼¼...
```

```python
# åœ¨recognizer3d_mm.pyçš„fine2coarseå‡½æ•°ä¸­ï¼š
def fine2coarse(x):
    # Hack for NTU-60: å…¨éƒ¨æ˜ å°„åˆ°0
    if x < 60:  # NTU-60
        return 0
    # åŸMA-52é€»è¾‘
    elif x <= 4:
        return 0
    # ... rest
```

---

**User**

å…ˆç”¨æ–¹æ¡ˆBå§ ä¹Ÿå°±æ˜¯é€‚é…PCANåˆ°NTU-60ï¼ˆæ¨èæ–¹æ¡ˆï¼‰æˆ‘ç°åœ¨å·²ç»æœ‰ntud60-subçš„éª¨æ¶åºåˆ—ä»¥åŠrgbè§†é¢‘æ•°æ®äº†ï¼Œè¯·ä½ ç»™å‡ºæ­¥éª¤ æˆ‘ä¸€æ­¥ä¸€æ­¥æ¥

---

**Cursor**

å¥½çš„ï¼è®©æˆ‘å¸®ä½ å®Œæ•´åœ°é€‚é…PCANåˆ°NTU-60æ•°æ®é›†ã€‚é¦–å…ˆè®©æˆ‘æ£€æŸ¥ä¸€ä¸‹ä½ çš„æ•°æ®æ ¼å¼ã€‚

å®Œç¾ï¼è®©æˆ‘ç»™ä½ ä¸€ä¸ªå®Œæ•´çš„åˆ†æ­¥æŒ‡å—ï¼Œä»æ•°æ®å‡†å¤‡åˆ°è¿è¡Œæµ‹è¯•ã€‚

## ğŸš€ PCANé€‚é…NTU-60å®Œæ•´æŒ‡å—

### ğŸ“‹ å‡†å¤‡å·¥ä½œæ£€æŸ¥

é¦–å…ˆç¡®è®¤ä½ çš„æ•°æ®ä½ç½®ï¼š

```bash
# åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œ
cd /home/zh/ChCode/codes01/mmaction2

# æ£€æŸ¥ä½ çš„NTU-60æ•°æ®åœ¨å“ªé‡Œ
# é€šå¸¸åº”è¯¥åœ¨ï¼š
ls -lh <ä½ çš„NTU60æ•°æ®è·¯å¾„>/
```

è¯·å‘Šè¯‰æˆ‘ä½ çš„NTU-60æ•°æ®çš„å…·ä½“æ ¼å¼ï¼š
1. **éª¨æ¶æ•°æ®**ï¼šæ˜¯`.skeleton`åŸå§‹æ–‡ä»¶ï¼Ÿè¿˜æ˜¯å·²ç»æ˜¯`.pkl`æ ¼å¼ï¼Ÿ
2. **RGBè§†é¢‘**ï¼šæ˜¯`.avi`åŸå§‹æ–‡ä»¶ï¼Ÿè¿˜æ˜¯å·²å‹ç¼©çš„`.mp4`ï¼Ÿ
3. **æ•°æ®è·¯å¾„**ï¼šå…·ä½“åœ¨å“ªä¸ªç›®å½•ï¼Ÿ

---

## ğŸ“ æ­¥éª¤1ï¼šåˆ›å»ºæ•°æ®ç›®å½•ç»“æ„

```bash
cd /home/zh/ChCode/codes01/mmaction2

# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p data/skeleton
mkdir -p data/nturgbd_raw      # åŸå§‹è§†é¢‘ï¼ˆå¦‚æœæœ‰ï¼‰
mkdir -p data/nturgbd_videos   # å¤„ç†åçš„è§†é¢‘
```

---

## ğŸ“ æ­¥éª¤2ï¼šå‡†å¤‡éª¨æ¶æ•°æ®

### æ–¹æ¡ˆAï¼šå¦‚æœä½ æœ‰`.skeleton`åŸå§‹æ–‡ä»¶

```bash
# å°†åŸå§‹éª¨æ¶æ–‡ä»¶æ”¾åˆ°ä¸€ä¸ªç›®å½•
# ä¾‹å¦‚ï¼šdata/ntu60_raw_skeletons/

# è¿è¡Œè½¬æ¢è„šæœ¬ï¼ˆç”Ÿæˆ25ç‚¹çš„3Déª¨æ¶ï¼‰
python tools/data/skeleton/gen_ntu_rgbd_raw.py \
    --data-path <ä½ çš„éª¨æ¶æ–‡ä»¶è·¯å¾„> \
    --ignored-sample-path tools/data/skeleton/NTU_RGBD_samples_with_missing_skeletons.txt \
    --out-folder data/skeleton/ \
    --task ntu60

# è¿™ä¼šç”Ÿæˆï¼šdata/skeleton/ntu60_3d.pklï¼ˆ25ä¸ª3Då…³é”®ç‚¹ï¼‰
```

### æ–¹æ¡ˆBï¼šå¦‚æœä½ å·²æœ‰`.pkl`æ–‡ä»¶

```bash
# ç›´æ¥å¤åˆ¶åˆ°data/skeleton/
cp <ä½ çš„pklè·¯å¾„>/ntu60_*.pkl data/skeleton/

# æ£€æŸ¥æ ¼å¼
python << 'EOF'
import pickle
with open('data/skeleton/ntu60_3d.pkl', 'rb') as f:
    data = pickle.load(f)
    print(f"Keys: {data.keys()}")
    print(f"Splits: {data['split'].keys()}")
    print(f"Samples: {len(data['annotations'])}")
    sample = data['annotations'][0]
    print(f"Keypoint shape: {sample['keypoint'].shape}")  # åº”è¯¥æ˜¯[M, T, V, C]
    # M: äººæ•°, T: å¸§æ•°, V: å…³é”®ç‚¹æ•°(17æˆ–25), C: åæ ‡ç»´åº¦(2æˆ–3)
EOF
```

### æ–¹æ¡ˆCï¼šå¦‚æœåªæœ‰2Déª¨æ¶ï¼ˆ17ç‚¹ï¼‰

```bash
# ä¸‹è½½MMAction2æä¾›çš„é¢„å¤„ç†éª¨æ¶
cd data/skeleton
wget https://download.openmmlab.com/mmaction/v1.0/skeleton/data/ntu60_2d.pkl
# æˆ–
wget https://download.openmmlab.com/mmaction/v1.0/skeleton/data/ntu60_3d.pkl
```

---

## ğŸ“ æ­¥éª¤3ï¼šå‡†å¤‡RGBè§†é¢‘

### å¦‚æœæœ‰`.avi`åŸå§‹è§†é¢‘

```bash
# 1. æ”¾ç½®åŸå§‹è§†é¢‘
# å°†NTU-60çš„RGBè§†é¢‘æ”¾åˆ° data/nturgbd_raw/

# 2. å‹ç¼©è§†é¢‘ï¼ˆä»1920x1080é™åˆ°960x540ï¼Œè½¬mp4ï¼‰
python tools/data/skeleton/compress_nturgbd.py

# è¿™ä¼šç”Ÿæˆï¼šdata/nturgbd_videos/*.mp4
```

### å¦‚æœå·²æœ‰`.mp4`è§†é¢‘

```bash
# ç›´æ¥å¤åˆ¶åˆ°ç›®æ ‡ç›®å½•
cp -r <ä½ çš„è§†é¢‘è·¯å¾„>/*.mp4 data/nturgbd_videos/
```

### éªŒè¯è§†é¢‘å’Œéª¨æ¶å¯¹åº”

```bash
# æ£€æŸ¥è§†é¢‘æ•°é‡å’Œéª¨æ¶æ•°é‡æ˜¯å¦åŒ¹é…
python << 'EOF'
import pickle
import os

# æ£€æŸ¥éª¨æ¶
with open('data/skeleton/ntu60_3d.pkl', 'rb') as f:
    data = pickle.load(f)
    skeleton_names = [ann['frame_dir'] for ann in data['annotations']]
    print(f"éª¨æ¶æ ·æœ¬æ•°: {len(skeleton_names)}")
    print(f"ç¤ºä¾‹: {skeleton_names[0]}")  # ä¾‹å¦‚: S001C001P001R001A001

# æ£€æŸ¥è§†é¢‘
videos = os.listdir('data/nturgbd_videos/')
print(f"è§†é¢‘æ•°é‡: {len([v for v in videos if v.endswith('.mp4')])}")
print(f"ç¤ºä¾‹: {videos[0]}")

# æ£€æŸ¥æ˜¯å¦åŒ¹é…
sample_name = skeleton_names[0]
video_name = sample_name + '.mp4'
if video_name in videos:
    print(f"âœ“ è§†é¢‘å’Œéª¨æ¶åŒ¹é…ï¼")
else:
    print(f"âœ— è­¦å‘Šï¼š{video_name} ä¸å­˜åœ¨")
EOF
```

---

## ğŸ“ æ­¥éª¤4ï¼šç¡®å®šä½¿ç”¨çš„éª¨æ¶æ ¼å¼

æ ¹æ®ä½ çš„éª¨æ¶æ•°æ®ï¼Œé€‰æ‹©é…ç½®ï¼š

```bash
# æ£€æŸ¥éª¨æ¶ç‚¹æ•°
python << 'EOF'
import pickle
with open('data/skeleton/ntu60_3d.pkl', 'rb') as f:
    data = pickle.load(f)
    keypoint = data['annotations'][0]['keypoint']
    print(f"Keypoint shape: {keypoint.shape}")
    # [M, T, V, C]
    # V=17 â†’ ä½¿ç”¨2Déª¨æ¶ï¼ˆCOCOæ ¼å¼ï¼‰
    # V=25 â†’ ä½¿ç”¨3Déª¨æ¶ï¼ˆKinectæ ¼å¼ï¼‰
EOF
```

**è®°ä½è¿™ä¸ªæ•°å­—**ï¼ˆVçš„å€¼ï¼‰ï¼Œåé¢é…ç½®ä¼šç”¨åˆ°ï¼

---

## ğŸ“ æ­¥éª¤5ï¼šåˆ›å»ºNTU-60é…ç½®æ–‡ä»¶

åœ¨ `configs/skeleton/posec3d/rgbpose_conv3d/` ç›®å½•ä¸‹åˆ›å»º `pcan_ntu60.py`ï¼š

```python
_base_ = '../../../_base_/default_runtime.py'

# ==========================================
# æ¨¡å‹é…ç½®
# ==========================================
backbone_cfg = dict(
    type='RGBPoseConv3D',
    speed_ratio=4,
    channel_ratio=4,
    rgb_pathway=dict(
        num_stages=4,
        lateral=True,
        lateral_infl=1,
        lateral_activate=[0, 0, 1, 1],
        fusion_kernel=7,
        base_channels=64,
        conv1_kernel=(1, 7, 7),
        inflate=(0, 0, 1, 1),
        with_pool2=False),
    pose_pathway=dict(
        num_stages=3,
        stage_blocks=(4, 6, 3),
        lateral=True,
        lateral_inv=True,
        lateral_infl=16,
        lateral_activate=(0, 1, 1),
        fusion_kernel=7,
        in_channels=17,  # â† å¦‚æœæ˜¯2Déª¨æ¶ç”¨17ï¼Œ3Déª¨æ¶ç”¨25
        base_channels=32,
        out_indices=(2, ),
        conv1_kernel=(1, 7, 7),
        conv1_stride_s=1,
        conv1_stride_t=1,
        pool1_stride_s=1,
        pool1_stride_t=1,
        inflate=(0, 1, 1),
        spatial_strides=(2, 2, 2),
        temporal_strides=(1, 1, 1),
        dilations=(1, 1, 1),
        with_pool2=False))

head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,  # â† NTU-60çš„60ç±»
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose'],  # â† åªç”¨rgbå’Œposeï¼Œå»æ‰coarse
    loss_weights=[1., 1.],
    average_clips='prob')

data_preprocessor = dict(
    type='MultiModalDataPreprocessor',
    preprocessors=dict(
        imgs=dict(
            type='ActionDataPreprocessor',
            mean=[123.675, 116.28, 103.53],
            std=[58.395, 57.12, 57.375],
            format_shape='NCTHW'),
        heatmap_imgs=dict(type='ActionDataPreprocessor')))

model = dict(
    type='MMRecognizer3D',
    backbone=backbone_cfg,
    cls_head=head_cfg,
    data_preprocessor=data_preprocessor)

# ==========================================
# æ•°æ®é…ç½®
# ==========================================
dataset_type = 'PoseDataset'
data_root = './data/nturgbd_videos/'
ann_file = './data/skeleton/ntu60_3d.pkl'  # æˆ– ntu60_2d.pkl
ann_file_val = './data/skeleton/ntu60_3d.pkl'
ann_file_test = './data/skeleton/ntu60_3d.pkl'

# NTU-60çš„å·¦å³å…³é”®ç‚¹ï¼ˆ17ç‚¹-2Déª¨æ¶ï¼‰
left_kp = [1, 3, 5, 7, 9, 11, 13, 15]
right_kp = [2, 4, 6, 8, 10, 12, 14, 16]

# å¦‚æœæ˜¯25ç‚¹-3Déª¨æ¶ï¼Œä½¿ç”¨ï¼š
# left_kp = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23]
# right_kp = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]

train_pipeline = [
    dict(
        type='MMUniformSampleFrames',
        clip_len=dict(RGB=8, Pose=32),
        num_clips=1),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(type='RandomResizedCrop', area_range=(0.56, 1.0)),
    dict(type='Resize', scale=(224, 224), keep_ratio=False),
    dict(type='Flip', flip_ratio=0.5, left_kp=left_kp, right_kp=right_kp),
    dict(
        type='GeneratePoseTarget',
        sigma=0.7,
        use_score=True,
        with_kp=True,
        with_limb=False,
        scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

val_pipeline = [
    dict(
        type='MMUniformSampleFrames',
        clip_len=dict(RGB=8, Pose=32),
        num_clips=1,
        test_mode=True),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(
        type='GeneratePoseTarget',
        sigma=0.7,
        use_score=True,
        with_kp=True,
        with_limb=False,
        scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

test_pipeline = [
    dict(
        type='MMUniformSampleFrames',
        clip_len=dict(RGB=8, Pose=32),
        num_clips=10,  # å¤šclipæµ‹è¯•
        test_mode=True),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(
        type='GeneratePoseTarget',
        sigma=0.7,
        use_score=True,
        with_kp=True,
        with_limb=False,
        scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

train_dataloader = dict(
    batch_size=10,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=True),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file,
        data_prefix=dict(video=data_root),
        split='xsub_train',  # â† NTU-60çš„split
        pipeline=train_pipeline))

val_dataloader = dict(
    batch_size=1,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_val,
        data_prefix=dict(video=data_root),
        split='xsub_val',
        pipeline=val_pipeline,
        test_mode=True))

test_dataloader = dict(
    batch_size=1,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_test,
        data_prefix=dict(video=data_root),
        split='xsub_val',
        pipeline=test_pipeline,
        test_mode=True))

val_evaluator = [dict(type='AccMetric')]
test_evaluator = val_evaluator

# ==========================================
# è®­ç»ƒé…ç½®
# ==========================================
train_cfg = dict(
    type='EpochBasedTrainLoop', max_epochs=30, val_begin=3, val_interval=1)
val_cfg = dict(type='ValLoop')
test_cfg = dict(type='TestLoop')

optim_wrapper = dict(
    optimizer=dict(type='SGD', lr=0.0075, momentum=0.9, weight_decay=0.0001),
    clip_grad=dict(max_norm=40, norm_type=2))

param_scheduler = [
    dict(
        type='MultiStepLR',
        begin=0,
        end=30,
        by_epoch=True,
        milestones=[10, 20],
        gamma=0.1)
]

load_from = None  # åˆå§‹è®¾ç½®ä¸ºNoneï¼Œç¨åæŒ‡å®šé¢„è®­ç»ƒæƒé‡

auto_scale_lr = dict(enable=False, base_batch_size=40)
```

**ä¿å­˜ä¸º**ï¼š`configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py`

---

## ğŸ“ æ­¥éª¤6ï¼šä¿®æ”¹ä»£ç ä»¥æ”¯æŒNTU-60ï¼ˆå…³é”®ï¼ï¼‰

### ä¿®æ”¹1ï¼š`mmaction/models/recognizers/recognizer3d_mm.py`

åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ NTU-60çš„ç²—åˆ†ç±»æ˜ å°„ï¼š

```python
# ç¬¬10è¡Œä¹‹åæ·»åŠ 
def fine2coarse(x):
    # MA-52çš„æ˜ å°„ï¼ˆä¿æŒä¸å˜ï¼‰
    if x<=4:
        return 0
    elif 5<=x<=10:
        return 1
    elif 11<=x<=23:
        return 2
    elif 24<=x<=31:
        return 3
    elif 32<=x<=37:
        return 4
    elif 38<=x<=47:
        return 5
    else:
        return 6

def fine2coarse_ntu60(x):
    """
    NTU-60çš„è™šæ‹Ÿç²—åˆ†ç±»æ˜ å°„
    æ–¹æ¡ˆ1ï¼šå…¨éƒ¨æ˜ å°„åˆ°ç±»åˆ«0ï¼ˆæœ€ç®€å•ï¼Œä½†å¤±å»å±‚æ¬¡ä¿¡æ¯ï¼‰
    """
    return 0

# æˆ–è€…ä½¿ç”¨è¯­ä¹‰åˆ†ç»„ï¼ˆæ›´å¥½ï¼‰ï¼š
def fine2coarse_ntu60_semantic(x):
    """
    åŸºäºNTU-60åŠ¨ä½œè¯­ä¹‰çš„8ç±»ç²—åˆ†ç±»
    """
    if 0 <= x <= 9:
        return 0  # Drink, eat, brushing, reading (10ä¸ªåŠ¨ä½œ)
    elif 10 <= x <= 19:
        return 1  # Hand clapping, phone, camera (10ä¸ª)
    elif 20 <= x <= 29:
        return 2  # Pickup, throw, sitting (10ä¸ª)
    elif 30 <= x <= 39:
        return 3  # Standing, falling, kicking (10ä¸ª)
    elif 40 <= x <= 44:
        return 4  # Punching, pushing, hugging (5ä¸ª)
    elif 45 <= x <= 49:
        return 5  # Giving, handshaking (5ä¸ª)
    elif 50 <= x <= 54:
        return 6  # Touch pocket, sneeze, staggering (5ä¸ª)
    else:
        return 7  # Other (å‰©ä½™)
```

ç„¶åä¿®æ”¹`extract_feat`æ–¹æ³•ï¼ˆç¬¬56-65è¡Œï¼‰ï¼š

```python
# åŸä»£ç ï¼š
gts = []
for data in data_samples:
    gts.extend(data.gt_labels.item)
gts = torch.stack(gts)
temp = gts.cpu().numpy()
gts_coarse = [fine2coarse(i) for i in temp]  # â† è¿™é‡Œ
gts_coarse = torch.from_numpy(np.array(gts_coarse)).cuda()

# ä¿®æ”¹ä¸ºï¼š
gts = []
for data in data_samples:
    gts.extend(data.gt_labels.item)
gts = torch.stack(gts)
temp = gts.cpu().numpy()

# æ ¹æ®ç±»åˆ«æ•°åˆ¤æ–­æ•°æ®é›†
max_label = temp.max()
if max_label >= 52:  # NTU-60 (æ ‡ç­¾0-59)
    gts_coarse = [fine2coarse_ntu60_semantic(i) for i in temp]
else:  # MA-52 (æ ‡ç­¾0-51)
    gts_coarse = [fine2coarse(i) for i in temp]

gts_coarse = torch.from_numpy(np.array(gts_coarse)).cuda()
```

### ä¿®æ”¹2ï¼š`mmaction/models/heads/rgbpose_head.py`

ä¿®æ”¹`RenovateNet_Fine`æ”¯æŒä¸åŒçš„ç²—åˆ†ç±»æ•°ï¼ˆç¬¬68-89è¡Œï¼‰ï¼š

```python
class RenovateNet_Fine(nn.Module):
    def __init__(self, n_channel, n_class, alp=0.125, tmp=0.125, mom=0.9, 
                 h_channel=None, version='V0', pred_threshold=0.0, 
                 use_p_map=True,
                 n_class_coarse=7):  # â† æ·»åŠ è¿™ä¸ªå‚æ•°ï¼Œé»˜è®¤7
        super(RenovateNet_Fine, self).__init__()
        self.n_channel = n_channel
        self.h_channel = n_channel if h_channel is None else h_channel
        self.n_class = n_class
        self.n_class_coarse = n_class_coarse  # â† æ”¹ï¼šä½¿ç”¨ä¼ å…¥çš„å€¼
        # ... å…¶ä½™ä»£ç ä¿æŒä¸å˜
```

ä¿®æ”¹`RGBPoseHead`çš„åˆå§‹åŒ–ï¼ˆç¬¬548-567è¡Œï¼‰ï¼š

```python
# åœ¨__init__å‚æ•°ä¸­æ·»åŠ ï¼š
def __init__(self,
             num_classes: int,
             in_channels: Tuple[int],
             loss_cls: Dict = dict(type='CrossEntropyLoss'),
             loss_components: List[str] = ['rgb', 'pose'],
             loss_weights: Union[float, Tuple[float]] = 1.,
             dropout: float = 0.5,
             init_std: float = 0.01,
             num_coarse_classes: int = 7,  # â† æ·»åŠ è¿™ä¸ªå‚æ•°
             **kwargs) -> None:
    
    super().__init__(num_classes, in_channels, loss_cls, **kwargs)
    # ... existing code ...
    
    # ä¿®æ”¹è¿™äº›è¡Œï¼š
    self.fc_rgb_coarse = nn.Linear(self.in_channels[0], num_coarse_classes)
    self.fc_pose_coarse = nn.Linear(self.in_channels[1], num_coarse_classes)
    
    self.fr_coarse_rgb = ST_RenovateNet(
        2048, 8, n_class=num_coarse_classes, h_channel=128, version='V0', use_p_map=True)
    self.fr_coarse_pose = ST_RenovateNet(
        512, 32, n_class=num_coarse_classes, h_channel=128, version='V0', use_p_map=True)
    
    self.fr_rgb = ST_RenovateNet_Fine(
        2048, n_class=num_classes, version='V0', use_p_map=True,
        n_class_coarse=num_coarse_classes)  # â† ä¼ é€’ç²—åˆ†ç±»æ•°
    self.fr_pose = ST_RenovateNet_Fine(
        512, n_class=num_classes, version='V0', use_p_map=True,
        n_class_coarse=num_coarse_classes)  # â† ä¼ é€’ç²—åˆ†ç±»æ•°
    
    self.tree_loss_rgb = TreeLoss()
    self.tree_loss_pose = TreeLoss()
```

### ä¿®æ”¹3ï¼š`TreeLoss`é€‚é…ï¼ˆç¬¬35-64è¡Œï¼‰

```python
class TreeLoss(nn.Module):
    def __init__(self, num_actions=52, num_bodies=7):  # â† æ·»åŠ å‚æ•°
        super(TreeLoss, self).__init__()
        self.num_actions = num_actions
        self.num_bodies = num_bodies
        self.stateSpace = self.generateStateSpace().cuda()
        self.sig = nn.Sigmoid()

    def generateStateSpace(self):
        total_size = self.num_bodies + self.num_actions
        stat_list = np.eye(total_size)
        
        for i in range(self.num_bodies, total_size):
            temp = stat_list[i]
            index = np.where(temp > 0)[0]
            action_id = int(index) - self.num_bodies
            
            # æ ¹æ®åŠ¨ä½œæ•°åˆ¤æ–­ä½¿ç”¨å“ªä¸ªæ˜ å°„
            if self.num_actions == 60:
                coarse = fine2coarse_ntu60_semantic(action_id)
            else:
                coarse = action2body(action_id)
            
            stat_list[i][coarse] = 1
        stateSpace = torch.tensor(stat_list)
        return stateSpace
```

ç„¶ååœ¨`RGBPoseHead.__init__`ä¸­ä¼ é€’å‚æ•°ï¼š

```python
self.tree_loss_rgb = TreeLoss(
    num_actions=num_classes, 
    num_bodies=num_coarse_classes)
self.tree_loss_pose = TreeLoss(
    num_actions=num_classes, 
    num_bodies=num_coarse_classes)
```

---

## ğŸ“ æ­¥éª¤7ï¼šæ›´æ–°é…ç½®æ–‡ä»¶ä¼ é€’ç²—åˆ†ç±»æ•°

å›åˆ° `pcan_ntu60.py`ï¼Œæ›´æ–°headé…ç½®ï¼š

```python
head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,
    num_coarse_classes=8,  # â† æ·»åŠ ï¼šNTU-60ä½¿ç”¨8ä¸ªç²—ç±»
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose', 'rgb_coarse', 'pose_coarse'],  # â† æ”¹å›æ¥
    loss_weights=[1., 1., 0.5, 0.5],  # â† æ·»åŠ ç²—åˆ†ç±»æƒé‡
    average_clips='prob')
```

---

## ğŸ“ æ­¥éª¤8ï¼šéªŒè¯é…ç½®å’Œæ•°æ®

```bash
cd /home/zh/ChCode/codes01/mmaction2

# æ£€æŸ¥é…ç½®æ˜¯å¦æ­£ç¡®
python << 'EOF'
from mmengine.config import Config

cfg = Config.fromfile('configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py')
print("é…ç½®åŠ è½½æˆåŠŸï¼")
print(f"ç±»åˆ«æ•°: {cfg.model.cls_head.num_classes}")
print(f"éª¨æ¶ç‚¹æ•°: {cfg.model.backbone.pose_pathway.in_channels}")
print(f"æ•°æ®è·¯å¾„: {cfg.data_root}")
print(f"æ ‡æ³¨æ–‡ä»¶: {cfg.ann_file}")
EOF

# æµ‹è¯•æ•°æ®åŠ è½½
python tools/analysis_tools/browse_dataset.py \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    --mode pipeline \
    --show-number 1
```

---

## ğŸ“ æ­¥éª¤9ï¼šå‡†å¤‡é¢„è®­ç»ƒæƒé‡ï¼ˆå¯é€‰ä½†æ¨èï¼‰

### æ–¹æ¡ˆAï¼šä»å¤´è®­ç»ƒï¼ˆä¸æ¨èï¼‰

```bash
# ç›´æ¥è®­ç»ƒï¼Œä½†æ•ˆæœå¯èƒ½ä¸å¥½
bash tools/dist_train.sh \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    4
```

### æ–¹æ¡ˆBï¼šä½¿ç”¨NTU-60çš„é¢„è®­ç»ƒæƒé‡ï¼ˆæ¨èï¼‰

```bash
# 1. ä¸‹è½½NTU-60çš„RGB-onlyå’ŒPose-onlyé¢„è®­ç»ƒæƒé‡
mkdir -p pretrained/ntu60
cd pretrained/ntu60

# RGB-onlyé¢„è®­ç»ƒ
wget https://download.openmmlab.com/mmaction/v1.0/skeleton/posec3d/rgbpose_conv3d/rgb_only_20230228-576b9f86.pth

# Pose-onlyé¢„è®­ç»ƒ
wget https://download.openmmlab.com/mmaction/v1.0/skeleton/posec3d/rgbpose_conv3d/pose_only_20230228-fa40054e.pth

# 2. åˆå¹¶ä¸¤ä¸ªæƒé‡ï¼ˆå‚è€ƒMA-52çš„æ–¹æ³•ï¼‰
cd /home/zh/ChCode/codes01/mmaction2

python << 'EOF'
import torch

print("åˆå¹¶NTU-60çš„é¢„è®­ç»ƒæƒé‡...")

# åŠ è½½ä¸¤ä¸ªå•ç‹¬çš„æƒé‡
rgb_ckpt = torch.load('pretrained/ntu60/rgb_only_20230228-576b9f86.pth', 
                       map_location='cpu')
pose_ckpt = torch.load('pretrained/ntu60/pose_only_20230228-fa40054e.pth', 
                        map_location='cpu')

# åˆ›å»ºåˆå¹¶çš„æƒé‡
merged = {'state_dict': {}}

# æ·»åŠ RGBè·¯å¾„çš„æƒé‡
for key, value in rgb_ckpt['state_dict'].items():
    if 'backbone' in key:
        new_key = key.replace('backbone', 'backbone.rgb_path')
        merged['state_dict'][new_key] = value

# æ·»åŠ Poseè·¯å¾„çš„æƒé‡
for key, value in pose_ckpt['state_dict'].items():
    if 'backbone' in key:
        new_key = key.replace('backbone', 'backbone.pose_path')
        merged['state_dict'][new_key] = value

print(f"åˆå¹¶åçš„å‚æ•°æ•°é‡: {len(merged['state_dict'])}")

# ä¿å­˜
torch.save(merged, 'pretrained/ntu60/rgbpose_ntu60_init.pth')
print("âœ“ ä¿å­˜æˆåŠŸ: pretrained/ntu60/rgbpose_ntu60_init.pth")
EOF
```

### æ–¹æ¡ˆCï¼šè¿ç§»MA-52çš„æƒé‡ï¼ˆæ¬¡ä¼˜ï¼‰

```bash
# ä½¿ç”¨MA-52è®­ç»ƒå¥½çš„backboneï¼Œåªé‡æ–°è®­ç»ƒhead
# åœ¨é…ç½®æ–‡ä»¶ä¸­ï¼š
load_from = './pretrained/rgbpose_conv3d_init.pth'
# ä½†éœ€è¦æ‰‹åŠ¨è°ƒæ•´in_channelsï¼ˆ28â†’17/25ï¼‰
```

---

## ğŸ“ æ­¥éª¤10ï¼šæ›´æ–°é…ç½®æ–‡ä»¶çš„load_from

ä¿®æ”¹ `pcan_ntu60.py` çš„æœ€åï¼š

```python
# å¦‚æœæœ‰NTU-60çš„åˆå§‹åŒ–æƒé‡
load_from = './pretrained/ntu60/rgbpose_ntu60_init.pth'

# æˆ–è€…ä»å¤´è®­ç»ƒ
# load_from = None
```

---

## ğŸ“ æ­¥éª¤11ï¼šå¼€å§‹è®­ç»ƒï¼

```bash
cd /home/zh/ChCode/codes01/mmaction2

# ä½¿ç”¨4å¼ A100è®­ç»ƒ
bash tools/dist_train.sh \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    4

# è®­ç»ƒæ—¥å¿—ä¼šä¿å­˜åœ¨ work_dirs/pcan_ntu60/
```

---

## ğŸ“ æ­¥éª¤12ï¼šæµ‹è¯•å’Œè¯„ä¼°

```bash
# è®­ç»ƒå®Œæˆåæµ‹è¯•
bash tools/dist_test.sh \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    work_dirs/pcan_ntu60/best_acc_top1_epoch_*.pth \
    4

# æˆ–è€…ä½¿ç”¨å•GPUæµ‹è¯•
CUDA_VISIBLE_DEVICES=0 python tools/test.py \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    work_dirs/pcan_ntu60/best_acc_top1_epoch_*.pth
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜1ï¼š`TreeLoss`å°ºå¯¸ä¸åŒ¹é…

**æŠ¥é”™**ï¼š`RuntimeError: size mismatch, m1: [8, 67], m2: [59, ...]`

**è§£å†³**ï¼šç¡®ä¿`TreeLoss`æ­£ç¡®åˆå§‹åŒ–ï¼š

```python
# åœ¨RGBPoseHead.__init__ä¸­
self.tree_loss_rgb = TreeLoss(num_actions=60, num_bodies=8)
self.tree_loss_pose = TreeLoss(num_actions=60, num_bodies=8)
```

### é—®é¢˜2ï¼šæ‰¾ä¸åˆ°è§†é¢‘æ–‡ä»¶

**æŠ¥é”™**ï¼š`FileNotFoundError: S001C001P001R001A001.mp4`

**è§£å†³**ï¼šæ£€æŸ¥è§†é¢‘å‘½åï¼š

```bash
# NTU-60çš„æ ‡å‡†å‘½åï¼ˆä¸å¸¦åç¼€ï¼‰
ls data/nturgbd_videos/ | head -5
# åº”è¯¥çœ‹åˆ°ï¼šS001C001P001R001A001.mp4

# å¦‚æœpklä¸­æ˜¯ä¸å¸¦åç¼€çš„
# ä½†è§†é¢‘æ–‡ä»¶æ˜¯ .mp4
# ä»£ç ä¼šè‡ªåŠ¨æ·»åŠ  .mp4
```

### é—®é¢˜3ï¼šéª¨æ¶ç‚¹æ•°ä¸åŒ¹é…

**æŠ¥é”™**ï¼š`RuntimeError: Expected 28 channels, got 17`

**è§£å†³**ï¼šç¡®ä¿é…ç½®æ–‡ä»¶çš„`in_channels`ä¸å®é™…éª¨æ¶ç‚¹æ•°ä¸€è‡´ï¼š

```bash
# æ£€æŸ¥å®é™…éª¨æ¶ç‚¹æ•°
python << 'EOF'
import pickle
with open('data/skeleton/ntu60_3d.pkl', 'rb') as f:
    data = pickle.load(f)
    V = data['annotations'][0]['keypoint'].shape[2]
    print(f"éª¨æ¶ç‚¹æ•°: {V}")
    # V=17 â†’ é…ç½®ç”¨ in_channels=17
    # V=25 â†’ é…ç½®ç”¨ in_channels=25
EOF
```

---

## ğŸ“‹ å®Œæ•´çš„æ–‡ä»¶æ¸…å•

ä½ éœ€è¦åˆ›å»º/ä¿®æ”¹çš„æ–‡ä»¶ï¼š

```
mmaction2/
â”œâ”€â”€ configs/skeleton/posec3d/rgbpose_conv3d/
â”‚   â””â”€â”€ pcan_ntu60.py  â† æ–°å»ºé…ç½®æ–‡ä»¶
â”œâ”€â”€ mmaction/models/recognizers/
â”‚   â””â”€â”€ recognizer3d_mm.py  â† ä¿®æ”¹ï¼šæ·»åŠ fine2coarse_ntu60
â”œâ”€â”€ mmaction/models/heads/
â”‚   â””â”€â”€ rgbpose_head.py  â† ä¿®æ”¹ï¼šæ”¯æŒåŠ¨æ€ç²—åˆ†ç±»æ•°
â””â”€â”€ data/
    â”œâ”€â”€ skeleton/
    â”‚   â”œâ”€â”€ ntu60_2d.pkl  â† éª¨æ¶æ•°æ®ï¼ˆ17ç‚¹ï¼‰
    â”‚   â””â”€â”€ ntu60_3d.pkl  â† æˆ–3Déª¨æ¶ï¼ˆ25ç‚¹ï¼‰
    â””â”€â”€ nturgbd_videos/
        â””â”€â”€ *.mp4  â† RGBè§†é¢‘
```

---

## âœ… å¿«é€Ÿæ£€æŸ¥æ¸…å•

åœ¨å¼€å§‹è®­ç»ƒå‰ï¼Œç¡®è®¤ï¼š

- [ ] éª¨æ¶pklæ–‡ä»¶å­˜åœ¨ï¼š`data/skeleton/ntu60_*.pkl`
- [ ] RGBè§†é¢‘å­˜åœ¨ï¼š`data/nturgbd_videos/*.mp4`
- [ ] é…ç½®æ–‡ä»¶åˆ›å»ºï¼š`pcan_ntu60.py`
- [ ] ä»£ç å·²ä¿®æ”¹ï¼š`recognizer3d_mm.py`
- [ ] ä»£ç å·²ä¿®æ”¹ï¼š`rgbpose_head.py`ï¼ˆ3å¤„ï¼‰
- [ ] éª¨æ¶ç‚¹æ•°åŒ¹é…ï¼šé…ç½®ä¸­çš„`in_channels`=å®é™…ç‚¹æ•°
- [ ] ç±»åˆ«æ•°åŒ¹é…ï¼š`num_classes=60`
- [ ] ç²—åˆ†ç±»æ•°åŒ¹é…ï¼š`num_coarse_classes=8`ï¼ˆæˆ–1ï¼‰

---

## ğŸ’¡ å¦‚æœä½ ç°åœ¨å°±æƒ³å¼€å§‹

**æœ€å¿«çš„éªŒè¯æ­¥éª¤**ï¼š

```bash
# 1. å‘Šè¯‰æˆ‘ä½ çš„æ•°æ®æ ¼å¼
cd /home/zh/ChCode/codes01/mmaction2
ls data/skeleton/
ls data/nturgbd_videos/ | head -5

# 2. æ£€æŸ¥éª¨æ¶ç‚¹æ•°
python << 'EOF'
import pickle
with open('data/skeleton/ntu60_3d.pkl', 'rb') as f:
    data = pickle.load(f)
    print(f"éª¨æ¶ç‚¹æ•°V: {data['annotations'][0]['keypoint'].shape[2]}")
EOF
```

**æŠŠè¿™ä¸¤ä¸ªå‘½ä»¤çš„è¾“å‡ºå‘Šè¯‰æˆ‘**ï¼Œæˆ‘ä¼šæ ¹æ®ä½ çš„å®é™…æ•°æ®æ ¼å¼ï¼Œç»™å‡ºæœ€ç²¾ç¡®çš„é…ç½®ï¼

ä½ å‡†å¤‡å¥½å¼€å§‹äº†å—ï¼Ÿå…ˆç¡®è®¤ä½ çš„æ•°æ®æ ¼å¼ï¼Œç„¶åæˆ‘ä»¬ä¸€æ­¥æ­¥æ¥ï¼ğŸš€

```shellscript
# åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œ
cd /home/zh/ChCode/codes01/mmaction2

# æ£€æŸ¥ä½ çš„NTU-60æ•°æ®åœ¨å“ªé‡Œ
# é€šå¸¸åº”è¯¥åœ¨ï¼š
ls -lh <ä½ çš„NTU60æ•°æ®è·¯å¾„>/
```

```shellscript
cd /home/zh/ChCode/codes01/mmaction2

# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p data/skeleton
mkdir -p data/nturgbd_raw      # åŸå§‹è§†é¢‘ï¼ˆå¦‚æœæœ‰ï¼‰
mkdir -p data/nturgbd_videos   # å¤„ç†åçš„è§†é¢‘
```

```shellscript
# å°†åŸå§‹éª¨æ¶æ–‡ä»¶æ”¾åˆ°ä¸€ä¸ªç›®å½•
# ä¾‹å¦‚ï¼šdata/ntu60_raw_skeletons/

# è¿è¡Œè½¬æ¢è„šæœ¬ï¼ˆç”Ÿæˆ25ç‚¹çš„3Déª¨æ¶ï¼‰
python tools/data/skeleton/gen_ntu_rgbd_raw.py \
    --data-path <ä½ çš„éª¨æ¶æ–‡ä»¶è·¯å¾„> \
    --ignored-sample-path tools/data/skeleton/NTU_RGBD_samples_with_missing_skeletons.txt \
    --out-folder data/skeleton/ \
    --task ntu60

# è¿™ä¼šç”Ÿæˆï¼šdata/skeleton/ntu60_3d.pklï¼ˆ25ä¸ª3Då…³é”®ç‚¹ï¼‰
```

```shellscript
# ç›´æ¥å¤åˆ¶åˆ°data/skeleton/
cp <ä½ çš„pklè·¯å¾„>/ntu60_*.pkl data/skeleton/

# æ£€æŸ¥æ ¼å¼
python << 'EOF'
import pickle
with open('data/skeleton/ntu60_3d.pkl', 'rb') as f:
    data = pickle.load(f)
    print(f"Keys: {data.keys()}")
    print(f"Splits: {data['split'].keys()}")
    print(f"Samples: {len(data['annotations'])}")
    sample = data['annotations'][0]
    print(f"Keypoint shape: {sample['keypoint'].shape}")  # åº”è¯¥æ˜¯[M, T, V, C]
    # M: äººæ•°, T: å¸§æ•°, V: å…³é”®ç‚¹æ•°(17æˆ–25), C: åæ ‡ç»´åº¦(2æˆ–3)
EOF
```

```shellscript
# ä¸‹è½½MMAction2æä¾›çš„é¢„å¤„ç†éª¨æ¶
cd data/skeleton
wget https://download.openmmlab.com/mmaction/v1.0/skeleton/data/ntu60_2d.pkl
# æˆ–
wget https://download.openmmlab.com/mmaction/v1.0/skeleton/data/ntu60_3d.pkl
```

```shellscript
# 1. æ”¾ç½®åŸå§‹è§†é¢‘
# å°†NTU-60çš„RGBè§†é¢‘æ”¾åˆ° data/nturgbd_raw/

# 2. å‹ç¼©è§†é¢‘ï¼ˆä»1920x1080é™åˆ°960x540ï¼Œè½¬mp4ï¼‰
python tools/data/skeleton/compress_nturgbd.py

# è¿™ä¼šç”Ÿæˆï¼šdata/nturgbd_videos/*.mp4
```

```shellscript
# ç›´æ¥å¤åˆ¶åˆ°ç›®æ ‡ç›®å½•
cp -r <ä½ çš„è§†é¢‘è·¯å¾„>/*.mp4 data/nturgbd_videos/
```

```shellscript
# æ£€æŸ¥è§†é¢‘æ•°é‡å’Œéª¨æ¶æ•°é‡æ˜¯å¦åŒ¹é…
python << 'EOF'
import pickle
import os

# æ£€æŸ¥éª¨æ¶
with open('data/skeleton/ntu60_3d.pkl', 'rb') as f:
    data = pickle.load(f)
    skeleton_names = [ann['frame_dir'] for ann in data['annotations']]
    print(f"éª¨æ¶æ ·æœ¬æ•°: {len(skeleton_names)}")
    print(f"ç¤ºä¾‹: {skeleton_names[0]}")  # ä¾‹å¦‚: S001C001P001R001A001

# æ£€æŸ¥è§†é¢‘
videos = os.listdir('data/nturgbd_videos/')
print(f"è§†é¢‘æ•°é‡: {len([v for v in videos if v.endswith('.mp4')])}")
print(f"ç¤ºä¾‹: {videos[0]}")

# æ£€æŸ¥æ˜¯å¦åŒ¹é…
sample_name = skeleton_names[0]
video_name = sample_name + '.mp4'
if video_name in videos:
    print(f"âœ“ è§†é¢‘å’Œéª¨æ¶åŒ¹é…ï¼")
else:
    print(f"âœ— è­¦å‘Šï¼š{video_name} ä¸å­˜åœ¨")
EOF
```

```shellscript
# æ£€æŸ¥éª¨æ¶ç‚¹æ•°
python << 'EOF'
import pickle
with open('data/skeleton/ntu60_3d.pkl', 'rb') as f:
    data = pickle.load(f)
    keypoint = data['annotations'][0]['keypoint']
    print(f"Keypoint shape: {keypoint.shape}")
    # [M, T, V, C]
    # V=17 â†’ ä½¿ç”¨2Déª¨æ¶ï¼ˆCOCOæ ¼å¼ï¼‰
    # V=25 â†’ ä½¿ç”¨3Déª¨æ¶ï¼ˆKinectæ ¼å¼ï¼‰
EOF
```

```python
_base_ = '../../../_base_/default_runtime.py'

# ==========================================
# æ¨¡å‹é…ç½®
# ==========================================
backbone_cfg = dict(
    type='RGBPoseConv3D',
    speed_ratio=4,
    channel_ratio=4,
    rgb_pathway=dict(
        num_stages=4,
        lateral=True,
        lateral_infl=1,
        lateral_activate=[0, 0, 1, 1],
        fusion_kernel=7,
        base_channels=64,
        conv1_kernel=(1, 7, 7),
        inflate=(0, 0, 1, 1),
        with_pool2=False),
    pose_pathway=dict(
        num_stages=3,
        stage_blocks=(4, 6, 3),
        lateral=True,
        lateral_inv=True,
        lateral_infl=16,
        lateral_activate=(0, 1, 1),
        fusion_kernel=7,
        in_channels=17,  # â† å¦‚æœæ˜¯2Déª¨æ¶ç”¨17ï¼Œ3Déª¨æ¶ç”¨25
        base_channels=32,
        out_indices=(2, ),
        conv1_kernel=(1, 7, 7),
        conv1_stride_s=1,
        conv1_stride_t=1,
        pool1_stride_s=1,
        pool1_stride_t=1,
        inflate=(0, 1, 1),
        spatial_strides=(2, 2, 2),
        temporal_strides=(1, 1, 1),
        dilations=(1, 1, 1),
        with_pool2=False))

head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,  # â† NTU-60çš„60ç±»
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose'],  # â† åªç”¨rgbå’Œposeï¼Œå»æ‰coarse
    loss_weights=[1., 1.],
    average_clips='prob')

data_preprocessor = dict(
    type='MultiModalDataPreprocessor',
    preprocessors=dict(
        imgs=dict(
            type='ActionDataPreprocessor',
            mean=[123.675, 116.28, 103.53],
            std=[58.395, 57.12, 57.375],
            format_shape='NCTHW'),
        heatmap_imgs=dict(type='ActionDataPreprocessor')))

model = dict(
    type='MMRecognizer3D',
    backbone=backbone_cfg,
    cls_head=head_cfg,
    data_preprocessor=data_preprocessor)

# ==========================================
# æ•°æ®é…ç½®
# ==========================================
dataset_type = 'PoseDataset'
data_root = './data/nturgbd_videos/'
ann_file = './data/skeleton/ntu60_3d.pkl'  # æˆ– ntu60_2d.pkl
ann_file_val = './data/skeleton/ntu60_3d.pkl'
ann_file_test = './data/skeleton/ntu60_3d.pkl'

# NTU-60çš„å·¦å³å…³é”®ç‚¹ï¼ˆ17ç‚¹-2Déª¨æ¶ï¼‰
left_kp = [1, 3, 5, 7, 9, 11, 13, 15]
right_kp = [2, 4, 6, 8, 10, 12, 14, 16]

# å¦‚æœæ˜¯25ç‚¹-3Déª¨æ¶ï¼Œä½¿ç”¨ï¼š
# left_kp = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23]
# right_kp = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]

train_pipeline = [
    dict(
        type='MMUniformSampleFrames',
        clip_len=dict(RGB=8, Pose=32),
        num_clips=1),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(type='RandomResizedCrop', area_range=(0.56, 1.0)),
    dict(type='Resize', scale=(224, 224), keep_ratio=False),
    dict(type='Flip', flip_ratio=0.5, left_kp=left_kp, right_kp=right_kp),
    dict(
        type='GeneratePoseTarget',
        sigma=0.7,
        use_score=True,
        with_kp=True,
        with_limb=False,
        scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

val_pipeline = [
    dict(
        type='MMUniformSampleFrames',
        clip_len=dict(RGB=8, Pose=32),
        num_clips=1,
        test_mode=True),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(
        type='GeneratePoseTarget',
        sigma=0.7,
        use_score=True,
        with_kp=True,
        with_limb=False,
        scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

test_pipeline = [
    dict(
        type='MMUniformSampleFrames',
        clip_len=dict(RGB=8, Pose=32),
        num_clips=10,  # å¤šclipæµ‹è¯•
        test_mode=True),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(
        type='GeneratePoseTarget',
        sigma=0.7,
        use_score=True,
        with_kp=True,
        with_limb=False,
        scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

train_dataloader = dict(
    batch_size=10,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=True),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file,
        data_prefix=dict(video=data_root),
        split='xsub_train',  # â† NTU-60çš„split
        pipeline=train_pipeline))

val_dataloader = dict(
    batch_size=1,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_val,
        data_prefix=dict(video=data_root),
        split='xsub_val',
        pipeline=val_pipeline,
        test_mode=True))

test_dataloader = dict(
    batch_size=1,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_test,
        data_prefix=dict(video=data_root),
        split='xsub_val',
        pipeline=test_pipeline,
        test_mode=True))

val_evaluator = [dict(type='AccMetric')]
test_evaluator = val_evaluator

# ==========================================
# è®­ç»ƒé…ç½®
# ==========================================
train_cfg = dict(
    type='EpochBasedTrainLoop', max_epochs=30, val_begin=3, val_interval=1)
val_cfg = dict(type='ValLoop')
test_cfg = dict(type='TestLoop')

optim_wrapper = dict(
    optimizer=dict(type='SGD', lr=0.0075, momentum=0.9, weight_decay=0.0001),
    clip_grad=dict(max_norm=40, norm_type=2))

param_scheduler = [
    dict(
        type='MultiStepLR',
        begin=0,
        end=30,
        by_epoch=True,
        milestones=[10, 20],
        gamma=0.1)
]

load_from = None  # åˆå§‹è®¾ç½®ä¸ºNoneï¼Œç¨åæŒ‡å®šé¢„è®­ç»ƒæƒé‡

auto_scale_lr = dict(enable=False, base_batch_size=40)
```

```python
# ç¬¬10è¡Œä¹‹åæ·»åŠ 
def fine2coarse(x):
    # MA-52çš„æ˜ å°„ï¼ˆä¿æŒä¸å˜ï¼‰
    if x<=4:
        return 0
    elif 5<=x<=10:
        return 1
    elif 11<=x<=23:
        return 2
    elif 24<=x<=31:
        return 3
    elif 32<=x<=37:
        return 4
    elif 38<=x<=47:
        return 5
    else:
        return 6

def fine2coarse_ntu60(x):
    """
    NTU-60çš„è™šæ‹Ÿç²—åˆ†ç±»æ˜ å°„
    æ–¹æ¡ˆ1ï¼šå…¨éƒ¨æ˜ å°„åˆ°ç±»åˆ«0ï¼ˆæœ€ç®€å•ï¼Œä½†å¤±å»å±‚æ¬¡ä¿¡æ¯ï¼‰
    """
    return 0

# æˆ–è€…ä½¿ç”¨è¯­ä¹‰åˆ†ç»„ï¼ˆæ›´å¥½ï¼‰ï¼š
def fine2coarse_ntu60_semantic(x):
    """
    åŸºäºNTU-60åŠ¨ä½œè¯­ä¹‰çš„8ç±»ç²—åˆ†ç±»
    """
    if 0 <= x <= 9:
        return 0  # Drink, eat, brushing, reading (10ä¸ªåŠ¨ä½œ)
    elif 10 <= x <= 19:
        return 1  # Hand clapping, phone, camera (10ä¸ª)
    elif 20 <= x <= 29:
        return 2  # Pickup, throw, sitting (10ä¸ª)
    elif 30 <= x <= 39:
        return 3  # Standing, falling, kicking (10ä¸ª)
    elif 40 <= x <= 44:
        return 4  # Punching, pushing, hugging (5ä¸ª)
    elif 45 <= x <= 49:
        return 5  # Giving, handshaking (5ä¸ª)
    elif 50 <= x <= 54:
        return 6  # Touch pocket, sneeze, staggering (5ä¸ª)
    else:
        return 7  # Other (å‰©ä½™)
```

```python
# åŸä»£ç ï¼š
gts = []
for data in data_samples:
    gts.extend(data.gt_labels.item)
gts = torch.stack(gts)
temp = gts.cpu().numpy()
gts_coarse = [fine2coarse(i) for i in temp]  # â† è¿™é‡Œ
gts_coarse = torch.from_numpy(np.array(gts_coarse)).cuda()

# ä¿®æ”¹ä¸ºï¼š
gts = []
for data in data_samples:
    gts.extend(data.gt_labels.item)
gts = torch.stack(gts)
temp = gts.cpu().numpy()

# æ ¹æ®ç±»åˆ«æ•°åˆ¤æ–­æ•°æ®é›†
max_label = temp.max()
if max_label >= 52:  # NTU-60 (æ ‡ç­¾0-59)
    gts_coarse = [fine2coarse_ntu60_semantic(i) for i in temp]
else:  # MA-52 (æ ‡ç­¾0-51)
    gts_coarse = [fine2coarse(i) for i in temp]

gts_coarse = torch.from_numpy(np.array(gts_coarse)).cuda()
```

```python
class RenovateNet_Fine(nn.Module):
    def __init__(self, n_channel, n_class, alp=0.125, tmp=0.125, mom=0.9, 
                 h_channel=None, version='V0', pred_threshold=0.0, 
                 use_p_map=True,
                 n_class_coarse=7):  # â† æ·»åŠ è¿™ä¸ªå‚æ•°ï¼Œé»˜è®¤7
        super(RenovateNet_Fine, self).__init__()
        self.n_channel = n_channel
        self.h_channel = n_channel if h_channel is None else h_channel
        self.n_class = n_class
        self.n_class_coarse = n_class_coarse  # â† æ”¹ï¼šä½¿ç”¨ä¼ å…¥çš„å€¼
        # ... å…¶ä½™ä»£ç ä¿æŒä¸å˜
```

```python
# åœ¨__init__å‚æ•°ä¸­æ·»åŠ ï¼š
def __init__(self,
             num_classes: int,
             in_channels: Tuple[int],
             loss_cls: Dict = dict(type='CrossEntropyLoss'),
             loss_components: List[str] = ['rgb', 'pose'],
             loss_weights: Union[float, Tuple[float]] = 1.,
             dropout: float = 0.5,
             init_std: float = 0.01,
             num_coarse_classes: int = 7,  # â† æ·»åŠ è¿™ä¸ªå‚æ•°
             **kwargs) -> None:
    
    super().__init__(num_classes, in_channels, loss_cls, **kwargs)
    # ... existing code ...
    
    # ä¿®æ”¹è¿™äº›è¡Œï¼š
    self.fc_rgb_coarse = nn.Linear(self.in_channels[0], num_coarse_classes)
    self.fc_pose_coarse = nn.Linear(self.in_channels[1], num_coarse_classes)
    
    self.fr_coarse_rgb = ST_RenovateNet(
        2048, 8, n_class=num_coarse_classes, h_channel=128, version='V0', use_p_map=True)
    self.fr_coarse_pose = ST_RenovateNet(
        512, 32, n_class=num_coarse_classes, h_channel=128, version='V0', use_p_map=True)
    
    self.fr_rgb = ST_RenovateNet_Fine(
        2048, n_class=num_classes, version='V0', use_p_map=True,
        n_class_coarse=num_coarse_classes)  # â† ä¼ é€’ç²—åˆ†ç±»æ•°
    self.fr_pose = ST_RenovateNet_Fine(
        512, n_class=num_classes, version='V0', use_p_map=True,
        n_class_coarse=num_coarse_classes)  # â† ä¼ é€’ç²—åˆ†ç±»æ•°
    
    self.tree_loss_rgb = TreeLoss()
    self.tree_loss_pose = TreeLoss()
```

```python
class TreeLoss(nn.Module):
    def __init__(self, num_actions=52, num_bodies=7):  # â† æ·»åŠ å‚æ•°
        super(TreeLoss, self).__init__()
        self.num_actions = num_actions
        self.num_bodies = num_bodies
        self.stateSpace = self.generateStateSpace().cuda()
        self.sig = nn.Sigmoid()

    def generateStateSpace(self):
        total_size = self.num_bodies + self.num_actions
        stat_list = np.eye(total_size)
        
        for i in range(self.num_bodies, total_size):
            temp = stat_list[i]
            index = np.where(temp > 0)[0]
            action_id = int(index) - self.num_bodies
            
            # æ ¹æ®åŠ¨ä½œæ•°åˆ¤æ–­ä½¿ç”¨å“ªä¸ªæ˜ å°„
            if self.num_actions == 60:
                coarse = fine2coarse_ntu60_semantic(action_id)
            else:
                coarse = action2body(action_id)
            
            stat_list[i][coarse] = 1
        stateSpace = torch.tensor(stat_list)
        return stateSpace
```

```python
self.tree_loss_rgb = TreeLoss(
    num_actions=num_classes, 
    num_bodies=num_coarse_classes)
self.tree_loss_pose = TreeLoss(
    num_actions=num_classes, 
    num_bodies=num_coarse_classes)
```

```python
head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,
    num_coarse_classes=8,  # â† æ·»åŠ ï¼šNTU-60ä½¿ç”¨8ä¸ªç²—ç±»
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose', 'rgb_coarse', 'pose_coarse'],  # â† æ”¹å›æ¥
    loss_weights=[1., 1., 0.5, 0.5],  # â† æ·»åŠ ç²—åˆ†ç±»æƒé‡
    average_clips='prob')
```

```shellscript
cd /home/zh/ChCode/codes01/mmaction2

# æ£€æŸ¥é…ç½®æ˜¯å¦æ­£ç¡®
python << 'EOF'
from mmengine.config import Config

cfg = Config.fromfile('configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py')
print("é…ç½®åŠ è½½æˆåŠŸï¼")
print(f"ç±»åˆ«æ•°: {cfg.model.cls_head.num_classes}")
print(f"éª¨æ¶ç‚¹æ•°: {cfg.model.backbone.pose_pathway.in_channels}")
print(f"æ•°æ®è·¯å¾„: {cfg.data_root}")
print(f"æ ‡æ³¨æ–‡ä»¶: {cfg.ann_file}")
EOF

# æµ‹è¯•æ•°æ®åŠ è½½
python tools/analysis_tools/browse_dataset.py \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    --mode pipeline \
    --show-number 1
```

```shellscript
# ç›´æ¥è®­ç»ƒï¼Œä½†æ•ˆæœå¯èƒ½ä¸å¥½
bash tools/dist_train.sh \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    4
```

```shellscript
# 1. ä¸‹è½½NTU-60çš„RGB-onlyå’ŒPose-onlyé¢„è®­ç»ƒæƒé‡
mkdir -p pretrained/ntu60
cd pretrained/ntu60

# RGB-onlyé¢„è®­ç»ƒ
wget https://download.openmmlab.com/mmaction/v1.0/skeleton/posec3d/rgbpose_conv3d/rgb_only_20230228-576b9f86.pth

# Pose-onlyé¢„è®­ç»ƒ
wget https://download.openmmlab.com/mmaction/v1.0/skeleton/posec3d/rgbpose_conv3d/pose_only_20230228-fa40054e.pth

# 2. åˆå¹¶ä¸¤ä¸ªæƒé‡ï¼ˆå‚è€ƒMA-52çš„æ–¹æ³•ï¼‰
cd /home/zh/ChCode/codes01/mmaction2

python << 'EOF'
import torch

print("åˆå¹¶NTU-60çš„é¢„è®­ç»ƒæƒé‡...")

# åŠ è½½ä¸¤ä¸ªå•ç‹¬çš„æƒé‡
rgb_ckpt = torch.load('pretrained/ntu60/rgb_only_20230228-576b9f86.pth', 
                       map_location='cpu')
pose_ckpt = torch.load('pretrained/ntu60/pose_only_20230228-fa40054e.pth', 
                        map_location='cpu')

# åˆ›å»ºåˆå¹¶çš„æƒé‡
merged = {'state_dict': {}}

# æ·»åŠ RGBè·¯å¾„çš„æƒé‡
for key, value in rgb_ckpt['state_dict'].items():
    if 'backbone' in key:
        new_key = key.replace('backbone', 'backbone.rgb_path')
        merged['state_dict'][new_key] = value

# æ·»åŠ Poseè·¯å¾„çš„æƒé‡
for key, value in pose_ckpt['state_dict'].items():
    if 'backbone' in key:
        new_key = key.replace('backbone', 'backbone.pose_path')
        merged['state_dict'][new_key] = value

print(f"åˆå¹¶åçš„å‚æ•°æ•°é‡: {len(merged['state_dict'])}")

# ä¿å­˜
torch.save(merged, 'pretrained/ntu60/rgbpose_ntu60_init.pth')
print("âœ“ ä¿å­˜æˆåŠŸ: pretrained/ntu60/rgbpose_ntu60_init.pth")
EOF
```

```shellscript
# ä½¿ç”¨MA-52è®­ç»ƒå¥½çš„backboneï¼Œåªé‡æ–°è®­ç»ƒhead
# åœ¨é…ç½®æ–‡ä»¶ä¸­ï¼š
load_from = './pretrained/rgbpose_conv3d_init.pth'
# ä½†éœ€è¦æ‰‹åŠ¨è°ƒæ•´in_channelsï¼ˆ28â†’17/25ï¼‰
```

```python
# å¦‚æœæœ‰NTU-60çš„åˆå§‹åŒ–æƒé‡
load_from = './pretrained/ntu60/rgbpose_ntu60_init.pth'

# æˆ–è€…ä»å¤´è®­ç»ƒ
# load_from = None
```

```shellscript
cd /home/zh/ChCode/codes01/mmaction2

# ä½¿ç”¨4å¼ A100è®­ç»ƒ
bash tools/dist_train.sh \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    4

# è®­ç»ƒæ—¥å¿—ä¼šä¿å­˜åœ¨ work_dirs/pcan_ntu60/
```

```shellscript
# è®­ç»ƒå®Œæˆåæµ‹è¯•
bash tools/dist_test.sh \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    work_dirs/pcan_ntu60/best_acc_top1_epoch_*.pth \
    4

# æˆ–è€…ä½¿ç”¨å•GPUæµ‹è¯•
CUDA_VISIBLE_DEVICES=0 python tools/test.py \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    work_dirs/pcan_ntu60/best_acc_top1_epoch_*.pth
```

```python
# åœ¨RGBPoseHead.__init__ä¸­
self.tree_loss_rgb = TreeLoss(num_actions=60, num_bodies=8)
self.tree_loss_pose = TreeLoss(num_actions=60, num_bodies=8)
```

```shellscript
# NTU-60çš„æ ‡å‡†å‘½åï¼ˆä¸å¸¦åç¼€ï¼‰
ls data/nturgbd_videos/ | head -5
# åº”è¯¥çœ‹åˆ°ï¼šS001C001P001R001A001.mp4

# å¦‚æœpklä¸­æ˜¯ä¸å¸¦åç¼€çš„
# ä½†è§†é¢‘æ–‡ä»¶æ˜¯ .mp4
# ä»£ç ä¼šè‡ªåŠ¨æ·»åŠ  .mp4
```

```shellscript
# æ£€æŸ¥å®é™…éª¨æ¶ç‚¹æ•°
python << 'EOF'
import pickle
with open('data/skeleton/ntu60_3d.pkl', 'rb') as f:
    data = pickle.load(f)
    V = data['annotations'][0]['keypoint'].shape[2]
    print(f"éª¨æ¶ç‚¹æ•°: {V}")
    # V=17 â†’ é…ç½®ç”¨ in_channels=17
    # V=25 â†’ é…ç½®ç”¨ in_channels=25
EOF
```

```plaintext
mmaction2/
â”œâ”€â”€ configs/skeleton/posec3d/rgbpose_conv3d/
â”‚   â””â”€â”€ pcan_ntu60.py  â† æ–°å»ºé…ç½®æ–‡ä»¶
â”œâ”€â”€ mmaction/models/recognizers/
â”‚   â””â”€â”€ recognizer3d_mm.py  â† ä¿®æ”¹ï¼šæ·»åŠ fine2coarse_ntu60
â”œâ”€â”€ mmaction/models/heads/
â”‚   â””â”€â”€ rgbpose_head.py  â† ä¿®æ”¹ï¼šæ”¯æŒåŠ¨æ€ç²—åˆ†ç±»æ•°
â””â”€â”€ data/
    â”œâ”€â”€ skeleton/
    â”‚   â”œâ”€â”€ ntu60_2d.pkl  â† éª¨æ¶æ•°æ®ï¼ˆ17ç‚¹ï¼‰
    â”‚   â””â”€â”€ ntu60_3d.pkl  â† æˆ–3Déª¨æ¶ï¼ˆ25ç‚¹ï¼‰
    â””â”€â”€ nturgbd_videos/
        â””â”€â”€ *.mp4  â† RGBè§†é¢‘
```

```shellscript
# 1. å‘Šè¯‰æˆ‘ä½ çš„æ•°æ®æ ¼å¼
cd /home/zh/ChCode/codes01/mmaction2
ls data/skeleton/
ls data/nturgbd_videos/ | head -5

# 2. æ£€æŸ¥éª¨æ¶ç‚¹æ•°
python << 'EOF'
import pickle
with open('data/skeleton/ntu60_3d.pkl', 'rb') as f:
    data = pickle.load(f)
    print(f"éª¨æ¶ç‚¹æ•°V: {data['annotations'][0]['keypoint'].shape[2]}")
EOF
```

---

**User**

ç°åœ¨å‡ºç°æŠ¥é”™äº†ï¼šTraceback (most recent call last):

  File "tools/train.py", line 143, in <module>

    main()

  File "tools/train.py", line 139, in main

    runner.train()

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/runner.py", line 1728, in train

    self._train_loop = self.build_train_loop(

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/runner.py", line 1520, in build_train_loop

    loop = LOOPS.build(

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/registry/registry.py", line 570, in build

    return self.build_func(cfg, *args, **kwargs, registry=self)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/registry/build_functions.py", line 121, in build_from_cfg

    obj = obj_cls(**args)  # type: ignore

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/loops.py", line 46, in __init__

    super().__init__(runner, dataloader)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/base_loop.py", line 26, in __init__

    self.dataloader = runner.build_dataloader(

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/runner.py", line 1370, in build_dataloader

    dataset = DATASETS.build(dataset_cfg)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/registry/registry.py", line 570, in build

    return self.build_func(cfg, *args, **kwargs, registry=self)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/registry/build_functions.py", line 121, in build_from_cfg

    obj = obj_cls(**args)  # type: ignore

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/datasets/pose_dataset.py", line 40, in __init__

    super().__init__(

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/datasets/base.py", line 48, in __init__

    super().__init__(

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/dataset/base_dataset.py", line 247, in __init__

    self.full_init()

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/dataset/base_dataset.py", line 298, in full_init

    self.data_list = self.load_data_list()

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/datasets/pose_dataset.py", line 50, in load_data_list

    split, annos = data_list['split'], data_list['annotations']

TypeError: list indices must be integers or slices, not str

Traceback (most recent call last):

  File "tools/train.py", line 143, in <module>

    main()

  File "tools/train.py", line 139, in main

    runner.train()

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/runner.py", line 1728, in train

    self._train_loop = self.build_train_loop(

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/runner.py", line 1520, in build_train_loop

    loop = LOOPS.build(

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/registry/registry.py", line 570, in build

    return self.build_func(cfg, *args, **kwargs, registry=self)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/registry/build_functions.py", line 121, in build_from_cfg

    obj = obj_cls(**args)  # type: ignore

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/loops.py", line 46, in __init__

    super().__init__(runner, dataloader)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/base_loop.py", line 26, in __init__

    self.dataloader = runner.build_dataloader(

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/runner.py", line 1370, in build_dataloader

    dataset = DATASETS.build(dataset_cfg)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/registry/registry.py", line 570, in build

    return self.build_func(cfg, *args, **kwargs, registry=self)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/registry/build_functions.py", line 121, in build_from_cfg

    obj = obj_cls(**args)  # type: ignore

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/datasets/pose_dataset.py", line 40, in __init__

    super().__init__(

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/datasets/base.py", line 48, in __init__

    super().__init__(

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/dataset/base_dataset.py", line 247, in __init__

    self.full_init()

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/dataset/base_dataset.py", line 298, in full_init

    self.data_list = self.load_data_list()

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/datasets/pose_dataset.py", line 50, in load_data_list

    split, annos = data_list['split'], data_list['annotations']

TypeError: list indices must be integers or slices, not str

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 3322297) of binary: /home/zh/anaconda3/envs/openmmlab/bin/python

Traceback (most recent call last):

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/runpy.py", line 194, in _run_module_as_main

    return _run_code(code, main_globals, None,

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/runpy.py", line 87, in _run_code

    exec(code, run_globals)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/distributed/launch.py", line 196, in <module>

    main()

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/distributed/launch.py", line 192, in main

    launch(args)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/distributed/launch.py", line 177, in launch

    run(args)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/distributed/run.py", line 785, in run

    elastic_launch(

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 134, in __call__

    return launch_agent(self._config, self._entrypoint, list(args))

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent

    raise ChildFailedError(

torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 

============================================================

tools/train.py FAILED

------------------------------------------------------------

Failures:

[1]:

  time      : 2025-11-21_00:56:14

  host      : localhost.localdomain

  rank      : 1 (local_rank: 1)

  exitcode  : 1 (pid: 3322298)

  error_file: <N/A>

  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html

------------------------------------------------------------

Root Cause (first observed failure):

[0]:

  time      : 2025-11-21_00:56:14

  host      : localhost.localdomain

  rank      : 0 (local_rank: 0)

  exitcode  : 1 (pid: 3322297)

  error_file: <N/A>

  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html

============================================================   æˆ‘pcan_ntu60.pyè¿™ä¸ªæ–‡ä»¶çš„æ•°æ®é…ç½®éƒ¨åˆ†æ˜¯è¿™æ ·çš„# ==========================================

# æ•°æ®é…ç½®

# ==========================================

dataset_type = 'PoseDataset'

data_root = '/home/zh/ChCode/codes01/mmaction2/data/nturgbd_videos/'

ann_file = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_train.pkl'  # æˆ– ntu60_2d.pkl

ann_file_val = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_val.pkl'

ann_file_test = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_val.pkl'     è¿™ä¸ªæ˜¯è¿™æ ·é…ç½®ä¹ˆï¼Ÿntu60_xsub_val.pklå’Œntu60_xsub_val.pklè¿™ä¸¤ä¸ªæ–‡ä»¶æ˜¯ç”±ntu60_2d.pkl æ‹†åˆ†å‡ºæ¥çš„ï¼Œ  æ­¤å¤–éª¨éª¼ç‚¹æ˜¯17ä¸ªï¼Œæ‰€æœ‰çš„ä¿®æ”¹æˆ‘éƒ½ç›´æ¥ä¿®æ”¹åœ¨æœåŠ¡å™¨ä¸Šäº†ï¼Œç›®å‰ä½ çœ‹åˆ°çš„é¡¹ç›®åœ¨æˆ‘æœ¬åœ°ï¼Œæœ¬åœ°æ²¡æœ‰ä¿®æ”¹ï¼Œå› æ­¤ä½ çœ‹ä¸åˆ°ã€‚ç„¶åç°åœ¨æŠ¥é”™æ˜¯ä»€ä¹ˆæƒ…å†µï¼Ÿ  ä»¥åŠæˆ‘è¿è¡Œè¿™ä¸ªæ£€æµ‹æ•°æ®çš„ä»£ç ç»“æœå¦‚ä¸‹ (openmmlab) [zh@node01 mmaction2]$ python << 'EOF'

import pickle

import os



# æ£€æŸ¥éª¨æ¶

with open('/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_2d.pkl', 'rb') as f:

    data = pickle.load(f)

    skeleton_names = [ann['frame_dir'] for ann in data['annotations']]

    print(f"éª¨æ¶æ ·æœ¬æ•°: {len(skeleton_names)}")

    print(f"ç¤ºä¾‹: {skeleton_names[0]}")  # ä¾‹å¦‚: S001C001P001R001A001



# æ£€æŸ¥è§†é¢‘

videos = os.listdir('/home/zh/ChCode/codes01/mmaction2/data/nturgbd_videos/')

print(f"è§†é¢‘æ•°é‡: {len([v for v in videos if v.endswith('.mp4')])}")

print(f"ç¤ºä¾‹: {videos[0]}")



# æ£€æŸ¥æ˜¯å¦åŒ¹é…

sample_name = skeleton_names[0]

video_name = sample_name + '.mp4'

if video_name in videos:

    print(f"âœ“ è§†é¢‘å’Œéª¨æ¶åŒ¹é…ï¼")

else:

    print(f"âœ— è­¦å‘Šï¼š{video_name} ä¸å­˜åœ¨")

EOF

éª¨æ¶æ ·æœ¬æ•°: 56578

ç¤ºä¾‹: S001C001P001R001A001

è§†é¢‘æ•°é‡: 56578

ç¤ºä¾‹: S007C003P028R001A021_rgb.mp4

âœ— è­¦å‘Šï¼šS001C001P001R001A001.mp4 ä¸å­˜åœ¨

---

**Cursor**

å‘ç°äº†ä¸¤ä¸ªé—®é¢˜ï¼è®©æˆ‘å¸®ä½ é€ä¸€è§£å†³ã€‚

**æ‰¾åˆ°é—®é¢˜äº†ï¼æœ‰ä¸¤ä¸ªå…³é”®é”™è¯¯ï¼š**

## âŒ é—®é¢˜1ï¼špklæ–‡ä»¶æ ¼å¼ä¸å¯¹

é”™è¯¯ä¿¡æ¯ï¼š`TypeError: list indices must be integers or slices, not str`

**åŸå› **ï¼šä½ çš„`ntu60_xsub_train.pkl`å¯èƒ½åªæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œè€Œä¸æ˜¯æ ‡å‡†çš„å­—å…¸æ ¼å¼ã€‚

### æ£€æŸ¥pklæ ¼å¼

```bash
python << 'EOF'
import pickle

# æ£€æŸ¥train pkl
with open('/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_train.pkl', 'rb') as f:
    data = pickle.load(f)
    print(f"æ•°æ®ç±»å‹: {type(data)}")
    
    if isinstance(data, dict):
        print(f"âœ“ æ ¼å¼æ­£ç¡® - å­—å…¸")
        print(f"  Keys: {data.keys()}")
    elif isinstance(data, list):
        print(f"âœ— æ ¼å¼é”™è¯¯ - åˆ—è¡¨")
        print(f"  éœ€è¦è½¬æ¢ä¸ºå­—å…¸æ ¼å¼")
        print(f"  åˆ—è¡¨é•¿åº¦: {len(data)}")
EOF
```

### è§£å†³æ–¹æ¡ˆï¼šè½¬æ¢pklæ ¼å¼

å¦‚æœè¾“å‡ºæ˜¾ç¤ºæ˜¯**åˆ—è¡¨**ï¼Œéœ€è¦è½¬æ¢ï¼š

```bash
python << 'EOF'
import pickle

# åŠ è½½åˆ—è¡¨æ ¼å¼çš„æ•°æ®
with open('/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_train.pkl', 'rb') as f:
    train_data = pickle.load(f)

with open('/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_val.pkl', 'rb') as f:
    val_data = pickle.load(f)

print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_data)}")
print(f"éªŒè¯é›†æ ·æœ¬æ•°: {len(val_data)}")

# è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
standard_format = {
    'split': {
        'xsub_train': [item['frame_dir'] for item in train_data],
        'xsub_val': [item['frame_dir'] for item in val_data]
    },
    'annotations': train_data + val_data  # åˆå¹¶æ‰€æœ‰æ ‡æ³¨
}

# ä¿å­˜ä¸ºæ ‡å‡†æ ¼å¼
with open('/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_merged.pkl', 'wb') as f:
    pickle.dump(standard_format, f)

print("âœ“ è½¬æ¢å®Œæˆï¼")
print(f"  æ€»æ ·æœ¬æ•°: {len(standard_format['annotations'])}")
print(f"  Splits: {standard_format['split'].keys()}")
print(f"  è®­ç»ƒé›†: {len(standard_format['split']['xsub_train'])}ä¸ª")
print(f"  éªŒè¯é›†: {len(standard_format['split']['xsub_val'])}ä¸ª")
EOF
```

**ç„¶åä¿®æ”¹é…ç½®æ–‡ä»¶**ï¼š

```python
# pcan_ntu60.py ä¸­ä¿®æ”¹ï¼š
ann_file = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_merged.pkl'
ann_file_val = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_merged.pkl'
ann_file_test = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_merged.pkl'

# dataloaderä¸­éœ€è¦æŒ‡å®šsplit
train_dataloader = dict(
    # ... other config
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file,
        data_prefix=dict(video=data_root),
        split='xsub_train',  # â† æŒ‡å®šä½¿ç”¨å“ªä¸ªsplit
        pipeline=train_pipeline))

val_dataloader = dict(
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_val,
        data_prefix=dict(video=data_root),
        split='xsub_val',  # â† æŒ‡å®šsplit
        pipeline=val_pipeline,
        test_mode=True))
```

---

## âŒ é—®é¢˜2ï¼šè§†é¢‘å‘½åä¸åŒ¹é…

**éª¨æ¶ä¸­**ï¼š`S001C001P001R001A001`  
**å®é™…è§†é¢‘**ï¼š`S007C003P028R001A021_rgb.mp4`ï¼ˆæœ‰`_rgb`åç¼€ï¼‰

### è§£å†³æ–¹æ¡ˆAï¼šé‡å‘½åè§†é¢‘æ–‡ä»¶ï¼ˆæ¨èï¼‰

```bash
cd /home/zh/ChCode/codes01/mmaction2/data/nturgbd_videos

# æ‰¹é‡å»é™¤_rgbåç¼€
for file in *_rgb.mp4; do
    newname="${file/_rgb.mp4/.mp4}"
    mv "$file" "$newname"
done

# éªŒè¯
ls | head -5
# åº”è¯¥çœ‹åˆ°ï¼šS001C001P001R001A001.mp4
```

### è§£å†³æ–¹æ¡ˆBï¼šä¿®æ”¹pklä¸­çš„frame_dir

```bash
python << 'EOF'
import pickle

# åŠ è½½pkl
with open('/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_merged.pkl', 'rb') as f:
    data = pickle.load(f)

# ç»™æ‰€æœ‰frame_diræ·»åŠ _rgbåç¼€
for ann in data['annotations']:
    if not ann['frame_dir'].endswith('_rgb'):
        ann['frame_dir'] = ann['frame_dir'] + '_rgb'

# ä¿å­˜
with open('/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_merged.pkl', 'wb') as f:
    pickle.dump(data, f)

print("âœ“ å·²æ·»åŠ _rgbåç¼€")
EOF
```

---

## ğŸ“‹ å®Œæ•´çš„ä¿®å¤æ­¥éª¤

### æ­¥éª¤1ï¼šæ£€æŸ¥å¹¶è½¬æ¢pklæ ¼å¼

```bash
cd /home/zh/ChCode/codes01/mmaction2

# 1. æ£€æŸ¥æ ¼å¼
python << 'EOF'
import pickle

files = {
    'train': 'data/skeleton/ntu60_xsub_train.pkl',
    'val': 'data/skeleton/ntu60_xsub_val.pkl'
}

for name, path in files.items():
    with open(path, 'rb') as f:
        data = pickle.load(f)
    print(f"{name}: type={type(data)}, ", end='')
    if isinstance(data, list):
        print(f"len={len(data)}")
    elif isinstance(data, dict):
        print(f"keys={data.keys()}")
EOF
```

### æ­¥éª¤2ï¼šå¦‚æœæ˜¯åˆ—è¡¨ï¼Œè¿è¡Œè½¬æ¢è„šæœ¬

```bash
python << 'EOF'
import pickle

print("è½¬æ¢pklæ ¼å¼...")

# åŠ è½½åˆ†ç¦»çš„pkl
with open('data/skeleton/ntu60_xsub_train.pkl', 'rb') as f:
    train_data = pickle.load(f)
    
with open('data/skeleton/ntu60_xsub_val.pkl', 'rb') as f:
    val_data = pickle.load(f)

# ç¡®ä¿æ˜¯åˆ—è¡¨
if not isinstance(train_data, list):
    print("âœ— trainæ•°æ®ä¸æ˜¯åˆ—è¡¨æ ¼å¼")
    exit(1)
if not isinstance(val_data, list):
    print("âœ— valæ•°æ®ä¸æ˜¯åˆ—è¡¨æ ¼å¼")
    exit(1)

print(f"è®­ç»ƒé›†: {len(train_data)}ä¸ªæ ·æœ¬")
print(f"éªŒè¯é›†: {len(val_data)}ä¸ªæ ·æœ¬")

# æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ _rgbåç¼€
sample = train_data[0]
print(f"ç¤ºä¾‹frame_dir: {sample['frame_dir']}")

# æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ ¼å¼
import os
videos = os.listdir('data/nturgbd_videos/')
has_rgb_suffix = any('_rgb.mp4' in v for v in videos)
print(f"è§†é¢‘æœ‰_rgbåç¼€: {has_rgb_suffix}")

# å¦‚æœè§†é¢‘æœ‰_rgbåç¼€ï¼Œç»™frame_dirä¹ŸåŠ ä¸Š
if has_rgb_suffix:
    print("æ·»åŠ _rgbåç¼€åˆ°frame_dir...")
    for item in train_data + val_data:
        if not item['frame_dir'].endswith('_rgb'):
            item['frame_dir'] = item['frame_dir'] + '_rgb'

# è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
standard_format = {
    'split': {
        'xsub_train': [item['frame_dir'] for item in train_data],
        'xsub_val': [item['frame_dir'] for item in val_data]
    },
    'annotations': train_data + val_data
}

# ä¿å­˜
output_path = 'data/skeleton/ntu60_xsub.pkl'
with open(output_path, 'wb') as f:
    pickle.dump(standard_format, f)

print(f"\nâœ“ è½¬æ¢å®Œæˆï¼ä¿å­˜åˆ°: {output_path}")
print(f"  æ ¼å¼: dict with keys {list(standard_format.keys())}")
print(f"  Splits: {list(standard_format['split'].keys())}")
print(f"  æ€»æ ·æœ¬æ•°: {len(standard_format['annotations'])}")
print(f"  è®­ç»ƒé›†: {len(standard_format['split']['xsub_train'])}ä¸ª")
print(f"  éªŒè¯é›†: {len(standard_format['split']['xsub_val'])}ä¸ª")

# éªŒè¯
sample = standard_format['annotations'][0]
print(f"\nç¤ºä¾‹æ•°æ®:")
print(f"  frame_dir: {sample['frame_dir']}")
print(f"  label: {sample['label']}")
print(f"  keypoint shape: {sample['keypoint'].shape}")
EOF
```

### æ­¥éª¤3ï¼šä¿®æ­£é…ç½®æ–‡ä»¶

ä¿®æ”¹ `pcan_ntu60.py` çš„æ•°æ®é…ç½®éƒ¨åˆ†ï¼š

```python
# ==========================================
# æ•°æ®é…ç½®
# ==========================================
dataset_type = 'PoseDataset'
data_root = '/home/zh/ChCode/codes01/mmaction2/data/nturgbd_videos/'

# â† æ”¹ï¼šä½¿ç”¨åˆå¹¶åçš„pklæ–‡ä»¶
ann_file = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub.pkl'
ann_file_val = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub.pkl'
ann_file_test = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub.pkl'

# ... å…¶ä»–é…ç½® ...

train_dataloader = dict(
    batch_size=10,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=True),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file,
        data_prefix=dict(video=data_root),
        split='xsub_train',  # â† å¿…é¡»æŒ‡å®šsplit
        pipeline=train_pipeline))

val_dataloader = dict(
    batch_size=1,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_val,
        data_prefix=dict(video=data_root),
        split='xsub_val',  # â† å¿…é¡»æŒ‡å®šsplit
        pipeline=val_pipeline,
        test_mode=True))

test_dataloader = dict(
    batch_size=1,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_test,
        data_prefix=dict(video=data_root),
        split='xsub_val',  # â† å¿…é¡»æŒ‡å®šsplit
        pipeline=test_pipeline,
        test_mode=True))
```

### æ­¥éª¤4ï¼šéªŒè¯ä¿®å¤

```bash
# è¿è¡Œè½¬æ¢è„šæœ¬åï¼ŒéªŒè¯æ–°pkl
python << 'EOF'
import pickle
import os

pkl_path = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub.pkl'
with open(pkl_path, 'rb') as f:
    data = pickle.load(f)

print("="*60)
print("PKLæ ¼å¼éªŒè¯")
print("="*60)
print(f"âœ“ ç±»å‹: {type(data)}")
print(f"âœ“ Keys: {list(data.keys())}")
print(f"âœ“ Splits: {list(data['split'].keys())}")
print(f"âœ“ æ€»æ ·æœ¬: {len(data['annotations'])}")

# æ£€æŸ¥è§†é¢‘åŒ¹é…
sample = data['annotations'][0]
frame_dir = sample['frame_dir']
print(f"\nç¤ºä¾‹frame_dir: {frame_dir}")

# æ„å»ºè§†é¢‘è·¯å¾„
video_path = os.path.join('data/nturgbd_videos', frame_dir + '.mp4')
if os.path.exists(video_path):
    print(f"âœ“ è§†é¢‘å­˜åœ¨: {video_path}")
else:
    print(f"âœ— è§†é¢‘ä¸å­˜åœ¨: {video_path}")
    # å°è¯•æŸ¥æ‰¾
    videos = os.listdir('data/nturgbd_videos')
    # å»æ‰_rgb.mp4çœ‹çœ‹èƒ½ä¸èƒ½åŒ¹é…
    base_name = frame_dir.replace('_rgb', '')
    if base_name + '.mp4' in videos:
        print(f"  æç¤º: æ‰¾åˆ° {base_name}.mp4")
        print(f"  å»ºè®®: frame_dirå»æ‰_rgbåç¼€")
    elif frame_dir + '_rgb.mp4' in videos:
        print(f"  æç¤º: æ‰¾åˆ° {frame_dir}_rgb.mp4")
        print(f"  å»ºè®®: è§†é¢‘å»æ‰_rgbåç¼€")
EOF
```

### æ­¥éª¤5ï¼šæ ¹æ®ä¸Šé¢çš„è¾“å‡ºé€‰æ‹©ä¿®æ­£æ–¹æ¡ˆ

**æ–¹æ¡ˆAï¼šå¦‚æœframe_diræœ‰`_rgb`ä½†è§†é¢‘æ²¡æœ‰**

```bash
# ä¿®æ”¹pklï¼Œå»æ‰_rgb
python << 'EOF'
import pickle

with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

# å»æ‰æ‰€æœ‰_rgbåç¼€
for ann in data['annotations']:
    ann['frame_dir'] = ann['frame_dir'].replace('_rgb', '')

# æ›´æ–°split
data['split']['xsub_train'] = [s.replace('_rgb', '') for s in data['split']['xsub_train']]
data['split']['xsub_val'] = [s.replace('_rgb', '') for s in data['split']['xsub_val']]

# ä¿å­˜
with open('data/skeleton/ntu60_xsub.pkl', 'wb') as f:
    pickle.dump(data, f)
print("âœ“ å·²å»é™¤_rgbåç¼€")
EOF
```

**æ–¹æ¡ˆBï¼šå¦‚æœè§†é¢‘æœ‰`_rgb`ä½†frame_diræ²¡æœ‰**

```bash
# ä¿®æ”¹pklï¼Œæ·»åŠ _rgb
python << 'EOF'
import pickle

with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

# æ·»åŠ _rgbåç¼€
for ann in data['annotations']:
    if not ann['frame_dir'].endswith('_rgb'):
        ann['frame_dir'] = ann['frame_dir'] + '_rgb'

# æ›´æ–°split
data['split']['xsub_train'] = [s if s.endswith('_rgb') else s+'_rgb' 
                                for s in data['split']['xsub_train']]
data['split']['xsub_val'] = [s if s.endswith('_rgb') else s+'_rgb' 
                              for s in data['split']['xsub_val']]

# ä¿å­˜
with open('data/skeleton/ntu60_xsub.pkl', 'wb') as f:
    pickle.dump(data, f)
print("âœ“ å·²æ·»åŠ _rgbåç¼€")
EOF
```

---

## ğŸ“ å®Œæ•´çš„ä¿®å¤æµç¨‹ï¼ˆæŒ‰é¡ºåºæ‰§è¡Œï¼‰

```bash
cd /home/zh/ChCode/codes01/mmaction2

# ===== ç¬¬1æ­¥ï¼šæ£€æŸ¥pklæ ¼å¼ =====
echo "æ£€æŸ¥pklæ ¼å¼..."
python << 'EOF'
import pickle
with open('data/skeleton/ntu60_xsub_train.pkl', 'rb') as f:
    data = pickle.load(f)
print(f"ç±»å‹: {type(data)}")
if isinstance(data, dict):
    print("âœ“ å·²ç»æ˜¯å­—å…¸æ ¼å¼")
elif isinstance(data, list):
    print("âœ— æ˜¯åˆ—è¡¨æ ¼å¼ï¼Œéœ€è¦è½¬æ¢")
EOF

# ===== ç¬¬2æ­¥ï¼šè½¬æ¢æ ¼å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰=====
echo ""
echo "è½¬æ¢pklæ ¼å¼..."
python << 'EOF'
import pickle
import os

# åŠ è½½
with open('data/skeleton/ntu60_xsub_train.pkl', 'rb') as f:
    train_data = pickle.load(f)
with open('data/skeleton/ntu60_xsub_val.pkl', 'rb') as f:
    val_data = pickle.load(f)

# æ£€æŸ¥è§†é¢‘å‘½å
videos = os.listdir('data/nturgbd_videos/')
has_rgb_suffix = videos[0].endswith('_rgb.mp4')

print(f"è§†é¢‘ç¤ºä¾‹: {videos[0]}")
print(f"è§†é¢‘æœ‰_rgbåç¼€: {has_rgb_suffix}")
print(f"éª¨æ¶ç¤ºä¾‹: {train_data[0]['frame_dir']}")

# ç»Ÿä¸€å‘½åï¼šéƒ½åŠ _rgbï¼ˆå› ä¸ºè§†é¢‘æœ‰_rgbï¼‰
for item in train_data + val_data:
    if not item['frame_dir'].endswith('_rgb'):
        item['frame_dir'] = item['frame_dir'] + '_rgb'

# æ ‡å‡†æ ¼å¼
data = {
    'split': {
        'xsub_train': [item['frame_dir'] for item in train_data],
        'xsub_val': [item['frame_dir'] for item in val_data]
    },
    'annotations': train_data + val_data
}

# ä¿å­˜
with open('data/skeleton/ntu60_xsub.pkl', 'wb') as f:
    pickle.dump(data, f)

print(f"âœ“ ä¿å­˜åˆ°: data/skeleton/ntu60_xsub.pkl")
print(f"  è®­ç»ƒé›†: {len(data['split']['xsub_train'])}")
print(f"  éªŒè¯é›†: {len(data['split']['xsub_val'])}")
EOF

# ===== ç¬¬3æ­¥ï¼šéªŒè¯è§†é¢‘åŒ¹é… =====
echo ""
echo "éªŒè¯è§†é¢‘å’Œéª¨æ¶åŒ¹é…..."
python << 'EOF'
import pickle
import os

with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

# æ£€æŸ¥å‰10ä¸ªæ ·æœ¬
success = 0
for i in range(min(10, len(data['annotations']))):
    frame_dir = data['annotations'][i]['frame_dir']
    video_path = os.path.join('data/nturgbd_videos', frame_dir + '.mp4')
    if os.path.exists(video_path):
        success += 1
    else:
        print(f"âœ— ç¼ºå¤±: {frame_dir}.mp4")

print(f"\nåŒ¹é…ç‡: {success}/10")
if success == 10:
    print("âœ“ æ‰€æœ‰è§†é¢‘éƒ½åŒ¹é…ï¼")
else:
    print("âš ï¸ æœ‰è§†é¢‘ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥å‘½å")
EOF

# ===== ç¬¬4æ­¥ï¼šæµ‹è¯•æ•°æ®åŠ è½½ =====
echo ""
echo "æµ‹è¯•æ•°æ®åŠ è½½..."
python tools/analysis_tools/browse_dataset.py \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    --mode pipeline \
    --show-number 1 2>&1 | head -50

# å¦‚æœæ²¡æŠ¥é”™ï¼Œè¯´æ˜æ•°æ®åŠ è½½æˆåŠŸï¼
```

---

## ğŸ¯ é‡æ–°è®­ç»ƒ

ä¿®å¤åé‡æ–°è¿è¡Œï¼š

```bash
cd /home/zh/ChCode/codes01/mmaction2

# å•GPUæµ‹è¯•ï¼ˆå…ˆéªŒè¯èƒ½è·‘é€šï¼‰
CUDA_VISIBLE_DEVICES=0 python tools/train.py \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    --work-dir work_dirs/pcan_ntu60_test

# å¦‚æœå•GPUèƒ½è·‘ï¼Œå†ç”¨4GPU
bash tools/dist_train.sh \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    4
```

---

## ğŸ“Š é—®é¢˜æ€»ç»“

| é—®é¢˜ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|---------|
| `TypeError: list indices...` | pklæ˜¯åˆ—è¡¨ä¸æ˜¯å­—å…¸ | è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ |
| è§†é¢‘æ‰¾ä¸åˆ° | frame_dirå’Œè§†é¢‘åä¸åŒ¹é… | ç»Ÿä¸€å‘½åï¼ˆåŠ æˆ–å»_rgbï¼‰ |
| splitæœªæŒ‡å®š | dataloaderç¼ºå°‘splitå‚æ•° | æ·»åŠ `split='xsub_train'` |

---

## âœ… æ‰§è¡Œè¿™ä¸ªä¸€é”®ä¿®å¤è„šæœ¬

```bash
cd /home/zh/ChCode/codes01/mmaction2

# ä¿å­˜ä¸º fix_ntu60_data.sh
cat > fix_ntu60_data.sh << 'SCRIPT'
#!/bin/bash

echo "=========================================="
echo "ä¿®å¤NTU-60æ•°æ®æ ¼å¼"
echo "=========================================="

cd /home/zh/ChCode/codes01/mmaction2

# è½¬æ¢pklæ ¼å¼
python << 'EOF'
import pickle
import os

print("1. åŠ è½½pklæ–‡ä»¶...")
with open('data/skeleton/ntu60_xsub_train.pkl', 'rb') as f:
    train_data = pickle.load(f)
with open('data/skeleton/ntu60_xsub_val.pkl', 'rb') as f:
    val_data = pickle.load(f)

print(f"   è®­ç»ƒé›†: {len(train_data)}")
print(f"   éªŒè¯é›†: {len(val_data)}")

print("\n2. ç»Ÿä¸€å‘½åï¼ˆæ·»åŠ _rgbï¼‰...")
for item in train_data + val_data:
    if not item['frame_dir'].endswith('_rgb'):
        item['frame_dir'] = item['frame_dir'] + '_rgb'

print("\n3. è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼...")
data = {
    'split': {
        'xsub_train': [item['frame_dir'] for item in train_data],
        'xsub_val': [item['frame_dir'] for item in val_data]
    },
    'annotations': train_data + val_data
}

print("\n4. ä¿å­˜...")
with open('data/skeleton/ntu60_xsub.pkl', 'wb') as f:
    pickle.dump(data, f)

print("âœ“ å®Œæˆï¼")
print(f"  æ–‡ä»¶: data/skeleton/ntu60_xsub.pkl")
print(f"  æ€»æ ·æœ¬: {len(data['annotations'])}")

# éªŒè¯
sample = data['annotations'][0]
video_path = os.path.join('data/nturgbd_videos', sample['frame_dir'] + '.mp4')
if os.path.exists(video_path):
    print(f"âœ“ è§†é¢‘åŒ¹é…æµ‹è¯•é€šè¿‡")
else:
    print(f"âœ— è­¦å‘Šï¼š{video_path} ä¸å­˜åœ¨")
EOF

echo ""
echo "=========================================="
echo "ä¿®å¤å®Œæˆï¼"
echo "=========================================="
SCRIPT

# è¿è¡Œ
chmod +x fix_ntu60_data.sh
./fix_ntu60_data.sh
```

è¿è¡Œè¿™ä¸ªè„šæœ¬åï¼Œ**å†é‡æ–°è®­ç»ƒ**åº”è¯¥å°±å¯ä»¥äº†ï¼

æŠŠè„šæœ¬è¿è¡Œç»“æœå‘Šè¯‰æˆ‘ï¼Œå¦‚æœè¿˜æœ‰é—®é¢˜æˆ‘ä»¬ç»§ç»­è°ƒè¯•ï¼ğŸš€

```shellscript
python << 'EOF'
import pickle

# æ£€æŸ¥train pkl
with open('/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_train.pkl', 'rb') as f:
    data = pickle.load(f)
    print(f"æ•°æ®ç±»å‹: {type(data)}")
    
    if isinstance(data, dict):
        print(f"âœ“ æ ¼å¼æ­£ç¡® - å­—å…¸")
        print(f"  Keys: {data.keys()}")
    elif isinstance(data, list):
        print(f"âœ— æ ¼å¼é”™è¯¯ - åˆ—è¡¨")
        print(f"  éœ€è¦è½¬æ¢ä¸ºå­—å…¸æ ¼å¼")
        print(f"  åˆ—è¡¨é•¿åº¦: {len(data)}")
EOF
```

```shellscript
python << 'EOF'
import pickle

# åŠ è½½åˆ—è¡¨æ ¼å¼çš„æ•°æ®
with open('/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_train.pkl', 'rb') as f:
    train_data = pickle.load(f)

with open('/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_val.pkl', 'rb') as f:
    val_data = pickle.load(f)

print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_data)}")
print(f"éªŒè¯é›†æ ·æœ¬æ•°: {len(val_data)}")

# è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
standard_format = {
    'split': {
        'xsub_train': [item['frame_dir'] for item in train_data],
        'xsub_val': [item['frame_dir'] for item in val_data]
    },
    'annotations': train_data + val_data  # åˆå¹¶æ‰€æœ‰æ ‡æ³¨
}

# ä¿å­˜ä¸ºæ ‡å‡†æ ¼å¼
with open('/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_merged.pkl', 'wb') as f:
    pickle.dump(standard_format, f)

print("âœ“ è½¬æ¢å®Œæˆï¼")
print(f"  æ€»æ ·æœ¬æ•°: {len(standard_format['annotations'])}")
print(f"  Splits: {standard_format['split'].keys()}")
print(f"  è®­ç»ƒé›†: {len(standard_format['split']['xsub_train'])}ä¸ª")
print(f"  éªŒè¯é›†: {len(standard_format['split']['xsub_val'])}ä¸ª")
EOF
```

```python
# pcan_ntu60.py ä¸­ä¿®æ”¹ï¼š
ann_file = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_merged.pkl'
ann_file_val = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_merged.pkl'
ann_file_test = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_merged.pkl'

# dataloaderä¸­éœ€è¦æŒ‡å®šsplit
train_dataloader = dict(
    # ... other config
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file,
        data_prefix=dict(video=data_root),
        split='xsub_train',  # â† æŒ‡å®šä½¿ç”¨å“ªä¸ªsplit
        pipeline=train_pipeline))

val_dataloader = dict(
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_val,
        data_prefix=dict(video=data_root),
        split='xsub_val',  # â† æŒ‡å®šsplit
        pipeline=val_pipeline,
        test_mode=True))
```

```shellscript
cd /home/zh/ChCode/codes01/mmaction2/data/nturgbd_videos

# æ‰¹é‡å»é™¤_rgbåç¼€
for file in *_rgb.mp4; do
    newname="${file/_rgb.mp4/.mp4}"
    mv "$file" "$newname"
done

# éªŒè¯
ls | head -5
# åº”è¯¥çœ‹åˆ°ï¼šS001C001P001R001A001.mp4
```

```shellscript
python << 'EOF'
import pickle

# åŠ è½½pkl
with open('/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_merged.pkl', 'rb') as f:
    data = pickle.load(f)

# ç»™æ‰€æœ‰frame_diræ·»åŠ _rgbåç¼€
for ann in data['annotations']:
    if not ann['frame_dir'].endswith('_rgb'):
        ann['frame_dir'] = ann['frame_dir'] + '_rgb'

# ä¿å­˜
with open('/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub_merged.pkl', 'wb') as f:
    pickle.dump(data, f)

print("âœ“ å·²æ·»åŠ _rgbåç¼€")
EOF
```

```shellscript
cd /home/zh/ChCode/codes01/mmaction2

# 1. æ£€æŸ¥æ ¼å¼
python << 'EOF'
import pickle

files = {
    'train': 'data/skeleton/ntu60_xsub_train.pkl',
    'val': 'data/skeleton/ntu60_xsub_val.pkl'
}

for name, path in files.items():
    with open(path, 'rb') as f:
        data = pickle.load(f)
    print(f"{name}: type={type(data)}, ", end='')
    if isinstance(data, list):
        print(f"len={len(data)}")
    elif isinstance(data, dict):
        print(f"keys={data.keys()}")
EOF
```

```shellscript
python << 'EOF'
import pickle

print("è½¬æ¢pklæ ¼å¼...")

# åŠ è½½åˆ†ç¦»çš„pkl
with open('data/skeleton/ntu60_xsub_train.pkl', 'rb') as f:
    train_data = pickle.load(f)
    
with open('data/skeleton/ntu60_xsub_val.pkl', 'rb') as f:
    val_data = pickle.load(f)

# ç¡®ä¿æ˜¯åˆ—è¡¨
if not isinstance(train_data, list):
    print("âœ— trainæ•°æ®ä¸æ˜¯åˆ—è¡¨æ ¼å¼")
    exit(1)
if not isinstance(val_data, list):
    print("âœ— valæ•°æ®ä¸æ˜¯åˆ—è¡¨æ ¼å¼")
    exit(1)

print(f"è®­ç»ƒé›†: {len(train_data)}ä¸ªæ ·æœ¬")
print(f"éªŒè¯é›†: {len(val_data)}ä¸ªæ ·æœ¬")

# æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ _rgbåç¼€
sample = train_data[0]
print(f"ç¤ºä¾‹frame_dir: {sample['frame_dir']}")

# æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ ¼å¼
import os
videos = os.listdir('data/nturgbd_videos/')
has_rgb_suffix = any('_rgb.mp4' in v for v in videos)
print(f"è§†é¢‘æœ‰_rgbåç¼€: {has_rgb_suffix}")

# å¦‚æœè§†é¢‘æœ‰_rgbåç¼€ï¼Œç»™frame_dirä¹ŸåŠ ä¸Š
if has_rgb_suffix:
    print("æ·»åŠ _rgbåç¼€åˆ°frame_dir...")
    for item in train_data + val_data:
        if not item['frame_dir'].endswith('_rgb'):
            item['frame_dir'] = item['frame_dir'] + '_rgb'

# è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
standard_format = {
    'split': {
        'xsub_train': [item['frame_dir'] for item in train_data],
        'xsub_val': [item['frame_dir'] for item in val_data]
    },
    'annotations': train_data + val_data
}

# ä¿å­˜
output_path = 'data/skeleton/ntu60_xsub.pkl'
with open(output_path, 'wb') as f:
    pickle.dump(standard_format, f)

print(f"\nâœ“ è½¬æ¢å®Œæˆï¼ä¿å­˜åˆ°: {output_path}")
print(f"  æ ¼å¼: dict with keys {list(standard_format.keys())}")
print(f"  Splits: {list(standard_format['split'].keys())}")
print(f"  æ€»æ ·æœ¬æ•°: {len(standard_format['annotations'])}")
print(f"  è®­ç»ƒé›†: {len(standard_format['split']['xsub_train'])}ä¸ª")
print(f"  éªŒè¯é›†: {len(standard_format['split']['xsub_val'])}ä¸ª")

# éªŒè¯
sample = standard_format['annotations'][0]
print(f"\nç¤ºä¾‹æ•°æ®:")
print(f"  frame_dir: {sample['frame_dir']}")
print(f"  label: {sample['label']}")
print(f"  keypoint shape: {sample['keypoint'].shape}")
EOF
```

```python
# ==========================================
# æ•°æ®é…ç½®
# ==========================================
dataset_type = 'PoseDataset'
data_root = '/home/zh/ChCode/codes01/mmaction2/data/nturgbd_videos/'

# â† æ”¹ï¼šä½¿ç”¨åˆå¹¶åçš„pklæ–‡ä»¶
ann_file = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub.pkl'
ann_file_val = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub.pkl'
ann_file_test = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub.pkl'

# ... å…¶ä»–é…ç½® ...

train_dataloader = dict(
    batch_size=10,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=True),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file,
        data_prefix=dict(video=data_root),
        split='xsub_train',  # â† å¿…é¡»æŒ‡å®šsplit
        pipeline=train_pipeline))

val_dataloader = dict(
    batch_size=1,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_val,
        data_prefix=dict(video=data_root),
        split='xsub_val',  # â† å¿…é¡»æŒ‡å®šsplit
        pipeline=val_pipeline,
        test_mode=True))

test_dataloader = dict(
    batch_size=1,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_test,
        data_prefix=dict(video=data_root),
        split='xsub_val',  # â† å¿…é¡»æŒ‡å®šsplit
        pipeline=test_pipeline,
        test_mode=True))
```

```shellscript
# è¿è¡Œè½¬æ¢è„šæœ¬åï¼ŒéªŒè¯æ–°pkl
python << 'EOF'
import pickle
import os

pkl_path = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub.pkl'
with open(pkl_path, 'rb') as f:
    data = pickle.load(f)

print("="*60)
print("PKLæ ¼å¼éªŒè¯")
print("="*60)
print(f"âœ“ ç±»å‹: {type(data)}")
print(f"âœ“ Keys: {list(data.keys())}")
print(f"âœ“ Splits: {list(data['split'].keys())}")
print(f"âœ“ æ€»æ ·æœ¬: {len(data['annotations'])}")

# æ£€æŸ¥è§†é¢‘åŒ¹é…
sample = data['annotations'][0]
frame_dir = sample['frame_dir']
print(f"\nç¤ºä¾‹frame_dir: {frame_dir}")

# æ„å»ºè§†é¢‘è·¯å¾„
video_path = os.path.join('data/nturgbd_videos', frame_dir + '.mp4')
if os.path.exists(video_path):
    print(f"âœ“ è§†é¢‘å­˜åœ¨: {video_path}")
else:
    print(f"âœ— è§†é¢‘ä¸å­˜åœ¨: {video_path}")
    # å°è¯•æŸ¥æ‰¾
    videos = os.listdir('data/nturgbd_videos')
    # å»æ‰_rgb.mp4çœ‹çœ‹èƒ½ä¸èƒ½åŒ¹é…
    base_name = frame_dir.replace('_rgb', '')
    if base_name + '.mp4' in videos:
        print(f"  æç¤º: æ‰¾åˆ° {base_name}.mp4")
        print(f"  å»ºè®®: frame_dirå»æ‰_rgbåç¼€")
    elif frame_dir + '_rgb.mp4' in videos:
        print(f"  æç¤º: æ‰¾åˆ° {frame_dir}_rgb.mp4")
        print(f"  å»ºè®®: è§†é¢‘å»æ‰_rgbåç¼€")
EOF
```

```shellscript
# ä¿®æ”¹pklï¼Œå»æ‰_rgb
python << 'EOF'
import pickle

with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

# å»æ‰æ‰€æœ‰_rgbåç¼€
for ann in data['annotations']:
    ann['frame_dir'] = ann['frame_dir'].replace('_rgb', '')

# æ›´æ–°split
data['split']['xsub_train'] = [s.replace('_rgb', '') for s in data['split']['xsub_train']]
data['split']['xsub_val'] = [s.replace('_rgb', '') for s in data['split']['xsub_val']]

# ä¿å­˜
with open('data/skeleton/ntu60_xsub.pkl', 'wb') as f:
    pickle.dump(data, f)
print("âœ“ å·²å»é™¤_rgbåç¼€")
EOF
```

```shellscript
# ä¿®æ”¹pklï¼Œæ·»åŠ _rgb
python << 'EOF'
import pickle

with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

# æ·»åŠ _rgbåç¼€
for ann in data['annotations']:
    if not ann['frame_dir'].endswith('_rgb'):
        ann['frame_dir'] = ann['frame_dir'] + '_rgb'

# æ›´æ–°split
data['split']['xsub_train'] = [s if s.endswith('_rgb') else s+'_rgb' 
                                for s in data['split']['xsub_train']]
data['split']['xsub_val'] = [s if s.endswith('_rgb') else s+'_rgb' 
                              for s in data['split']['xsub_val']]

# ä¿å­˜
with open('data/skeleton/ntu60_xsub.pkl', 'wb') as f:
    pickle.dump(data, f)
print("âœ“ å·²æ·»åŠ _rgbåç¼€")
EOF
```

```shellscript
cd /home/zh/ChCode/codes01/mmaction2

# ===== ç¬¬1æ­¥ï¼šæ£€æŸ¥pklæ ¼å¼ =====
echo "æ£€æŸ¥pklæ ¼å¼..."
python << 'EOF'
import pickle
with open('data/skeleton/ntu60_xsub_train.pkl', 'rb') as f:
    data = pickle.load(f)
print(f"ç±»å‹: {type(data)}")
if isinstance(data, dict):
    print("âœ“ å·²ç»æ˜¯å­—å…¸æ ¼å¼")
elif isinstance(data, list):
    print("âœ— æ˜¯åˆ—è¡¨æ ¼å¼ï¼Œéœ€è¦è½¬æ¢")
EOF

# ===== ç¬¬2æ­¥ï¼šè½¬æ¢æ ¼å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰=====
echo ""
echo "è½¬æ¢pklæ ¼å¼..."
python << 'EOF'
import pickle
import os

# åŠ è½½
with open('data/skeleton/ntu60_xsub_train.pkl', 'rb') as f:
    train_data = pickle.load(f)
with open('data/skeleton/ntu60_xsub_val.pkl', 'rb') as f:
    val_data = pickle.load(f)

# æ£€æŸ¥è§†é¢‘å‘½å
videos = os.listdir('data/nturgbd_videos/')
has_rgb_suffix = videos[0].endswith('_rgb.mp4')

print(f"è§†é¢‘ç¤ºä¾‹: {videos[0]}")
print(f"è§†é¢‘æœ‰_rgbåç¼€: {has_rgb_suffix}")
print(f"éª¨æ¶ç¤ºä¾‹: {train_data[0]['frame_dir']}")

# ç»Ÿä¸€å‘½åï¼šéƒ½åŠ _rgbï¼ˆå› ä¸ºè§†é¢‘æœ‰_rgbï¼‰
for item in train_data + val_data:
    if not item['frame_dir'].endswith('_rgb'):
        item['frame_dir'] = item['frame_dir'] + '_rgb'

# æ ‡å‡†æ ¼å¼
data = {
    'split': {
        'xsub_train': [item['frame_dir'] for item in train_data],
        'xsub_val': [item['frame_dir'] for item in val_data]
    },
    'annotations': train_data + val_data
}

# ä¿å­˜
with open('data/skeleton/ntu60_xsub.pkl', 'wb') as f:
    pickle.dump(data, f)

print(f"âœ“ ä¿å­˜åˆ°: data/skeleton/ntu60_xsub.pkl")
print(f"  è®­ç»ƒé›†: {len(data['split']['xsub_train'])}")
print(f"  éªŒè¯é›†: {len(data['split']['xsub_val'])}")
EOF

# ===== ç¬¬3æ­¥ï¼šéªŒè¯è§†é¢‘åŒ¹é… =====
echo ""
echo "éªŒè¯è§†é¢‘å’Œéª¨æ¶åŒ¹é…..."
python << 'EOF'
import pickle
import os

with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

# æ£€æŸ¥å‰10ä¸ªæ ·æœ¬
success = 0
for i in range(min(10, len(data['annotations']))):
    frame_dir = data['annotations'][i]['frame_dir']
    video_path = os.path.join('data/nturgbd_videos', frame_dir + '.mp4')
    if os.path.exists(video_path):
        success += 1
    else:
        print(f"âœ— ç¼ºå¤±: {frame_dir}.mp4")

print(f"\nåŒ¹é…ç‡: {success}/10")
if success == 10:
    print("âœ“ æ‰€æœ‰è§†é¢‘éƒ½åŒ¹é…ï¼")
else:
    print("âš ï¸ æœ‰è§†é¢‘ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥å‘½å")
EOF

# ===== ç¬¬4æ­¥ï¼šæµ‹è¯•æ•°æ®åŠ è½½ =====
echo ""
echo "æµ‹è¯•æ•°æ®åŠ è½½..."
python tools/analysis_tools/browse_dataset.py \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    --mode pipeline \
    --show-number 1 2>&1 | head -50

# å¦‚æœæ²¡æŠ¥é”™ï¼Œè¯´æ˜æ•°æ®åŠ è½½æˆåŠŸï¼
```

```shellscript
cd /home/zh/ChCode/codes01/mmaction2

# å•GPUæµ‹è¯•ï¼ˆå…ˆéªŒè¯èƒ½è·‘é€šï¼‰
CUDA_VISIBLE_DEVICES=0 python tools/train.py \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    --work-dir work_dirs/pcan_ntu60_test

# å¦‚æœå•GPUèƒ½è·‘ï¼Œå†ç”¨4GPU
bash tools/dist_train.sh \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    4
```

```shellscript
cd /home/zh/ChCode/codes01/mmaction2

# ä¿å­˜ä¸º fix_ntu60_data.sh
cat > fix_ntu60_data.sh << 'SCRIPT'
#!/bin/bash

echo "=========================================="
echo "ä¿®å¤NTU-60æ•°æ®æ ¼å¼"
echo "=========================================="

cd /home/zh/ChCode/codes01/mmaction2

# è½¬æ¢pklæ ¼å¼
python << 'EOF'
import pickle
import os

print("1. åŠ è½½pklæ–‡ä»¶...")
with open('data/skeleton/ntu60_xsub_train.pkl', 'rb') as f:
    train_data = pickle.load(f)
with open('data/skeleton/ntu60_xsub_val.pkl', 'rb') as f:
    val_data = pickle.load(f)

print(f"   è®­ç»ƒé›†: {len(train_data)}")
print(f"   éªŒè¯é›†: {len(val_data)}")

print("\n2. ç»Ÿä¸€å‘½åï¼ˆæ·»åŠ _rgbï¼‰...")
for item in train_data + val_data:
    if not item['frame_dir'].endswith('_rgb'):
        item['frame_dir'] = item['frame_dir'] + '_rgb'

print("\n3. è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼...")
data = {
    'split': {
        'xsub_train': [item['frame_dir'] for item in train_data],
        'xsub_val': [item['frame_dir'] for item in val_data]
    },
    'annotations': train_data + val_data
}

print("\n4. ä¿å­˜...")
with open('data/skeleton/ntu60_xsub.pkl', 'wb') as f:
    pickle.dump(data, f)

print("âœ“ å®Œæˆï¼")
print(f"  æ–‡ä»¶: data/skeleton/ntu60_xsub.pkl")
print(f"  æ€»æ ·æœ¬: {len(data['annotations'])}")

# éªŒè¯
sample = data['annotations'][0]
video_path = os.path.join('data/nturgbd_videos', sample['frame_dir'] + '.mp4')
if os.path.exists(video_path):
    print(f"âœ“ è§†é¢‘åŒ¹é…æµ‹è¯•é€šè¿‡")
else:
    print(f"âœ— è­¦å‘Šï¼š{video_path} ä¸å­˜åœ¨")
EOF

echo ""
echo "=========================================="
echo "ä¿®å¤å®Œæˆï¼"
echo "=========================================="
SCRIPT

# è¿è¡Œ
chmod +x fix_ntu60_data.sh
./fix_ntu60_data.sh
```

---

**User**

æ–°çš„é”™è¯¯ Traceback (most recent call last):

  File "tools/train.py", line 143, in <module>

    main()

  File "tools/train.py", line 139, in main

    runner.train()

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/runner.py", line 1777, in train

    model = self.train_loop.run()  # type: ignore

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/loops.py", line 98, in run

    self.run_epoch()

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/loops.py", line 115, in run_epoch

    self.run_iter(idx, data_batch)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/loops.py", line 131, in run_iter

    outputs = self.runner.model.train_step(

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py", line 114, in train_step

    losses = self._run_forward(data, mode='loss')  # type: ignore

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py", line 361, in _run_forward

    results = self(**data, mode=mode)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl

    return forward_call(*args, **kwargs)

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/models/recognizers/base.py", line 262, in forward

    s=self.loss(inputs, data_samples, **kwargs)

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/models/recognizers/base.py", line 176, in loss

    loss_cls = self.cls_head.loss(feats, data_samples, **loss_kwargs)

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/models/heads/rgbpose_head.py", line 690, in loss

    return self.loss_by_feat(cls_scores, data_samples)

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/models/heads/rgbpose_head.py", line 725, in loss_by_feat

    labels_body = labels.cpu().numpy()

RuntimeError: CUDA error: device-side assert triggered

CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.

For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.    ä»¥ä¸Šè¿™ä¸ªé”™è¯¯æ˜¯æˆ‘æ‰§è¡ŒCUDA_VISIBLE_DEVICES=1 python tools/train.py \

    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \

    --work-dir work_dirs/pcan_ntu60_test   å› ä¸ºç›®å‰å¡0 æœ‰äººç”¨æ‰€ä»¥æˆ‘æ¢æˆäº†å¡1  è¿™æ˜¯ä»€ä¹ˆåŸå› ç»™æŠ¥é”™å•Š

---

**Cursor**

**CUDAé”™è¯¯é€šå¸¸æ˜¯æ ‡ç­¾è¶Šç•Œï¼** è®©æˆ‘å¸®ä½ è¯Šæ–­é—®é¢˜æ‰€åœ¨ã€‚

```python
labels_body = labels.cpu().numpy()
labels_body = np.array([action2body(i) for i in labels_body])
labels_body = torch.tensor(labels_body).cuda()
```

**æ‰¾åˆ°é—®é¢˜äº†ï¼** è¿™æ˜¯å…¸å‹çš„**æ ‡ç­¾è¶Šç•Œ**é”™è¯¯ã€‚è®©æˆ‘å¸®ä½ å®šä½å…·ä½“åŸå› ï¼š

## ğŸ” é—®é¢˜è¯Šæ–­

é”™è¯¯å‘ç”Ÿåœ¨ç¬¬696-698è¡Œï¼Œè°ƒç”¨`action2body`å‡½æ•°æ—¶ï¼š

```python
labels_body = labels.cpu().numpy()
labels_body = np.array([action2body(i) for i in labels_body])  # â† è¿™é‡Œï¼
```

**é—®é¢˜**ï¼š`action2body`å‡½æ•°æ˜¯ä¸ºMA-52è®¾è®¡çš„ï¼ˆå¤„ç†0-51æ ‡ç­¾ï¼‰ï¼Œä½†NTU-60çš„æ ‡ç­¾å¯èƒ½æ˜¯ï¼š
- **1-60**ï¼ˆåŸå§‹NTUæ ‡ç­¾ï¼‰â†’ éœ€è¦å‡1å˜æˆ0-59
- **0-59**ï¼ˆå·²è½¬æ¢ï¼‰ â†’ ä½†`action2body`ä¸è®¤è¯†è¿™äº›å€¼

## ğŸ”§ å¿«é€Ÿè¯Šæ–­ï¼šæ£€æŸ¥æ ‡ç­¾èŒƒå›´

```bash
cd /home/zh/ChCode/codes01/mmaction2

# è¿è¡Œè¿™ä¸ªæ£€æŸ¥NTU-60æ ‡ç­¾çš„å®é™…èŒƒå›´
CUDA_LAUNCH_BLOCKING=1 python << 'EOF'
import pickle
import numpy as np

# åŠ è½½NTU-60æ•°æ®
with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

# æ£€æŸ¥æ‰€æœ‰æ ‡ç­¾
labels = [ann['label'] for ann in data['annotations']]
print(f"æ€»æ ·æœ¬æ•°: {len(labels)}")
print(f"æ ‡ç­¾èŒƒå›´: [{min(labels)}, {max(labels)}]")
print(f"å”¯ä¸€æ ‡ç­¾æ•°: {len(set(labels))}")

# æ£€æŸ¥æ˜¯å¦æœ‰è¶Šç•Œ
if min(labels) < 0:
    print(f"âœ— é”™è¯¯ï¼šæœ‰è´Ÿæ•°æ ‡ç­¾ï¼")
if max(labels) > 59:
    print(f"âœ— é”™è¯¯ï¼šæ ‡ç­¾è¶…è¿‡59ï¼")
    print(f"  æœ€å¤§æ ‡ç­¾æ˜¯: {max(labels)}")
    print(f"  è¿™è¯´æ˜æ ‡ç­¾æ˜¯1-60ï¼Œéœ€è¦å‡1")
elif max(labels) == 59:
    print(f"âœ“ æ ‡ç­¾èŒƒå›´æ­£ç¡® (0-59)")
    
# ç»Ÿè®¡åˆ†å¸ƒ
from collections import Counter
label_dist = Counter(labels)
print(f"\næ ‡ç­¾åˆ†å¸ƒï¼ˆå‰10ä¸ªï¼‰:")
for label, count in sorted(label_dist.items())[:10]:
    print(f"  æ ‡ç­¾{label}: {count}ä¸ªæ ·æœ¬")
EOF
```

## ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼ˆæ ¹æ®è¯Šæ–­ç»“æœï¼‰

### æƒ…å†µAï¼šå¦‚æœæ ‡ç­¾æ˜¯1-60ï¼ˆéœ€è¦å‡1ï¼‰

ä¿®æ”¹pklæ–‡ä»¶ï¼š

```bash
python << 'EOF'
import pickle

print("ä¿®æ­£NTU-60æ ‡ç­¾ï¼ˆ1-60 â†’ 0-59ï¼‰...")

# åŠ è½½
with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

# æ£€æŸ¥å¹¶ä¿®æ­£æ ‡ç­¾
labels_before = [ann['label'] for ann in data['annotations']]
print(f"ä¿®æ­£å‰: æ ‡ç­¾èŒƒå›´ [{min(labels_before)}, {max(labels_before)}]")

if min(labels_before) == 1:  # æ ‡ç­¾ä»1å¼€å§‹
    print("âœ“ æ£€æµ‹åˆ°æ ‡ç­¾ä»1å¼€å§‹ï¼Œæ‰§è¡Œå‡1æ“ä½œ...")
    for ann in data['annotations']:
        ann['label'] = ann['label'] - 1
    
    labels_after = [ann['label'] for ann in data['annotations']]
    print(f"ä¿®æ­£å: æ ‡ç­¾èŒƒå›´ [{min(labels_after)}, {max(labels_after)}]")
    
    # ä¿å­˜
    with open('data/skeleton/ntu60_xsub.pkl', 'wb') as f:
        pickle.dump(data, f)
    print("âœ“ å·²ä¿å­˜ä¿®æ­£åçš„pkl")
else:
    print("âœ“ æ ‡ç­¾å·²ç»ä»0å¼€å§‹ï¼Œæ— éœ€ä¿®æ­£")
EOF
```

### æƒ…å†µBï¼šå¦‚æœæ ‡ç­¾æ˜¯0-59ï¼ˆaction2bodyå‡½æ•°é—®é¢˜ï¼‰

ä¿®æ”¹ `mmaction/models/heads/rgbpose_head.py` ç¬¬17-31è¡Œï¼š

```python
def action2body(x):
    """
    MA-52çš„actionåˆ°bodyæ˜ å°„ï¼ˆ0-51 â†’ 0-6ï¼‰
    """
    if x <= 4:
        return 0
    elif 5 <= x <= 10:
        return 1
    elif 11 <= x <= 23:
        return 2
    elif 24 <= x <= 31:
        return 3
    elif 32 <= x <= 37:
        return 4
    elif 38 <= x <= 47:
        return 5
    else:
        return 6

def action2body_ntu60(x):
    """
    NTU-60çš„actionåˆ°bodyæ˜ å°„ï¼ˆ0-59 â†’ 0-7ï¼‰
    æŒ‰æ¯8ä¸ªåŠ¨ä½œä¸€ç»„
    """
    if x < 0 or x > 59:
        print(f"è­¦å‘Šï¼šæ ‡ç­¾{x}è¶Šç•Œï¼")
        return 0
    return min(x // 8, 7)  # 0-7, 8-15, ..., 56-59 â†’ 0-7
```

ç„¶åä¿®æ”¹ç¬¬696-698è¡Œï¼Œä½¿ç”¨NTU-60çš„æ˜ å°„ï¼š

```python
# ç¬¬696-698è¡Œä¿®æ”¹ä¸ºï¼š
labels_body = labels.cpu().numpy()

# æ ¹æ®æœ€å¤§æ ‡ç­¾åˆ¤æ–­ä½¿ç”¨å“ªä¸ªæ˜ å°„
max_label = labels_body.max()
if max_label >= 52:  # NTU-60
    labels_body = np.array([action2body_ntu60(i) for i in labels_body])
else:  # MA-52
    labels_body = np.array([action2body(i) for i in labels_body])

labels_body = torch.tensor(labels_body).cuda()
```

### æƒ…å†µCï¼šF.one_hotçš„num_classesé”™è¯¯

é—®é¢˜å¯èƒ½åœ¨ç¬¬738è¡Œï¼š

```python
labels = F.one_hot(labels, num_classes=self.num_classes)
```

å¦‚æœ`self.num_classes=60`ä½†æ ‡ç­¾æ˜¯1-60ï¼Œä¼šè¶Šç•Œï¼

---

## ğŸš€ å®Œæ•´çš„ä¿®å¤è„šæœ¬

```bash
cd /home/zh/ChCode/codes01/mmaction2

# ===== ç¬¬1æ­¥ï¼šè¯Šæ–­æ ‡ç­¾èŒƒå›´ =====
echo "=========================================="
echo "è¯Šæ–­æ ‡ç­¾èŒƒå›´"
echo "=========================================="

CUDA_LAUNCH_BLOCKING=1 python << 'EOF'
import pickle
import numpy as np

with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

labels = [ann['label'] for ann in data['annotations']]
print(f"æ ‡ç­¾èŒƒå›´: [{min(labels)}, {max(labels)}]")
print(f"å”¯ä¸€æ ‡ç­¾æ•°: {len(set(labels))}")

if min(labels) == 0 and max(labels) == 59:
    print("âœ“ æ ‡ç­¾æ ¼å¼æ­£ç¡® (0-59)")
    print("  é—®é¢˜åœ¨action2bodyå‡½æ•°")
elif min(labels) == 1 and max(labels) == 60:
    print("âœ— æ ‡ç­¾éœ€è¦å‡1 (å½“å‰1-60ï¼Œåº”è¯¥0-59)")
    print("  æ‰§è¡Œæ­¥éª¤2çš„ä¿®æ­£è„šæœ¬")
else:
    print(f"âš ï¸ å¼‚å¸¸æ ‡ç­¾èŒƒå›´")
EOF

# ===== ç¬¬2æ­¥ï¼šä¿®æ­£æ ‡ç­¾ï¼ˆå¦‚æœéœ€è¦ï¼‰=====
echo ""
echo "ä¿®æ­£æ ‡ç­¾èŒƒå›´..."

python << 'EOF'
import pickle

with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

labels = [ann['label'] for ann in data['annotations']]
min_label, max_label = min(labels), max(labels)

if min_label == 1:
    print(f"ä¿®æ­£æ ‡ç­¾: {min_label}-{max_label} â†’ {min_label-1}-{max_label-1}")
    for ann in data['annotations']:
        ann['label'] = ann['label'] - 1
    
    with open('data/skeleton/ntu60_xsub.pkl', 'wb') as f:
        pickle.dump(data, f)
    print("âœ“ å·²ä¿å­˜")
else:
    print("âœ“ æ ‡ç­¾æ— éœ€ä¿®æ­£")
EOF

# ===== ç¬¬3æ­¥ï¼šéªŒè¯ä¿®æ­£ =====
echo ""
echo "éªŒè¯..."

python << 'EOF'
import pickle
with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)
labels = [ann['label'] for ann in data['annotations']]
print(f"æœ€ç»ˆæ ‡ç­¾èŒƒå›´: [{min(labels)}, {max(labels)}]")
if min(labels) == 0 and max(labels) == 59:
    print("âœ“ æ ‡ç­¾æ ¼å¼æ­£ç¡®ï¼")
else:
    print(f"âœ— ä»æœ‰é—®é¢˜")
EOF

echo ""
echo "=========================================="
echo "ä¿®å¤å®Œæˆï¼"
echo "=========================================="
```

---

## ğŸ“ ä¿®æ”¹ä»£ç æ–‡ä»¶

### ä¿®æ”¹1ï¼š`mmaction/models/heads/rgbpose_head.py`

åœ¨ç¬¬17è¡Œåæ·»åŠ NTU-60æ˜ å°„å‡½æ•°ï¼š

```python
def action2body(x):
    """MA-52: 0-51 â†’ 0-6"""
    if x <= 4:
        return 0
    elif 5 <= x <= 10:
        return 1
    elif 11 <= x <= 23:
        return 2
    elif 24 <= x <= 31:
        return 3
    elif 32 <= x <= 37:
        return 4
    elif 38 <= x <= 47:
        return 5
    else:
        return 6

def action2body_ntu60(x):
    """
    NTU-60: 0-59 â†’ 0-7
    æ¯8ä¸ªåŠ¨ä½œä¸€ç»„
    """
    if x < 0 or x > 59:
        # å¼‚å¸¸æ ‡ç­¾ï¼Œè¿”å›0é¿å…å´©æºƒ
        return 0
    return min(x // 8, 7)  # 0-7, 8-15, ..., 56-59 â†’ ç±»åˆ«0-7
```

ç„¶åä¿®æ”¹ç¬¬696-698è¡Œï¼š

```python
# åŸä»£ç ï¼ˆç¬¬696-698è¡Œï¼‰ï¼š
labels_body = labels.cpu().numpy()
labels_body = np.array([action2body(i) for i in labels_body])
labels_body = torch.tensor(labels_body).cuda()

# ä¿®æ”¹ä¸ºï¼š
labels_body = labels.cpu().numpy()

# æ ¹æ®æ ‡ç­¾èŒƒå›´åˆ¤æ–­æ•°æ®é›†
max_label = int(labels_body.max())
if max_label >= 52:  # NTU-60 (0-59)
    labels_body = np.array([action2body_ntu60(int(i)) for i in labels_body])
else:  # MA-52 (0-51)
    labels_body = np.array([action2body(int(i)) for i in labels_body])

labels_body = torch.tensor(labels_body, dtype=torch.long).cuda()
```

### ä¿®æ”¹2ï¼š`mmaction/models/recognizers/recognizer3d_mm.py`

åŒæ ·åœ¨ç¬¬10è¡Œåæ·»åŠ NTU-60æ˜ å°„ï¼š

```python
def fine2coarse(x):
    """MA-52æ˜ å°„"""
    if x<=4:
        return 0
    elif 5<=x<=10:
        return 1
    elif 11<=x<=23:
        return 2
    elif 24<=x<=31:
        return 3
    elif 32<=x<=37:
        return 4
    elif 38<=x<=47:
        return 5
    else:
        return 6

def fine2coarse_ntu60(x):
    """NTU-60æ˜ å°„ï¼š0-59 â†’ 0-7"""
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)
```

ç„¶åä¿®æ”¹ç¬¬62è¡Œï¼š

```python
# åŸä»£ç ï¼ˆç¬¬62è¡Œï¼‰ï¼š
gts_coarse=[fine2coarse(i) for i in temp]

# ä¿®æ”¹ä¸ºï¼š
max_label = int(temp.max())
if max_label >= 52:  # NTU-60
    gts_coarse = [fine2coarse_ntu60(int(i)) for i in temp]
else:  # MA-52
    gts_coarse = [fine2coarse(int(i)) for i in temp]
```

---

## ğŸ¯ å®Œæ•´çš„ä»£ç ä¿®æ”¹æ¸…å•

ç”±äºä½ åœ¨askæ¨¡å¼ï¼Œæˆ‘æŠŠéœ€è¦ä¿®æ”¹çš„ä»£ç éƒ½åˆ—å‡ºæ¥ï¼Œä½ æ‰‹åŠ¨ä¿®æ”¹ï¼š

### æ–‡ä»¶1ï¼š`mmaction/models/heads/rgbpose_head.py`

**ä½ç½®1**ï¼šç¬¬17è¡Œåæ·»åŠ 

```python
def action2body_ntu60(x):
    """NTU-60: 0-59 â†’ 0-7, æ¯8ä¸ªåŠ¨ä½œä¸€ç»„"""
    x = int(x)
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)
```

**ä½ç½®2**ï¼šç¬¬696-698è¡Œä¿®æ”¹

```python
# åŸä»£ç ï¼š
labels_body = labels.cpu().numpy()
labels_body = np.array([action2body(i) for i in labels_body])
labels_body = torch.tensor(labels_body).cuda()

# æ”¹ä¸ºï¼š
labels_body = labels.cpu().numpy()
max_label = int(labels_body.max())
if max_label >= 52:
    labels_body = np.array([action2body_ntu60(int(i)) for i in labels_body])
else:
    labels_body = np.array([action2body(int(i)) for i in labels_body])
labels_body = torch.tensor(labels_body, dtype=torch.long).cuda()
```

### æ–‡ä»¶2ï¼š`mmaction/models/recognizers/recognizer3d_mm.py`

**ä½ç½®1**ï¼šç¬¬24è¡Œåæ·»åŠ 

```python
def fine2coarse_ntu60(x):
    """NTU-60: 0-59 â†’ 0-7"""
    x = int(x)
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)
```

**ä½ç½®2**ï¼šç¬¬62è¡Œä¿®æ”¹

```python
# åŸä»£ç ï¼š
gts_coarse=[fine2coarse(i) for i in temp]

# æ”¹ä¸ºï¼š
max_label = int(temp.max())
if max_label >= 52:
    gts_coarse = [fine2coarse_ntu60(int(i)) for i in temp]
else:
    gts_coarse = [fine2coarse(int(i)) for i in temp]
```

---

## ğŸ”„ ä¿®å¤åé‡æ–°è®­ç»ƒ

```bash
cd /home/zh/ChCode/codes01/mmaction2

# å…ˆç¡®ä¿æ ‡ç­¾ä¿®æ­£äº†
python << 'EOF'
import pickle
with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)
labels = [ann['label'] for ann in data['annotations']]
print(f"æ ‡ç­¾èŒƒå›´: [{min(labels)}, {max(labels)}]")
assert min(labels) == 0 and max(labels) == 59, "æ ‡ç­¾èŒƒå›´ä¸å¯¹ï¼"
print("âœ“ æ ‡ç­¾æ£€æŸ¥é€šè¿‡")
EOF

# ç„¶åé‡æ–°è®­ç»ƒï¼ˆä½¿ç”¨CUDA_LAUNCH_BLOCKING=1ä¾¿äºè°ƒè¯•ï¼‰
CUDA_VISIBLE_DEVICES=1 CUDA_LAUNCH_BLOCKING=1 python tools/train.py \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    --work-dir work_dirs/pcan_ntu60_test
```

---

## ğŸ¯ å¦‚æœè¿˜æŠ¥é”™ï¼Œç”¨è¿™ä¸ªè¶…è¯¦ç»†è¯Šæ–­

```bash
# åˆ›å»ºè¯Šæ–­è„šæœ¬
cat > diagnose_labels.py << 'EOF'
import pickle
import numpy as np
import torch

print("="*60)
print("NTU-60æ ‡ç­¾è¯Šæ–­")
print("="*60)

# 1. æ£€æŸ¥pkl
with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

labels = np.array([ann['label'] for ann in data['annotations']])
print(f"\n1. æ ‡ç­¾ç»Ÿè®¡:")
print(f"   èŒƒå›´: [{labels.min()}, {labels.max()}]")
print(f"   å”¯ä¸€å€¼: {len(np.unique(labels))}")
print(f"   æ•°æ®ç±»å‹: {labels.dtype}")

# 2. æµ‹è¯•action2body_ntu60
print(f"\n2. æµ‹è¯•ç²—åˆ†ç±»æ˜ å°„:")
def action2body_ntu60(x):
    x = int(x)
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)

test_labels = [0, 10, 20, 30, 40, 50, 59]
for lbl in test_labels:
    coarse = action2body_ntu60(lbl)
    print(f"   {lbl} â†’ {coarse}")

# 3. æµ‹è¯•æ‰€æœ‰æ ‡ç­¾çš„ç²—åˆ†ç±»
coarse_labels = np.array([action2body_ntu60(int(i)) for i in labels])
print(f"\n3. ç²—åˆ†ç±»æ ‡ç­¾:")
print(f"   èŒƒå›´: [{coarse_labels.min()}, {coarse_labels.max()}]")
print(f"   å”¯ä¸€å€¼: {len(np.unique(coarse_labels))}")

# 4. æµ‹è¯•one_hot
print(f"\n4. æµ‹è¯•one_hot:")
try:
    labels_tensor = torch.tensor(labels[:10], dtype=torch.long)
    one_hot = torch.nn.functional.one_hot(labels_tensor, num_classes=60)
    print(f"   âœ“ one_hotæˆåŠŸ: {one_hot.shape}")
except Exception as e:
    print(f"   âœ— one_hotå¤±è´¥: {e}")

# 5. æµ‹è¯•ç²—åˆ†ç±»one_hot
print(f"\n5. æµ‹è¯•ç²—åˆ†ç±»one_hot:")
try:
    coarse_tensor = torch.tensor(coarse_labels[:10], dtype=torch.long)
    one_hot = torch.nn.functional.one_hot(coarse_tensor, num_classes=8)
    print(f"   âœ“ one_hotæˆåŠŸ: {one_hot.shape}")
except Exception as e:
    print(f"   âœ— one_hotå¤±è´¥: {e}")

print("\n" + "="*60)
print("è¯Šæ–­å®Œæˆï¼")
print("="*60)
EOF

python diagnose_labels.py
```

---

## ğŸ“‹ æ€»ç»“ï¼šéœ€è¦åšçš„ä¿®æ”¹

### âœ… å¿…é¡»æ‰§è¡Œ

1. **ä¿®æ­£æ ‡ç­¾èŒƒå›´**ï¼ˆå¦‚æœæ˜¯1-60ï¼‰
2. **æ·»åŠ `action2body_ntu60`å‡½æ•°**åˆ°ä¸¤ä¸ªæ–‡ä»¶
3. **ä¿®æ”¹ä¸¤å¤„è°ƒç”¨**ä½¿ç”¨NTU-60çš„æ˜ å°„

### âœ… é…ç½®æ–‡ä»¶ç¡®è®¤

ç¡®ä¿ `pcan_ntu60.py` ä¸­ï¼š

```python
head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,  # â† ç¡®è®¤æ˜¯60
    num_coarse_classes=8,  # â† æ·»åŠ è¿™ä¸ªï¼NTU-60ç”¨8ä¸ªç²—ç±»
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose', 'rgb_coarse', 'pose_coarse'],
    loss_weights=[1., 1., 0.5, 0.5],
    average_clips='prob')
```

---

## ğŸ¯ å¿«é€Ÿæµ‹è¯•checklist

ä¿®æ”¹å®Œæˆåï¼ŒæŒ‰é¡ºåºæ£€æŸ¥ï¼š

```bash
# âœ“ 1. æ ‡ç­¾èŒƒå›´
python -c "import pickle; data=pickle.load(open('data/skeleton/ntu60_xsub.pkl','rb')); labels=[a['label'] for a in data['annotations']]; print(f'[{min(labels)}, {max(labels)}]')"
# åº”è¯¥è¾“å‡º: [0, 59]

# âœ“ 2. pklæ ¼å¼
python -c "import pickle; data=pickle.load(open('data/skeleton/ntu60_xsub.pkl','rb')); print(type(data), list(data.keys()))"
# åº”è¯¥è¾“å‡º: <class 'dict'> ['split', 'annotations']

# âœ“ 3. splitå­˜åœ¨
python -c "import pickle; data=pickle.load(open('data/skeleton/ntu60_xsub.pkl','rb')); print(list(data['split'].keys()))"
# åº”è¯¥è¾“å‡º: ['xsub_train', 'xsub_val']

# âœ“ 4. è§†é¢‘åŒ¹é…
python -c "import pickle,os; data=pickle.load(open('data/skeleton/ntu60_xsub.pkl','rb')); f=data['annotations'][0]['frame_dir']; print('å­˜åœ¨' if os.path.exists(f'data/nturgbd_videos/{f}.mp4') else 'ä¸å­˜åœ¨')"
# åº”è¯¥è¾“å‡º: å­˜åœ¨
```

å…¨éƒ¨é€šè¿‡åï¼Œå†è¿è¡Œè®­ç»ƒï¼

å…ˆè¿è¡Œè¿™äº›æ£€æŸ¥ï¼ŒæŠŠç»“æœå‘Šè¯‰æˆ‘ï¼Œæˆ‘ä»¬ç»§ç»­è°ƒè¯•ï¼ğŸ”§

```python
labels_body = labels.cpu().numpy()
labels_body = np.array([action2body(i) for i in labels_body])  # â† è¿™é‡Œï¼
```

```shellscript
cd /home/zh/ChCode/codes01/mmaction2

# è¿è¡Œè¿™ä¸ªæ£€æŸ¥NTU-60æ ‡ç­¾çš„å®é™…èŒƒå›´
CUDA_LAUNCH_BLOCKING=1 python << 'EOF'
import pickle
import numpy as np

# åŠ è½½NTU-60æ•°æ®
with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

# æ£€æŸ¥æ‰€æœ‰æ ‡ç­¾
labels = [ann['label'] for ann in data['annotations']]
print(f"æ€»æ ·æœ¬æ•°: {len(labels)}")
print(f"æ ‡ç­¾èŒƒå›´: [{min(labels)}, {max(labels)}]")
print(f"å”¯ä¸€æ ‡ç­¾æ•°: {len(set(labels))}")

# æ£€æŸ¥æ˜¯å¦æœ‰è¶Šç•Œ
if min(labels) < 0:
    print(f"âœ— é”™è¯¯ï¼šæœ‰è´Ÿæ•°æ ‡ç­¾ï¼")
if max(labels) > 59:
    print(f"âœ— é”™è¯¯ï¼šæ ‡ç­¾è¶…è¿‡59ï¼")
    print(f"  æœ€å¤§æ ‡ç­¾æ˜¯: {max(labels)}")
    print(f"  è¿™è¯´æ˜æ ‡ç­¾æ˜¯1-60ï¼Œéœ€è¦å‡1")
elif max(labels) == 59:
    print(f"âœ“ æ ‡ç­¾èŒƒå›´æ­£ç¡® (0-59)")
    
# ç»Ÿè®¡åˆ†å¸ƒ
from collections import Counter
label_dist = Counter(labels)
print(f"\næ ‡ç­¾åˆ†å¸ƒï¼ˆå‰10ä¸ªï¼‰:")
for label, count in sorted(label_dist.items())[:10]:
    print(f"  æ ‡ç­¾{label}: {count}ä¸ªæ ·æœ¬")
EOF
```

```shellscript
python << 'EOF'
import pickle

print("ä¿®æ­£NTU-60æ ‡ç­¾ï¼ˆ1-60 â†’ 0-59ï¼‰...")

# åŠ è½½
with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

# æ£€æŸ¥å¹¶ä¿®æ­£æ ‡ç­¾
labels_before = [ann['label'] for ann in data['annotations']]
print(f"ä¿®æ­£å‰: æ ‡ç­¾èŒƒå›´ [{min(labels_before)}, {max(labels_before)}]")

if min(labels_before) == 1:  # æ ‡ç­¾ä»1å¼€å§‹
    print("âœ“ æ£€æµ‹åˆ°æ ‡ç­¾ä»1å¼€å§‹ï¼Œæ‰§è¡Œå‡1æ“ä½œ...")
    for ann in data['annotations']:
        ann['label'] = ann['label'] - 1
    
    labels_after = [ann['label'] for ann in data['annotations']]
    print(f"ä¿®æ­£å: æ ‡ç­¾èŒƒå›´ [{min(labels_after)}, {max(labels_after)}]")
    
    # ä¿å­˜
    with open('data/skeleton/ntu60_xsub.pkl', 'wb') as f:
        pickle.dump(data, f)
    print("âœ“ å·²ä¿å­˜ä¿®æ­£åçš„pkl")
else:
    print("âœ“ æ ‡ç­¾å·²ç»ä»0å¼€å§‹ï¼Œæ— éœ€ä¿®æ­£")
EOF
```

```python
def action2body(x):
    """
    MA-52çš„actionåˆ°bodyæ˜ å°„ï¼ˆ0-51 â†’ 0-6ï¼‰
    """
    if x <= 4:
        return 0
    elif 5 <= x <= 10:
        return 1
    elif 11 <= x <= 23:
        return 2
    elif 24 <= x <= 31:
        return 3
    elif 32 <= x <= 37:
        return 4
    elif 38 <= x <= 47:
        return 5
    else:
        return 6

def action2body_ntu60(x):
    """
    NTU-60çš„actionåˆ°bodyæ˜ å°„ï¼ˆ0-59 â†’ 0-7ï¼‰
    æŒ‰æ¯8ä¸ªåŠ¨ä½œä¸€ç»„
    """
    if x < 0 or x > 59:
        print(f"è­¦å‘Šï¼šæ ‡ç­¾{x}è¶Šç•Œï¼")
        return 0
    return min(x // 8, 7)  # 0-7, 8-15, ..., 56-59 â†’ 0-7
```

```python
# ç¬¬696-698è¡Œä¿®æ”¹ä¸ºï¼š
labels_body = labels.cpu().numpy()

# æ ¹æ®æœ€å¤§æ ‡ç­¾åˆ¤æ–­ä½¿ç”¨å“ªä¸ªæ˜ å°„
max_label = labels_body.max()
if max_label >= 52:  # NTU-60
    labels_body = np.array([action2body_ntu60(i) for i in labels_body])
else:  # MA-52
    labels_body = np.array([action2body(i) for i in labels_body])

labels_body = torch.tensor(labels_body).cuda()
```

```python
labels = F.one_hot(labels, num_classes=self.num_classes)
```

```shellscript
cd /home/zh/ChCode/codes01/mmaction2

# ===== ç¬¬1æ­¥ï¼šè¯Šæ–­æ ‡ç­¾èŒƒå›´ =====
echo "=========================================="
echo "è¯Šæ–­æ ‡ç­¾èŒƒå›´"
echo "=========================================="

CUDA_LAUNCH_BLOCKING=1 python << 'EOF'
import pickle
import numpy as np

with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

labels = [ann['label'] for ann in data['annotations']]
print(f"æ ‡ç­¾èŒƒå›´: [{min(labels)}, {max(labels)}]")
print(f"å”¯ä¸€æ ‡ç­¾æ•°: {len(set(labels))}")

if min(labels) == 0 and max(labels) == 59:
    print("âœ“ æ ‡ç­¾æ ¼å¼æ­£ç¡® (0-59)")
    print("  é—®é¢˜åœ¨action2bodyå‡½æ•°")
elif min(labels) == 1 and max(labels) == 60:
    print("âœ— æ ‡ç­¾éœ€è¦å‡1 (å½“å‰1-60ï¼Œåº”è¯¥0-59)")
    print("  æ‰§è¡Œæ­¥éª¤2çš„ä¿®æ­£è„šæœ¬")
else:
    print(f"âš ï¸ å¼‚å¸¸æ ‡ç­¾èŒƒå›´")
EOF

# ===== ç¬¬2æ­¥ï¼šä¿®æ­£æ ‡ç­¾ï¼ˆå¦‚æœéœ€è¦ï¼‰=====
echo ""
echo "ä¿®æ­£æ ‡ç­¾èŒƒå›´..."

python << 'EOF'
import pickle

with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

labels = [ann['label'] for ann in data['annotations']]
min_label, max_label = min(labels), max(labels)

if min_label == 1:
    print(f"ä¿®æ­£æ ‡ç­¾: {min_label}-{max_label} â†’ {min_label-1}-{max_label-1}")
    for ann in data['annotations']:
        ann['label'] = ann['label'] - 1
    
    with open('data/skeleton/ntu60_xsub.pkl', 'wb') as f:
        pickle.dump(data, f)
    print("âœ“ å·²ä¿å­˜")
else:
    print("âœ“ æ ‡ç­¾æ— éœ€ä¿®æ­£")
EOF

# ===== ç¬¬3æ­¥ï¼šéªŒè¯ä¿®æ­£ =====
echo ""
echo "éªŒè¯..."

python << 'EOF'
import pickle
with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)
labels = [ann['label'] for ann in data['annotations']]
print(f"æœ€ç»ˆæ ‡ç­¾èŒƒå›´: [{min(labels)}, {max(labels)}]")
if min(labels) == 0 and max(labels) == 59:
    print("âœ“ æ ‡ç­¾æ ¼å¼æ­£ç¡®ï¼")
else:
    print(f"âœ— ä»æœ‰é—®é¢˜")
EOF

echo ""
echo "=========================================="
echo "ä¿®å¤å®Œæˆï¼"
echo "=========================================="
```

```python
def action2body(x):
    """MA-52: 0-51 â†’ 0-6"""
    if x <= 4:
        return 0
    elif 5 <= x <= 10:
        return 1
    elif 11 <= x <= 23:
        return 2
    elif 24 <= x <= 31:
        return 3
    elif 32 <= x <= 37:
        return 4
    elif 38 <= x <= 47:
        return 5
    else:
        return 6

def action2body_ntu60(x):
    """
    NTU-60: 0-59 â†’ 0-7
    æ¯8ä¸ªåŠ¨ä½œä¸€ç»„
    """
    if x < 0 or x > 59:
        # å¼‚å¸¸æ ‡ç­¾ï¼Œè¿”å›0é¿å…å´©æºƒ
        return 0
    return min(x // 8, 7)  # 0-7, 8-15, ..., 56-59 â†’ ç±»åˆ«0-7
```

```python
# åŸä»£ç ï¼ˆç¬¬696-698è¡Œï¼‰ï¼š
labels_body = labels.cpu().numpy()
labels_body = np.array([action2body(i) for i in labels_body])
labels_body = torch.tensor(labels_body).cuda()

# ä¿®æ”¹ä¸ºï¼š
labels_body = labels.cpu().numpy()

# æ ¹æ®æ ‡ç­¾èŒƒå›´åˆ¤æ–­æ•°æ®é›†
max_label = int(labels_body.max())
if max_label >= 52:  # NTU-60 (0-59)
    labels_body = np.array([action2body_ntu60(int(i)) for i in labels_body])
else:  # MA-52 (0-51)
    labels_body = np.array([action2body(int(i)) for i in labels_body])

labels_body = torch.tensor(labels_body, dtype=torch.long).cuda()
```

```python
def fine2coarse(x):
    """MA-52æ˜ å°„"""
    if x<=4:
        return 0
    elif 5<=x<=10:
        return 1
    elif 11<=x<=23:
        return 2
    elif 24<=x<=31:
        return 3
    elif 32<=x<=37:
        return 4
    elif 38<=x<=47:
        return 5
    else:
        return 6

def fine2coarse_ntu60(x):
    """NTU-60æ˜ å°„ï¼š0-59 â†’ 0-7"""
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)
```

```python
# åŸä»£ç ï¼ˆç¬¬62è¡Œï¼‰ï¼š
gts_coarse=[fine2coarse(i) for i in temp]

# ä¿®æ”¹ä¸ºï¼š
max_label = int(temp.max())
if max_label >= 52:  # NTU-60
    gts_coarse = [fine2coarse_ntu60(int(i)) for i in temp]
else:  # MA-52
    gts_coarse = [fine2coarse(int(i)) for i in temp]
```

```python
def action2body_ntu60(x):
    """NTU-60: 0-59 â†’ 0-7, æ¯8ä¸ªåŠ¨ä½œä¸€ç»„"""
    x = int(x)
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)
```

```python
# åŸä»£ç ï¼š
labels_body = labels.cpu().numpy()
labels_body = np.array([action2body(i) for i in labels_body])
labels_body = torch.tensor(labels_body).cuda()

# æ”¹ä¸ºï¼š
labels_body = labels.cpu().numpy()
max_label = int(labels_body.max())
if max_label >= 52:
    labels_body = np.array([action2body_ntu60(int(i)) for i in labels_body])
else:
    labels_body = np.array([action2body(int(i)) for i in labels_body])
labels_body = torch.tensor(labels_body, dtype=torch.long).cuda()
```

```python
def fine2coarse_ntu60(x):
    """NTU-60: 0-59 â†’ 0-7"""
    x = int(x)
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)
```

```python
# åŸä»£ç ï¼š
gts_coarse=[fine2coarse(i) for i in temp]

# æ”¹ä¸ºï¼š
max_label = int(temp.max())
if max_label >= 52:
    gts_coarse = [fine2coarse_ntu60(int(i)) for i in temp]
else:
    gts_coarse = [fine2coarse(int(i)) for i in temp]
```

```shellscript
cd /home/zh/ChCode/codes01/mmaction2

# å…ˆç¡®ä¿æ ‡ç­¾ä¿®æ­£äº†
python << 'EOF'
import pickle
with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)
labels = [ann['label'] for ann in data['annotations']]
print(f"æ ‡ç­¾èŒƒå›´: [{min(labels)}, {max(labels)}]")
assert min(labels) == 0 and max(labels) == 59, "æ ‡ç­¾èŒƒå›´ä¸å¯¹ï¼"
print("âœ“ æ ‡ç­¾æ£€æŸ¥é€šè¿‡")
EOF

# ç„¶åé‡æ–°è®­ç»ƒï¼ˆä½¿ç”¨CUDA_LAUNCH_BLOCKING=1ä¾¿äºè°ƒè¯•ï¼‰
CUDA_VISIBLE_DEVICES=1 CUDA_LAUNCH_BLOCKING=1 python tools/train.py \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    --work-dir work_dirs/pcan_ntu60_test
```

```shellscript
# åˆ›å»ºè¯Šæ–­è„šæœ¬
cat > diagnose_labels.py << 'EOF'
import pickle
import numpy as np
import torch

print("="*60)
print("NTU-60æ ‡ç­¾è¯Šæ–­")
print("="*60)

# 1. æ£€æŸ¥pkl
with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

labels = np.array([ann['label'] for ann in data['annotations']])
print(f"\n1. æ ‡ç­¾ç»Ÿè®¡:")
print(f"   èŒƒå›´: [{labels.min()}, {labels.max()}]")
print(f"   å”¯ä¸€å€¼: {len(np.unique(labels))}")
print(f"   æ•°æ®ç±»å‹: {labels.dtype}")

# 2. æµ‹è¯•action2body_ntu60
print(f"\n2. æµ‹è¯•ç²—åˆ†ç±»æ˜ å°„:")
def action2body_ntu60(x):
    x = int(x)
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)

test_labels = [0, 10, 20, 30, 40, 50, 59]
for lbl in test_labels:
    coarse = action2body_ntu60(lbl)
    print(f"   {lbl} â†’ {coarse}")

# 3. æµ‹è¯•æ‰€æœ‰æ ‡ç­¾çš„ç²—åˆ†ç±»
coarse_labels = np.array([action2body_ntu60(int(i)) for i in labels])
print(f"\n3. ç²—åˆ†ç±»æ ‡ç­¾:")
print(f"   èŒƒå›´: [{coarse_labels.min()}, {coarse_labels.max()}]")
print(f"   å”¯ä¸€å€¼: {len(np.unique(coarse_labels))}")

# 4. æµ‹è¯•one_hot
print(f"\n4. æµ‹è¯•one_hot:")
try:
    labels_tensor = torch.tensor(labels[:10], dtype=torch.long)
    one_hot = torch.nn.functional.one_hot(labels_tensor, num_classes=60)
    print(f"   âœ“ one_hotæˆåŠŸ: {one_hot.shape}")
except Exception as e:
    print(f"   âœ— one_hotå¤±è´¥: {e}")

# 5. æµ‹è¯•ç²—åˆ†ç±»one_hot
print(f"\n5. æµ‹è¯•ç²—åˆ†ç±»one_hot:")
try:
    coarse_tensor = torch.tensor(coarse_labels[:10], dtype=torch.long)
    one_hot = torch.nn.functional.one_hot(coarse_tensor, num_classes=8)
    print(f"   âœ“ one_hotæˆåŠŸ: {one_hot.shape}")
except Exception as e:
    print(f"   âœ— one_hotå¤±è´¥: {e}")

print("\n" + "="*60)
print("è¯Šæ–­å®Œæˆï¼")
print("="*60)
EOF

python diagnose_labels.py
```

```python
head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,  # â† ç¡®è®¤æ˜¯60
    num_coarse_classes=8,  # â† æ·»åŠ è¿™ä¸ªï¼NTU-60ç”¨8ä¸ªç²—ç±»
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose', 'rgb_coarse', 'pose_coarse'],
    loss_weights=[1., 1., 0.5, 0.5],
    average_clips='prob')
```

```shellscript
# âœ“ 1. æ ‡ç­¾èŒƒå›´
python -c "import pickle; data=pickle.load(open('data/skeleton/ntu60_xsub.pkl','rb')); labels=[a['label'] for a in data['annotations']]; print(f'[{min(labels)}, {max(labels)}]')"
# åº”è¯¥è¾“å‡º: [0, 59]

# âœ“ 2. pklæ ¼å¼
python -c "import pickle; data=pickle.load(open('data/skeleton/ntu60_xsub.pkl','rb')); print(type(data), list(data.keys()))"
# åº”è¯¥è¾“å‡º: <class 'dict'> ['split', 'annotations']

# âœ“ 3. splitå­˜åœ¨
python -c "import pickle; data=pickle.load(open('data/skeleton/ntu60_xsub.pkl','rb')); print(list(data['split'].keys()))"
# åº”è¯¥è¾“å‡º: ['xsub_train', 'xsub_val']

# âœ“ 4. è§†é¢‘åŒ¹é…
python -c "import pickle,os; data=pickle.load(open('data/skeleton/ntu60_xsub.pkl','rb')); f=data['annotations'][0]['frame_dir']; print('å­˜åœ¨' if os.path.exists(f'data/nturgbd_videos/{f}.mp4') else 'ä¸å­˜åœ¨')"
# åº”è¯¥è¾“å‡º: å­˜åœ¨
```

---

**User**

å†æ¬¡æŠ¥é”™ Traceback (most recent call last):

  File "tools/train.py", line 143, in <module>

    main()

  File "tools/train.py", line 139, in main

    runner.train()

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/runner.py", line 1777, in train

    model = self.train_loop.run()  # type: ignore

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/loops.py", line 98, in run

    self.run_epoch()

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/loops.py", line 115, in run_epoch

    self.run_iter(idx, data_batch)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/loops.py", line 131, in run_iter

    outputs = self.runner.model.train_step(

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py", line 114, in train_step

    losses = self._run_forward(data, mode='loss')  # type: ignore

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py", line 361, in _run_forward

    results = self(**data, mode=mode)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl

    return forward_call(*args, **kwargs)

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/models/recognizers/base.py", line 262, in forward

    s=self.loss(inputs, data_samples, **kwargs)

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/models/recognizers/base.py", line 176, in loss

    loss_cls = self.cls_head.loss(feats, data_samples, **loss_kwargs)

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/models/heads/rgbpose_head.py", line 700, in loss

    return self.loss_by_feat(cls_scores, data_samples)

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/models/heads/rgbpose_head.py", line 737, in loss_by_feat

    max_label = labels_body.max()

UnboundLocalError: local variable 'labels_body' referenced before assignment

---

**Cursor**

**å¥½çš„ï¼è¿™æ˜¯å˜é‡ä½œç”¨åŸŸé—®é¢˜ã€‚** è®©æˆ‘æŸ¥çœ‹å®Œæ•´çš„`loss_by_feat`æ–¹æ³•ï¼š

```python
max_label = int(labels_body.max())
if max_label >= 52:
    labels_body = np.array([action2body_ntu60(int(i)) for i in labels_body])
```

**çœ‹åˆ°é—®é¢˜äº†ï¼** ä½ æŠŠä»£ç æ”¾é”™ä½ç½®äº†ã€‚`labels_body`åœ¨`loss_by_feat`æ–¹æ³•ä¸­å®šä¹‰ï¼ˆç¬¬696è¡Œï¼‰ï¼Œä½†ä½ åœ¨`loss_by_scores`æ–¹æ³•ä¸­ä½¿ç”¨äº†å®ƒï¼ˆç¬¬737è¡Œï¼‰ã€‚

è®©æˆ‘ç»™ä½ å®Œæ•´çš„æ­£ç¡®ä¿®æ”¹ï¼š

## ğŸ“ æ­£ç¡®çš„ä¿®æ”¹ä½ç½®

### `mmaction/models/heads/rgbpose_head.py` å®Œæ•´ä¿®æ”¹

**ç¬¬1å¤„ï¼šåœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ å‡½æ•°ï¼ˆç¬¬32è¡Œä¹‹åï¼‰**

```python
def action2body(x):
    """MA-52æ˜ å°„"""
    if x <= 4:
        return 0
    elif 5 <= x <= 10:
        return 1
    elif 11 <= x <= 23:
        return 2
    elif 24 <= x <= 31:
        return 3
    elif 32 <= x <= 37:
        return 4
    elif 38 <= x <= 47:
        return 5
    else:
        return 6

def action2body_ntu60(x):
    """NTU-60æ˜ å°„ï¼š0-59 â†’ 0-7"""
    x = int(x)
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)
```

**ç¬¬2å¤„ï¼šä¿®æ”¹loss_by_featæ–¹æ³•ï¼ˆç¬¬676-714è¡Œï¼‰**

æ‰¾åˆ°æ•´ä¸ª`loss_by_feat`æ–¹æ³•ï¼Œå®Œæ•´æ›¿æ¢ä¸ºï¼š

```python
def loss_by_feat(self, cls_scores: Dict[str, torch.Tensor],
                 data_samples: SampleList) -> Dict:
    """Calculate the loss based on the features extracted by the head."""
    labels = torch.stack([x.gt_labels.item for x in data_samples])
    labels = labels.squeeze()

    if labels.shape == torch.Size([]):
        labels = labels.unsqueeze(0)
    elif labels.dim() == 1 and labels.size()[0] == self.num_classes \
            and cls_scores.size()[0] == 1:
        labels = labels.unsqueeze(0)

    losses = dict()
    
    # ========== åœ¨å¾ªç¯å‰åˆ¤æ–­æ•°æ®é›†ç±»å‹ ==========
    max_label = int(labels.max().item())
    is_ntu60 = (max_label >= 52)  # æ ‡ç­¾èŒƒå›´åˆ¤æ–­
    
    for loss_name, weight in zip(self.loss_components, self.loss_weights):
        cls_score1 = cls_scores[loss_name]
        loss_cls = self.loss_by_scores(cls_score1, labels)
        loss_cls = {loss_name + '_' + k: v for k, v in loss_cls.items()}
        loss_cls[f'{loss_name}_loss_cls'] *= weight
        losses.update(loss_cls)

        # ========== ä¿®æ”¹ï¼šä½¿ç”¨æ­£ç¡®çš„æ˜ å°„å‡½æ•° ==========
        labels_body = labels.cpu().numpy()
        if is_ntu60:  # NTU-60
            labels_body = np.array([action2body_ntu60(int(i)) for i in labels_body])
        else:  # MA-52
            labels_body = np.array([action2body(int(i)) for i in labels_body])
        labels_body = torch.tensor(labels_body, dtype=torch.long).cuda()

        cls_score2 = cls_scores[loss_name+'_coarse']
        loss_name = loss_name+'_coarse'
        loss_cls = self.loss_by_scores(cls_score2, labels_body)
        loss_cls = {loss_name + '_' + k: v for k, v in loss_cls.items()}
        loss_cls[f'{loss_name}_loss_cls'] *= weight
        losses.update(loss_cls)

    if self.training:
        losses['rgb_fr_coarse_loss'] = cls_scores['fr_loss_rgb_coarse'] / 5
        losses['pose_fr_coarse_loss'] = cls_scores['fr_loss_pose_coarse'] / 5
        losses['rgb_fr_loss'] = cls_scores['fr_loss_rgb']/5
        losses['pose_fr_loss'] = cls_scores['fr_loss_pose']/5
        losses['hierarchy_rgb_loss'] = cls_scores['hierarchy_loss_rgb']
        losses['hierarchy_pose_loss'] = cls_scores['hierarchy_loss_pose']
    return losses
```

**æ³¨æ„**ï¼š`loss_by_scores`æ–¹æ³•ï¼ˆç¬¬716-748è¡Œï¼‰**ä¸éœ€è¦ä¿®æ”¹**ï¼

---

## ğŸ“ `mmaction/models/recognizers/recognizer3d_mm.py` ä¿®æ”¹

**ç¬¬1å¤„ï¼šæ·»åŠ å‡½æ•°ï¼ˆç¬¬24è¡Œä¹‹åï¼‰**

```python
def fine2coarse(x):
    """MA-52æ˜ å°„"""
    if x<=4:
        return 0
    elif 5<=x<=10:
        return 1
    elif 11<=x<=23:
        return 2
    elif 24<=x<=31:
        return 3
    elif 32<=x<=37:
        return 4
    elif 38<=x<=47:
        return 5
    else:
        return 6

def fine2coarse_ntu60(x):
    """NTU-60æ˜ å°„ï¼š0-59 â†’ 0-7"""
    x = int(x)
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)
```

**ç¬¬2å¤„ï¼šä¿®æ”¹extract_featæ–¹æ³•ï¼ˆç¬¬56-65è¡Œï¼‰**

```python
# åŸä»£ç ï¼š
gts=[]
for data in data_samples:
    gts.extend(data.gt_labels.item)
gts=torch.stack(gts)
temp=gts.cpu().numpy()
gts_coarse=[fine2coarse(i) for i in temp]
gts_coarse=torch.from_numpy(np.array(gts_coarse)).cuda()

# ä¿®æ”¹ä¸ºï¼š
gts=[]
for data in data_samples:
    gts.extend(data.gt_labels.item)
gts=torch.stack(gts)
temp=gts.cpu().numpy()

# åˆ¤æ–­æ•°æ®é›†ç±»å‹
max_label = int(temp.max())
if max_label >= 52:  # NTU-60
    gts_coarse = [fine2coarse_ntu60(int(i)) for i in temp]
else:  # MA-52
    gts_coarse = [fine2coarse(int(i)) for i in temp]

gts_coarse=torch.from_numpy(np.array(gts_coarse)).cuda()
```

---

## ğŸ”‘ å…³é”®æé†’ï¼šä½œç”¨åŸŸé—®é¢˜

```python
# âŒ é”™è¯¯çš„ä¿®æ”¹ï¼ˆä½ ç°åœ¨çš„æƒ…å†µï¼‰
def loss_by_feat(...):
    # ... 
    for loss_name in ...:
        labels_body = ...  # åœ¨å¾ªç¯å†…å®šä¹‰
    
    # åœ¨å¾ªç¯å¤–ä½¿ç”¨ labels_body â† é”™è¯¯ï¼
    max_label = labels_body.max()  # UnboundLocalError

# âœ“ æ­£ç¡®çš„ä¿®æ”¹
def loss_by_feat(...):
    labels = ...
    max_label = labels.max()  # â† åœ¨å¾ªç¯å‰åˆ¤æ–­
    is_ntu60 = (max_label >= 52)
    
    for loss_name in ...:
        labels_body = ...
        if is_ntu60:  # â† åœ¨å¾ªç¯å†…ä½¿ç”¨åˆ¤æ–­ç»“æœ
            labels_body = action2body_ntu60(...)
        else:
            labels_body = action2body(...)
```

---

## ğŸ“‹ å®Œæ•´çš„ä»£ç æ–‡ä»¶å†…å®¹ï¼ˆç›´æ¥å¤åˆ¶ï¼‰

### æ–‡ä»¶1ï¼š`mmaction/models/heads/rgbpose_head.py`

åœ¨**ç¬¬17-31è¡Œ**ï¼Œå®Œæ•´æ›¿æ¢ä¸ºï¼š

```python
def action2body(x):
    """MA-52: action (0-51) â†’ body (0-6)"""
    if x <= 4:
        return 0
    elif 5 <= x <= 10:
        return 1
    elif 11 <= x <= 23:
        return 2
    elif 24 <= x <= 31:
        return 3
    elif 32 <= x <= 37:
        return 4
    elif 38 <= x <= 47:
        return 5
    else:
        return 6

def action2body_ntu60(x):
    """NTU-60: action (0-59) â†’ body (0-7), æ¯8ä¸ªåŠ¨ä½œä¸€ç»„"""
    x = int(x)
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)
```

åœ¨**ç¬¬663-714è¡Œ**ï¼Œå®Œæ•´æ›¿æ¢`loss_by_feat`æ–¹æ³•ï¼š

```python
def loss_by_feat(self, cls_scores: Dict[str, torch.Tensor],
                 data_samples: SampleList) -> Dict:
    """Calculate the loss based on the features extracted by the head.

    Args:
        cls_scores (dict[str, torch.Tensor]): The dict of
            classification scores,
        data_samples (list[:obj:`ActionDataSample`]): The batch
            data samples.

    Returns:
        dict: A dictionary of loss components.
    """
    labels = torch.stack([x.gt_labels.item for x in data_samples])
    labels = labels.squeeze()

    if labels.shape == torch.Size([]):
        labels = labels.unsqueeze(0)
    elif labels.dim() == 1 and labels.size()[0] == self.num_classes \
            and cls_scores.size()[0] == 1:
        # Fix a bug when training with soft labels and batch size is 1.
        # When using soft labels, `labels` and `cls_score` share the same
        # shape.
        labels = labels.unsqueeze(0)

    # ========== åˆ¤æ–­æ•°æ®é›†ï¼ˆåœ¨å¾ªç¯å‰ï¼‰==========
    max_label = int(labels.max().item())
    is_ntu60 = (max_label >= 52)  # NTU-60: 0-59, MA-52: 0-51
    
    losses = dict()
    for loss_name, weight in zip(self.loss_components, self.loss_weights):
        cls_score1 = cls_scores[loss_name]
        loss_cls = self.loss_by_scores(cls_score1, labels)
        loss_cls = {loss_name + '_' + k: v for k, v in loss_cls.items()}
        loss_cls[f'{loss_name}_loss_cls'] *= weight
        losses.update(loss_cls)

        # ========== è®¡ç®—ç²—åˆ†ç±»æ ‡ç­¾ ==========
        labels_body = labels.cpu().numpy()
        if is_ntu60:
            labels_body = np.array([action2body_ntu60(int(i)) for i in labels_body])
        else:
            labels_body = np.array([action2body(int(i)) for i in labels_body])
        labels_body = torch.tensor(labels_body, dtype=torch.long).cuda()

        cls_score2 = cls_scores[loss_name+'_coarse']
        loss_name = loss_name+'_coarse'
        loss_cls = self.loss_by_scores(cls_score2, labels_body)
        loss_cls = {loss_name + '_' + k: v for k, v in loss_cls.items()}
        loss_cls[f'{loss_name}_loss_cls'] *= weight
        losses.update(loss_cls)

    if self.training:
        losses['rgb_fr_coarse_loss'] = cls_scores['fr_loss_rgb_coarse'] / 5
        losses['pose_fr_coarse_loss'] = cls_scores['fr_loss_pose_coarse'] / 5
        losses['rgb_fr_loss'] = cls_scores['fr_loss_rgb']/5
        losses['pose_fr_loss'] = cls_scores['fr_loss_pose']/5
        losses['hierarchy_rgb_loss'] = cls_scores['hierarchy_loss_rgb']
        losses['hierarchy_pose_loss'] = cls_scores['hierarchy_loss_pose']
    return losses
```

**ç¬¬716-748è¡Œçš„`loss_by_scores`æ–¹æ³•ä¿æŒä¸å˜ï¼**

---

### æ–‡ä»¶2ï¼š`mmaction/models/recognizers/recognizer3d_mm.py`

åœ¨**ç¬¬10-24è¡Œ**ï¼Œå®Œæ•´æ›¿æ¢ä¸ºï¼š

```python
def fine2coarse(x):
    """MA-52: 0-51 â†’ 0-6"""
    if x<=4:
        return 0
    elif 5<=x<=10:
        return 1
    elif 11<=x<=23:
        return 2
    elif 24<=x<=31:
        return 3
    elif 32<=x<=37:
        return 4
    elif 38<=x<=47:
        return 5
    else:
        return 6

def fine2coarse_ntu60(x):
    """NTU-60: 0-59 â†’ 0-7"""
    x = int(x)
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)
```

åœ¨**ç¬¬56-65è¡Œ**ï¼Œä¿®æ”¹ä¸ºï¼š

```python
#get gt_label
gts=[]
for data in data_samples:
    gts.extend(data.gt_labels.item)
gts=torch.stack(gts)
temp=gts.cpu().numpy()

# åˆ¤æ–­æ•°æ®é›†
max_label = int(temp.max())
if max_label >= 52:  # NTU-60
    gts_coarse = [fine2coarse_ntu60(int(i)) for i in temp]
else:  # MA-52
    gts_coarse = [fine2coarse(int(i)) for i in temp]

gts_coarse=torch.from_numpy(np.array(gts_coarse)).cuda()
```

---

## ğŸ¯ æ£€æŸ¥ä½ çš„ä¿®æ”¹æ˜¯å¦æ­£ç¡®

è¿è¡Œè¿™ä¸ªéªŒè¯è„šæœ¬ï¼š

```bash
cd /home/zh/ChCode/codes01/mmaction2

# æ£€æŸ¥rgbpose_head.pyçš„ä¿®æ”¹
python << 'EOF'
import sys
sys.path.insert(0, '/home/zh/ChCode/codes01/mmaction2')

# å°è¯•å¯¼å…¥å‡½æ•°
try:
    from mmaction.models.heads.rgbpose_head import action2body, action2body_ntu60
    print("âœ“ action2bodyå‡½æ•°å¯¼å…¥æˆåŠŸ")
    print("âœ“ action2body_ntu60å‡½æ•°å¯¼å…¥æˆåŠŸ")
    
    # æµ‹è¯•æ˜ å°„
    print("\nMA-52æµ‹è¯•:")
    for x in [0, 5, 11, 24, 32, 38, 50]:
        print(f"  {x} â†’ {action2body(x)}")
    
    print("\nNTU-60æµ‹è¯•:")
    for x in [0, 8, 16, 24, 32, 40, 48, 56, 59]:
        print(f"  {x} â†’ {action2body_ntu60(x)}")
        
except ImportError as e:
    print(f"âœ— å¯¼å…¥å¤±è´¥: {e}")
except Exception as e:
    print(f"âœ— å‡½æ•°å®šä¹‰æœ‰é—®é¢˜: {e}")
EOF

# æ£€æŸ¥recognizer3d_mm.pyçš„ä¿®æ”¹
python << 'EOF'
import sys
sys.path.insert(0, '/home/zh/ChCode/codes01/mmaction2')

try:
    from mmaction.models.recognizers.recognizer3d_mm import fine2coarse, fine2coarse_ntu60
    print("\nâœ“ fine2coarseå‡½æ•°å¯¼å…¥æˆåŠŸ")
    print("âœ“ fine2coarse_ntu60å‡½æ•°å¯¼å…¥æˆåŠŸ")
    
    # æµ‹è¯•
    print("\nNTU-60æµ‹è¯•:")
    for x in [0, 10, 20, 30, 40, 50, 59]:
        print(f"  {x} â†’ {fine2coarse_ntu60(x)}")
        
except ImportError as e:
    print(f"âœ— å¯¼å…¥å¤±è´¥: {e}")
except Exception as e:
    print(f"âœ— å‡½æ•°å®šä¹‰æœ‰é—®é¢˜: {e}")
EOF
```

---

## ğŸ” å¦‚æœè¿˜æœ‰é—®é¢˜ï¼Œå®Œæ•´æ£€æŸ¥

```bash
cd /home/zh/ChCode/codes01/mmaction2

# åˆ›å»ºå®Œæ•´çš„æµ‹è¯•è„šæœ¬
cat > test_ntu60_setup.py << 'EOF'
import torch
import pickle
import numpy as np
import sys
sys.path.insert(0, '/home/zh/ChCode/codes01/mmaction2')

print("="*60)
print("NTU-60å®Œæ•´æ£€æŸ¥")
print("="*60)

# 1. æ£€æŸ¥pklæ•°æ®
print("\n1. æ£€æŸ¥pklæ•°æ®...")
with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

labels = [ann['label'] for ann in data['annotations']]
print(f"   æ ‡ç­¾èŒƒå›´: [{min(labels)}, {max(labels)}]")
print(f"   æ ·æœ¬æ•°: {len(labels)}")

if min(labels) != 0 or max(labels) != 59:
    print(f"   âœ— é”™è¯¯ï¼šæ ‡ç­¾åº”è¯¥æ˜¯0-59ï¼")
    exit(1)
else:
    print(f"   âœ“ æ ‡ç­¾èŒƒå›´æ­£ç¡®")

# 2. æ£€æŸ¥å‡½æ•°å¯¼å…¥
print("\n2. æ£€æŸ¥å‡½æ•°å¯¼å…¥...")
try:
    from mmaction.models.heads.rgbpose_head import action2body_ntu60
    from mmaction.models.recognizers.recognizer3d_mm import fine2coarse_ntu60
    print("   âœ“ æ‰€æœ‰å‡½æ•°å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"   âœ— å¯¼å…¥å¤±è´¥: {e}")
    exit(1)

# 3. æµ‹è¯•æ˜ å°„å‡½æ•°
print("\n3. æµ‹è¯•æ˜ å°„å‡½æ•°...")
test_labels = np.array([0, 10, 20, 30, 40, 50, 59])
mapped = [action2body_ntu60(int(x)) for x in test_labels]
print(f"   Action: {test_labels.tolist()}")
print(f"   Body:   {mapped}")

if max(mapped) <= 7 and min(mapped) >= 0:
    print("   âœ“ æ˜ å°„ç»“æœåœ¨0-7èŒƒå›´å†…")
else:
    print(f"   âœ— æ˜ å°„è¶Šç•Œï¼")
    exit(1)

# 4. æ¨¡æ‹Ÿä¸€ä¸ªbatchçš„å¤„ç†
print("\n4. æ¨¡æ‹Ÿbatchå¤„ç†...")
batch_labels = torch.tensor([0, 15, 30, 45, 59], dtype=torch.long)
print(f"   æ¨¡æ‹Ÿæ ‡ç­¾: {batch_labels.tolist()}")

max_label = int(batch_labels.max().item())
print(f"   æœ€å¤§æ ‡ç­¾: {max_label}")

is_ntu60 = (max_label >= 52)
print(f"   åˆ¤å®šä¸ºNTU-60: {is_ntu60}")

labels_body = batch_labels.cpu().numpy()
if is_ntu60:
    labels_body = np.array([action2body_ntu60(int(i)) for i in labels_body])
else:
    labels_body = np.array([action2body(int(i)) for i in labels_body])

print(f"   ç²—åˆ†ç±»ç»“æœ: {labels_body.tolist()}")
print(f"   ç²—åˆ†ç±»èŒƒå›´: [{labels_body.min()}, {labels_body.max()}]")

# 5. æµ‹è¯•one_hot
print("\n5. æµ‹è¯•one_hotç¼–ç ...")
try:
    labels_tensor = torch.tensor(labels_body, dtype=torch.long).cuda()
    one_hot = torch.nn.functional.one_hot(labels_tensor, num_classes=8)
    print(f"   âœ“ one_hotæˆåŠŸ: {one_hot.shape}")
except Exception as e:
    print(f"   âœ— one_hotå¤±è´¥: {e}")
    exit(1)

print("\n" + "="*60)
print("âœ“ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒ")
print("="*60)
EOF

# è¿è¡Œæµ‹è¯•
python test_ntu60_setup.py
```

---

## ğŸš€ éªŒè¯é€šè¿‡åé‡æ–°è®­ç»ƒ

```bash
cd /home/zh/ChCode/codes01/mmaction2

# æ¸…ç†ä¹‹å‰çš„é”™è¯¯æ—¥å¿—
rm -rf work_dirs/pcan_ntu60_test

# é‡æ–°è®­ç»ƒï¼ˆä¿æŒCUDA_LAUNCH_BLOCKING=1ä¾¿äºè°ƒè¯•ï¼‰
CUDA_VISIBLE_DEVICES=1 CUDA_LAUNCH_BLOCKING=1 python tools/train.py \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    --work-dir work_dirs/pcan_ntu60_test

# å¦‚æœçœ‹åˆ°æ­£å¸¸çš„è®­ç»ƒæ—¥å¿—ï¼ˆlossä¸‹é™ï¼‰ï¼Œå°±æˆåŠŸäº†ï¼
```

---

## ğŸ“Š é¢„æœŸçš„æ­£å¸¸è¾“å‡º

ä¿®å¤åï¼Œä½ åº”è¯¥çœ‹åˆ°ï¼š

```
11/21 01:XX:XX - mmengine - INFO - Epoch(train) [1][10/XXXX]
    lr: 7.5000e-03
    eta: X:XX:XX
    time: X.XXXX
    data_time: X.XXXX
    memory: XXXX
    rgb_loss_cls: X.XXXX
    pose_loss_cls: X.XXXX
    rgb_coarse_loss_cls: X.XXXX  â† ç²—åˆ†ç±»æŸå¤±
    pose_coarse_loss_cls: X.XXXX
    rgb_fr_loss: X.XXXX  â† åŸå‹å­¦ä¹ æŸå¤±
    pose_fr_loss: X.XXXX
    hierarchy_rgb_loss: X.XXXX  â† å±‚æ¬¡çº¦æŸæŸå¤±
    hierarchy_pose_loss: X.XXXX
```

---

## âš ï¸ é‡è¦æé†’

1. **ä¸è¦ä¿®æ”¹`loss_by_scores`æ–¹æ³•**ï¼ˆç¬¬716-748è¡Œï¼‰
2. **åªä¿®æ”¹`loss_by_feat`æ–¹æ³•**ï¼ˆç¬¬663-714è¡Œï¼‰
3. **åœ¨å¾ªç¯å‰åˆ¤æ–­æ•°æ®é›†ç±»å‹**ï¼ˆæ·»åŠ `is_ntu60`å˜é‡ï¼‰
4. **åœ¨å¾ªç¯å†…ä½¿ç”¨`is_ntu60`**ï¼ˆä¸è¦åœ¨å¾ªç¯å¤–è®¿é—®`labels_body`ï¼‰

---

## ğŸ”§ å¦‚æœè¿˜æŠ¥é”™

æŠŠä»¥ä¸‹ä¿¡æ¯å‘ç»™æˆ‘ï¼š

```bash
# 1. æ ‡ç­¾èŒƒå›´
python -c "import pickle; d=pickle.load(open('data/skeleton/ntu60_xsub.pkl','rb')); l=[a['label'] for a in d['annotations']]; print(f'[{min(l)}, {max(l)}]')"

# 2. å‡½æ•°æµ‹è¯•ç»“æœ
python test_ntu60_setup.py 2>&1 | tail -20

# 3. è®­ç»ƒé”™è¯¯çš„å®Œæ•´å †æ ˆ
CUDA_VISIBLE_DEVICES=1 CUDA_LAUNCH_BLOCKING=1 python tools/train.py configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py --work-dir work_dirs/test 2>&1 | tail -50
```

å…ˆè¿è¡Œ`test_ntu60_setup.py`æ£€æŸ¥ï¼Œå¦‚æœå…¨éƒ¨é€šè¿‡ï¼Œå°±å¯ä»¥æ­£å¸¸è®­ç»ƒäº†ï¼ğŸš€

```python
def action2body(x):
    """MA-52æ˜ å°„"""
    if x <= 4:
        return 0
    elif 5 <= x <= 10:
        return 1
    elif 11 <= x <= 23:
        return 2
    elif 24 <= x <= 31:
        return 3
    elif 32 <= x <= 37:
        return 4
    elif 38 <= x <= 47:
        return 5
    else:
        return 6

def action2body_ntu60(x):
    """NTU-60æ˜ å°„ï¼š0-59 â†’ 0-7"""
    x = int(x)
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)
```

```python
def loss_by_feat(self, cls_scores: Dict[str, torch.Tensor],
                 data_samples: SampleList) -> Dict:
    """Calculate the loss based on the features extracted by the head."""
    labels = torch.stack([x.gt_labels.item for x in data_samples])
    labels = labels.squeeze()

    if labels.shape == torch.Size([]):
        labels = labels.unsqueeze(0)
    elif labels.dim() == 1 and labels.size()[0] == self.num_classes \
            and cls_scores.size()[0] == 1:
        labels = labels.unsqueeze(0)

    losses = dict()
    
    # ========== åœ¨å¾ªç¯å‰åˆ¤æ–­æ•°æ®é›†ç±»å‹ ==========
    max_label = int(labels.max().item())
    is_ntu60 = (max_label >= 52)  # æ ‡ç­¾èŒƒå›´åˆ¤æ–­
    
    for loss_name, weight in zip(self.loss_components, self.loss_weights):
        cls_score1 = cls_scores[loss_name]
        loss_cls = self.loss_by_scores(cls_score1, labels)
        loss_cls = {loss_name + '_' + k: v for k, v in loss_cls.items()}
        loss_cls[f'{loss_name}_loss_cls'] *= weight
        losses.update(loss_cls)

        # ========== ä¿®æ”¹ï¼šä½¿ç”¨æ­£ç¡®çš„æ˜ å°„å‡½æ•° ==========
        labels_body = labels.cpu().numpy()
        if is_ntu60:  # NTU-60
            labels_body = np.array([action2body_ntu60(int(i)) for i in labels_body])
        else:  # MA-52
            labels_body = np.array([action2body(int(i)) for i in labels_body])
        labels_body = torch.tensor(labels_body, dtype=torch.long).cuda()

        cls_score2 = cls_scores[loss_name+'_coarse']
        loss_name = loss_name+'_coarse'
        loss_cls = self.loss_by_scores(cls_score2, labels_body)
        loss_cls = {loss_name + '_' + k: v for k, v in loss_cls.items()}
        loss_cls[f'{loss_name}_loss_cls'] *= weight
        losses.update(loss_cls)

    if self.training:
        losses['rgb_fr_coarse_loss'] = cls_scores['fr_loss_rgb_coarse'] / 5
        losses['pose_fr_coarse_loss'] = cls_scores['fr_loss_pose_coarse'] / 5
        losses['rgb_fr_loss'] = cls_scores['fr_loss_rgb']/5
        losses['pose_fr_loss'] = cls_scores['fr_loss_pose']/5
        losses['hierarchy_rgb_loss'] = cls_scores['hierarchy_loss_rgb']
        losses['hierarchy_pose_loss'] = cls_scores['hierarchy_loss_pose']
    return losses
```

```python
def fine2coarse(x):
    """MA-52æ˜ å°„"""
    if x<=4:
        return 0
    elif 5<=x<=10:
        return 1
    elif 11<=x<=23:
        return 2
    elif 24<=x<=31:
        return 3
    elif 32<=x<=37:
        return 4
    elif 38<=x<=47:
        return 5
    else:
        return 6

def fine2coarse_ntu60(x):
    """NTU-60æ˜ å°„ï¼š0-59 â†’ 0-7"""
    x = int(x)
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)
```

```python
# åŸä»£ç ï¼š
gts=[]
for data in data_samples:
    gts.extend(data.gt_labels.item)
gts=torch.stack(gts)
temp=gts.cpu().numpy()
gts_coarse=[fine2coarse(i) for i in temp]
gts_coarse=torch.from_numpy(np.array(gts_coarse)).cuda()

# ä¿®æ”¹ä¸ºï¼š
gts=[]
for data in data_samples:
    gts.extend(data.gt_labels.item)
gts=torch.stack(gts)
temp=gts.cpu().numpy()

# åˆ¤æ–­æ•°æ®é›†ç±»å‹
max_label = int(temp.max())
if max_label >= 52:  # NTU-60
    gts_coarse = [fine2coarse_ntu60(int(i)) for i in temp]
else:  # MA-52
    gts_coarse = [fine2coarse(int(i)) for i in temp]

gts_coarse=torch.from_numpy(np.array(gts_coarse)).cuda()
```

```python
# âŒ é”™è¯¯çš„ä¿®æ”¹ï¼ˆä½ ç°åœ¨çš„æƒ…å†µï¼‰
def loss_by_feat(...):
    # ... 
    for loss_name in ...:
        labels_body = ...  # åœ¨å¾ªç¯å†…å®šä¹‰
    
    # åœ¨å¾ªç¯å¤–ä½¿ç”¨ labels_body â† é”™è¯¯ï¼
    max_label = labels_body.max()  # UnboundLocalError

# âœ“ æ­£ç¡®çš„ä¿®æ”¹
def loss_by_feat(...):
    labels = ...
    max_label = labels.max()  # â† åœ¨å¾ªç¯å‰åˆ¤æ–­
    is_ntu60 = (max_label >= 52)
    
    for loss_name in ...:
        labels_body = ...
        if is_ntu60:  # â† åœ¨å¾ªç¯å†…ä½¿ç”¨åˆ¤æ–­ç»“æœ
            labels_body = action2body_ntu60(...)
        else:
            labels_body = action2body(...)
```

```python
def action2body(x):
    """MA-52: action (0-51) â†’ body (0-6)"""
    if x <= 4:
        return 0
    elif 5 <= x <= 10:
        return 1
    elif 11 <= x <= 23:
        return 2
    elif 24 <= x <= 31:
        return 3
    elif 32 <= x <= 37:
        return 4
    elif 38 <= x <= 47:
        return 5
    else:
        return 6

def action2body_ntu60(x):
    """NTU-60: action (0-59) â†’ body (0-7), æ¯8ä¸ªåŠ¨ä½œä¸€ç»„"""
    x = int(x)
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)
```

```python
def loss_by_feat(self, cls_scores: Dict[str, torch.Tensor],
                 data_samples: SampleList) -> Dict:
    """Calculate the loss based on the features extracted by the head.

    Args:
        cls_scores (dict[str, torch.Tensor]): The dict of
            classification scores,
        data_samples (list[:obj:`ActionDataSample`]): The batch
            data samples.

    Returns:
        dict: A dictionary of loss components.
    """
    labels = torch.stack([x.gt_labels.item for x in data_samples])
    labels = labels.squeeze()

    if labels.shape == torch.Size([]):
        labels = labels.unsqueeze(0)
    elif labels.dim() == 1 and labels.size()[0] == self.num_classes \
            and cls_scores.size()[0] == 1:
        # Fix a bug when training with soft labels and batch size is 1.
        # When using soft labels, `labels` and `cls_score` share the same
        # shape.
        labels = labels.unsqueeze(0)

    # ========== åˆ¤æ–­æ•°æ®é›†ï¼ˆåœ¨å¾ªç¯å‰ï¼‰==========
    max_label = int(labels.max().item())
    is_ntu60 = (max_label >= 52)  # NTU-60: 0-59, MA-52: 0-51
    
    losses = dict()
    for loss_name, weight in zip(self.loss_components, self.loss_weights):
        cls_score1 = cls_scores[loss_name]
        loss_cls = self.loss_by_scores(cls_score1, labels)
        loss_cls = {loss_name + '_' + k: v for k, v in loss_cls.items()}
        loss_cls[f'{loss_name}_loss_cls'] *= weight
        losses.update(loss_cls)

        # ========== è®¡ç®—ç²—åˆ†ç±»æ ‡ç­¾ ==========
        labels_body = labels.cpu().numpy()
        if is_ntu60:
            labels_body = np.array([action2body_ntu60(int(i)) for i in labels_body])
        else:
            labels_body = np.array([action2body(int(i)) for i in labels_body])
        labels_body = torch.tensor(labels_body, dtype=torch.long).cuda()

        cls_score2 = cls_scores[loss_name+'_coarse']
        loss_name = loss_name+'_coarse'
        loss_cls = self.loss_by_scores(cls_score2, labels_body)
        loss_cls = {loss_name + '_' + k: v for k, v in loss_cls.items()}
        loss_cls[f'{loss_name}_loss_cls'] *= weight
        losses.update(loss_cls)

    if self.training:
        losses['rgb_fr_coarse_loss'] = cls_scores['fr_loss_rgb_coarse'] / 5
        losses['pose_fr_coarse_loss'] = cls_scores['fr_loss_pose_coarse'] / 5
        losses['rgb_fr_loss'] = cls_scores['fr_loss_rgb']/5
        losses['pose_fr_loss'] = cls_scores['fr_loss_pose']/5
        losses['hierarchy_rgb_loss'] = cls_scores['hierarchy_loss_rgb']
        losses['hierarchy_pose_loss'] = cls_scores['hierarchy_loss_pose']
    return losses
```

```python
def fine2coarse(x):
    """MA-52: 0-51 â†’ 0-6"""
    if x<=4:
        return 0
    elif 5<=x<=10:
        return 1
    elif 11<=x<=23:
        return 2
    elif 24<=x<=31:
        return 3
    elif 32<=x<=37:
        return 4
    elif 38<=x<=47:
        return 5
    else:
        return 6

def fine2coarse_ntu60(x):
    """NTU-60: 0-59 â†’ 0-7"""
    x = int(x)
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)
```

```python
#get gt_label
gts=[]
for data in data_samples:
    gts.extend(data.gt_labels.item)
gts=torch.stack(gts)
temp=gts.cpu().numpy()

# åˆ¤æ–­æ•°æ®é›†
max_label = int(temp.max())
if max_label >= 52:  # NTU-60
    gts_coarse = [fine2coarse_ntu60(int(i)) for i in temp]
else:  # MA-52
    gts_coarse = [fine2coarse(int(i)) for i in temp]

gts_coarse=torch.from_numpy(np.array(gts_coarse)).cuda()
```

```shellscript
cd /home/zh/ChCode/codes01/mmaction2

# æ£€æŸ¥rgbpose_head.pyçš„ä¿®æ”¹
python << 'EOF'
import sys
sys.path.insert(0, '/home/zh/ChCode/codes01/mmaction2')

# å°è¯•å¯¼å…¥å‡½æ•°
try:
    from mmaction.models.heads.rgbpose_head import action2body, action2body_ntu60
    print("âœ“ action2bodyå‡½æ•°å¯¼å…¥æˆåŠŸ")
    print("âœ“ action2body_ntu60å‡½æ•°å¯¼å…¥æˆåŠŸ")
    
    # æµ‹è¯•æ˜ å°„
    print("\nMA-52æµ‹è¯•:")
    for x in [0, 5, 11, 24, 32, 38, 50]:
        print(f"  {x} â†’ {action2body(x)}")
    
    print("\nNTU-60æµ‹è¯•:")
    for x in [0, 8, 16, 24, 32, 40, 48, 56, 59]:
        print(f"  {x} â†’ {action2body_ntu60(x)}")
        
except ImportError as e:
    print(f"âœ— å¯¼å…¥å¤±è´¥: {e}")
except Exception as e:
    print(f"âœ— å‡½æ•°å®šä¹‰æœ‰é—®é¢˜: {e}")
EOF

# æ£€æŸ¥recognizer3d_mm.pyçš„ä¿®æ”¹
python << 'EOF'
import sys
sys.path.insert(0, '/home/zh/ChCode/codes01/mmaction2')

try:
    from mmaction.models.recognizers.recognizer3d_mm import fine2coarse, fine2coarse_ntu60
    print("\nâœ“ fine2coarseå‡½æ•°å¯¼å…¥æˆåŠŸ")
    print("âœ“ fine2coarse_ntu60å‡½æ•°å¯¼å…¥æˆåŠŸ")
    
    # æµ‹è¯•
    print("\nNTU-60æµ‹è¯•:")
    for x in [0, 10, 20, 30, 40, 50, 59]:
        print(f"  {x} â†’ {fine2coarse_ntu60(x)}")
        
except ImportError as e:
    print(f"âœ— å¯¼å…¥å¤±è´¥: {e}")
except Exception as e:
    print(f"âœ— å‡½æ•°å®šä¹‰æœ‰é—®é¢˜: {e}")
EOF
```

```shellscript
cd /home/zh/ChCode/codes01/mmaction2

# åˆ›å»ºå®Œæ•´çš„æµ‹è¯•è„šæœ¬
cat > test_ntu60_setup.py << 'EOF'
import torch
import pickle
import numpy as np
import sys
sys.path.insert(0, '/home/zh/ChCode/codes01/mmaction2')

print("="*60)
print("NTU-60å®Œæ•´æ£€æŸ¥")
print("="*60)

# 1. æ£€æŸ¥pklæ•°æ®
print("\n1. æ£€æŸ¥pklæ•°æ®...")
with open('data/skeleton/ntu60_xsub.pkl', 'rb') as f:
    data = pickle.load(f)

labels = [ann['label'] for ann in data['annotations']]
print(f"   æ ‡ç­¾èŒƒå›´: [{min(labels)}, {max(labels)}]")
print(f"   æ ·æœ¬æ•°: {len(labels)}")

if min(labels) != 0 or max(labels) != 59:
    print(f"   âœ— é”™è¯¯ï¼šæ ‡ç­¾åº”è¯¥æ˜¯0-59ï¼")
    exit(1)
else:
    print(f"   âœ“ æ ‡ç­¾èŒƒå›´æ­£ç¡®")

# 2. æ£€æŸ¥å‡½æ•°å¯¼å…¥
print("\n2. æ£€æŸ¥å‡½æ•°å¯¼å…¥...")
try:
    from mmaction.models.heads.rgbpose_head import action2body_ntu60
    from mmaction.models.recognizers.recognizer3d_mm import fine2coarse_ntu60
    print("   âœ“ æ‰€æœ‰å‡½æ•°å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"   âœ— å¯¼å…¥å¤±è´¥: {e}")
    exit(1)

# 3. æµ‹è¯•æ˜ å°„å‡½æ•°
print("\n3. æµ‹è¯•æ˜ å°„å‡½æ•°...")
test_labels = np.array([0, 10, 20, 30, 40, 50, 59])
mapped = [action2body_ntu60(int(x)) for x in test_labels]
print(f"   Action: {test_labels.tolist()}")
print(f"   Body:   {mapped}")

if max(mapped) <= 7 and min(mapped) >= 0:
    print("   âœ“ æ˜ å°„ç»“æœåœ¨0-7èŒƒå›´å†…")
else:
    print(f"   âœ— æ˜ å°„è¶Šç•Œï¼")
    exit(1)

# 4. æ¨¡æ‹Ÿä¸€ä¸ªbatchçš„å¤„ç†
print("\n4. æ¨¡æ‹Ÿbatchå¤„ç†...")
batch_labels = torch.tensor([0, 15, 30, 45, 59], dtype=torch.long)
print(f"   æ¨¡æ‹Ÿæ ‡ç­¾: {batch_labels.tolist()}")

max_label = int(batch_labels.max().item())
print(f"   æœ€å¤§æ ‡ç­¾: {max_label}")

is_ntu60 = (max_label >= 52)
print(f"   åˆ¤å®šä¸ºNTU-60: {is_ntu60}")

labels_body = batch_labels.cpu().numpy()
if is_ntu60:
    labels_body = np.array([action2body_ntu60(int(i)) for i in labels_body])
else:
    labels_body = np.array([action2body(int(i)) for i in labels_body])

print(f"   ç²—åˆ†ç±»ç»“æœ: {labels_body.tolist()}")
print(f"   ç²—åˆ†ç±»èŒƒå›´: [{labels_body.min()}, {labels_body.max()}]")

# 5. æµ‹è¯•one_hot
print("\n5. æµ‹è¯•one_hotç¼–ç ...")
try:
    labels_tensor = torch.tensor(labels_body, dtype=torch.long).cuda()
    one_hot = torch.nn.functional.one_hot(labels_tensor, num_classes=8)
    print(f"   âœ“ one_hotæˆåŠŸ: {one_hot.shape}")
except Exception as e:
    print(f"   âœ— one_hotå¤±è´¥: {e}")
    exit(1)

print("\n" + "="*60)
print("âœ“ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒ")
print("="*60)
EOF

# è¿è¡Œæµ‹è¯•
python test_ntu60_setup.py
```

```shellscript
cd /home/zh/ChCode/codes01/mmaction2

# æ¸…ç†ä¹‹å‰çš„é”™è¯¯æ—¥å¿—
rm -rf work_dirs/pcan_ntu60_test

# é‡æ–°è®­ç»ƒï¼ˆä¿æŒCUDA_LAUNCH_BLOCKING=1ä¾¿äºè°ƒè¯•ï¼‰
CUDA_VISIBLE_DEVICES=1 CUDA_LAUNCH_BLOCKING=1 python tools/train.py \
    configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py \
    --work-dir work_dirs/pcan_ntu60_test

# å¦‚æœçœ‹åˆ°æ­£å¸¸çš„è®­ç»ƒæ—¥å¿—ï¼ˆlossä¸‹é™ï¼‰ï¼Œå°±æˆåŠŸäº†ï¼
```

```plaintext
11/21 01:XX:XX - mmengine - INFO - Epoch(train) [1][10/XXXX]
    lr: 7.5000e-03
    eta: X:XX:XX
    time: X.XXXX
    data_time: X.XXXX
    memory: XXXX
    rgb_loss_cls: X.XXXX
    pose_loss_cls: X.XXXX
    rgb_coarse_loss_cls: X.XXXX  â† ç²—åˆ†ç±»æŸå¤±
    pose_coarse_loss_cls: X.XXXX
    rgb_fr_loss: X.XXXX  â† åŸå‹å­¦ä¹ æŸå¤±
    pose_fr_loss: X.XXXX
    hierarchy_rgb_loss: X.XXXX  â† å±‚æ¬¡çº¦æŸæŸå¤±
    hierarchy_pose_loss: X.XXXX
```

```shellscript
# 1. æ ‡ç­¾èŒƒå›´
python -c "import pickle; d=pickle.load(open('data/skeleton/ntu60_xsub.pkl','rb')); l=[a['label'] for a in d['annotations']]; print(f'[{min(l)}, {max(l)}]')"

# 2. å‡½æ•°æµ‹è¯•ç»“æœ
python test_ntu60_setup.py 2>&1 | tail -20

# 3. è®­ç»ƒé”™è¯¯çš„å®Œæ•´å †æ ˆ
CUDA_VISIBLE_DEVICES=1 CUDA_LAUNCH_BLOCKING=1 python tools/train.py configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py --work-dir work_dirs/test 2>&1 | tail -50
```

---

**User**

è¿˜æ˜¯æŠ¥é”™ï¼Œä½ æ‰€è¯´çš„é‚£å‡ ä¸ªæ–‡ä»¶éƒ½æŒ‰ç…§ä½ çš„è¦æ±‚æ”¹äº†ï¼Œåªä¸è¿‡æœåŠ¡å™¨ä¸Šçš„æ”¹è¿‡çš„æ–‡ä»¶ï¼Œä½ çœ‹ä¸åˆ°è€Œå·²ï¼Œç°åœ¨è¿è¡Œè¿˜æ˜¯æŠ¥é”™ ä¿¡æ¯å¦‚ä¸‹ï¼š(openmmlab) [zh@node01 mmaction2]$ python -c "import pickle; d=pickle.load(open('data/skeleton/ntu60_xsub.pkl','rb')); l=[a['label'] for a in d['annotations']]; print(f'[{min(l)}, {max(l)}]')"

[0, 59]   (openmmlab) [zh@node01 mmaction2]$ python test_ntu60_setup.py 2>&1 | tail -20

   âœ“ æ‰€æœ‰å‡½æ•°å¯¼å…¥æˆåŠŸ

3. æµ‹è¯•æ˜ å°„å‡½æ•°...

   Action: [0, 10, 20, 30, 40, 50, 59]

   Body:   [0, 1, 2, 3, 5, 6, 7]

   âœ“ æ˜ å°„ç»“æœåœ¨0-7èŒƒå›´å†…

4. æ¨¡æ‹Ÿbatchå¤„ç†...

   æ¨¡æ‹Ÿæ ‡ç­¾: [0, 15, 30, 45, 59]

   æœ€å¤§æ ‡ç­¾: 59

   åˆ¤å®šä¸ºNTU-60: True

   ç²—åˆ†ç±»ç»“æœ: [0, 1, 3, 5, 7]

   ç²—åˆ†ç±»èŒƒå›´: [0, 7]

5. æµ‹è¯•one_hotç¼–ç ...

   âœ“ one_hotæˆåŠŸ: torch.Size([5, 8])

============================================================

âœ“ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒ

============================================================

(openmmlab) [zh@node01 mmaction2]$ CUDA_VISIBLE_DEVICES=1 CUDA_LAUNCH_BLOCKING=1 python tools/train.py configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py --work-dir work_dirs/test 2>&1 | tail -50

11/21 01:54:12 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.

11/21 01:54:12 - mmengine - INFO - Checkpoints will be saved to /home/zh/ChCode/codes01/mmaction2/work_dirs/test.

/opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.

/opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.

/opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.

/opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.

/opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.

/opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.

/opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.

/opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.

Traceback (most recent call last):

  File "tools/train.py", line 143, in <module>

    main()

  File "tools/train.py", line 139, in main

    runner.train()

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/runner.py", line 1777, in train

    model = self.train_loop.run()  # type: ignore

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/loops.py", line 98, in run

    self.run_epoch()

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/loops.py", line 115, in run_epoch

    self.run_iter(idx, data_batch)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/loops.py", line 131, in run_iter

    outputs = self.runner.model.train_step(

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py", line 114, in train_step

    losses = self._run_forward(data, mode='loss')  # type: ignore

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py", line 361, in _run_forward

    results = self(**data, mode=mode)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl

    return forward_call(*args, **kwargs)

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/models/recognizers/base.py", line 262, in forward

    s=self.loss(inputs, data_samples, **kwargs)

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/models/recognizers/base.py", line 176, in loss

    loss_cls = self.cls_head.loss(feats, data_samples, **loss_kwargs)

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/models/heads/rgbpose_head.py", line 700, in loss

    return self.loss_by_feat(cls_scores, data_samples)

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/models/heads/rgbpose_head.py", line 735, in loss_by_feat

    loss_cls = self.loss_by_scores(cls_score1, labels)

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/models/heads/rgbpose_head.py", line 790, in loss_by_scores

    loss_cls = self.loss_cls(cls_scores, labels)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl

    return forward_call(*args, **kwargs)

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/models/losses/base.py", line 39, in forward

    ret = self._forward(*args, **kwargs)

  File "/home/zh/ChCode/codes01/mmaction2/mmaction/models/losses/cross_entropy_loss.py", line 86, in _forward

    loss_cls = F.cross_entropy(cls_score, label, **kwargs)

  File "/home/zh/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy

    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)

RuntimeError: CUDA error: device-side assert triggered

Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.   

---

**Cursor**

```plaintext
Assertion `t >= 0 && t < n_classes` failed.
```

**é”™è¯¯ä¿¡æ¯å¾ˆæ˜ç¡®äº†ï¼** `Assertion t >= 0 && t < n_classes failed` è¯´æ˜æ ‡ç­¾è¶…å‡ºäº†åˆ†ç±»å™¨çš„ç±»åˆ«æ•°ã€‚

é—®é¢˜ä¸åœ¨æ ‡ç­¾ï¼ˆæ ‡ç­¾æ˜¯0-59æ­£ç¡®çš„ï¼‰ï¼Œè€Œåœ¨**åˆ†ç±»å™¨çš„è¾“å‡ºç»´åº¦ä¸åŒ¹é…**ï¼

## ğŸ” è¯Šæ–­ï¼šåˆ†ç±»å™¨ç»´åº¦

å¾ˆå¯èƒ½æ˜¯ï¼š
- æ ‡ç­¾ï¼š0-59 âœ“
- åˆ†ç±»å™¨è¾“å‡ºï¼šåªæœ‰52ç»´ï¼ˆä»MA-52ç»§æ‰¿ï¼‰ âœ—

è¿è¡Œè¿™ä¸ªè¯Šæ–­ï¼š

```bash
cd /home/zh/ChCode/codes01/mmaction2

python << 'EOF'
import torch
from mmengine.config import Config
from mmaction.registry import MODELS

print("æ£€æŸ¥æ¨¡å‹ç»´åº¦...")

# åŠ è½½é…ç½®
cfg = Config.fromfile('configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py')

print(f"é…ç½®ä¸­çš„num_classes: {cfg.model.cls_head.num_classes}")
print(f"é…ç½®ä¸­çš„num_coarse_classes: {cfg.model.cls_head.get('num_coarse_classes', 'æœªè®¾ç½®')}")

# æ„å»ºæ¨¡å‹
import sys
sys.path.insert(0, '.')
import mmaction

try:
    model = MODELS.build(cfg.model)
    
    # æ£€æŸ¥åˆ†ç±»å™¨ç»´åº¦
    print(f"\nå®é™…æ¨¡å‹ç»´åº¦:")
    print(f"  fc_rgbè¾“å‡º: {model.cls_head.fc_rgb.out_features}")
    print(f"  fc_poseè¾“å‡º: {model.cls_head.fc_pose.out_features}")
    print(f"  fc_rgb_coarseè¾“å‡º: {model.cls_head.fc_rgb_coarse.out_features}")
    print(f"  fc_pose_coarseè¾“å‡º: {model.cls_head.fc_pose_coarse.out_features}")
    
    # æ£€æŸ¥åŸå‹ç»´åº¦
    print(f"\nåŸå‹ç»´åº¦:")
    print(f"  fr_rgb.avg_f: {model.cls_head.fr_rgb.spatio_cl_net.avg_f.shape}")
    print(f"  fr_pose.avg_f: {model.cls_head.fr_pose.spatio_cl_net.avg_f.shape}")
    
    if model.cls_head.fc_rgb.out_features != 60:
        print(f"\nâœ— é”™è¯¯ï¼šfc_rgbåº”è¯¥æ˜¯60ç»´ï¼Œä½†å®é™…æ˜¯{model.cls_head.fc_rgb.out_features}ç»´ï¼")
        print("  é…ç½®æ–‡ä»¶çš„num_classesæ²¡æœ‰ç”Ÿæ•ˆ")
    else:
        print(f"\nâœ“ åˆ†ç±»å™¨ç»´åº¦æ­£ç¡®")
        
except Exception as e:
    print(f"âœ— æ„å»ºæ¨¡å‹å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
EOF
```

## ğŸ’¡ é—®é¢˜æ ¹æº

æˆ‘çŒœæµ‹é—®é¢˜æ˜¯**é…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘`num_coarse_classes`å‚æ•°**ï¼

### æ£€æŸ¥ä½ çš„é…ç½®æ–‡ä»¶

ç¡®è®¤ `pcan_ntu60.py` ä¸­çš„head_cfgæ˜¯è¿™æ ·çš„ï¼š

```python
head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,  # â† å¿…é¡»æœ‰
    num_coarse_classes=8,  # â† å¿…é¡»æ·»åŠ è¿™ä¸ªï¼
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose', 'rgb_coarse', 'pose_coarse'],
    loss_weights=[1., 1., 0.5, 0.5],
    average_clips='prob')
```

**å¦‚æœç¼ºå°‘`num_coarse_classes=8`**ï¼Œæ¨¡å‹ä¼šä½¿ç”¨é»˜è®¤å€¼7ï¼Œå¯¼è‡´ç»´åº¦ä¸åŒ¹é…ï¼

---

## ğŸ”§ ä¿®å¤æ–¹æ¡ˆï¼šç¡®ä¿RGBPoseHeadæ¥å—num_coarse_classes

### æ£€æŸ¥`mmaction/models/heads/rgbpose_head.py`çš„__init__

åœ¨ç¬¬520è¡Œå·¦å³ï¼Œ`__init__`æ–¹æ³•åº”è¯¥æ˜¯è¿™æ ·ï¼š

```python
def __init__(self,
             num_classes: int,
             in_channels: Tuple[int],
             loss_cls: Dict = dict(type='CrossEntropyLoss'),
             loss_components: List[str] = ['rgb', 'pose'],
             loss_weights: Union[float, Tuple[float]] = 1.,
             dropout: float = 0.5,
             init_std: float = 0.01,
             num_coarse_classes: int = 7,  # â† å¿…é¡»æ·»åŠ è¿™ä¸ªå‚æ•°ï¼
             **kwargs) -> None:
    
    super().__init__(num_classes, in_channels, loss_cls, **kwargs)
    
    # ... ä¸­é—´ä»£ç  ...
    
    # ä½¿ç”¨num_coarse_classesè€Œä¸æ˜¯ç¡¬ç¼–ç çš„7
    self.fc_rgb_coarse = nn.Linear(self.in_channels[0], num_coarse_classes)
    self.fc_pose_coarse = nn.Linear(self.in_channels[1], num_coarse_classes)
    
    self.fr_coarse_rgb = ST_RenovateNet(
        2048, 8, n_class=num_coarse_classes, h_channel=128, ...)
    self.fr_coarse_pose = ST_RenovateNet(
        512, 32, n_class=num_coarse_classes, h_channel=128, ...)
    
    self.fr_rgb = ST_RenovateNet_Fine(
        2048, n_class=num_classes, ..., 
        n_class_coarse=num_coarse_classes)  # â† ä¼ é€’ç»™RenovateNet_Fine
    self.fr_pose = ST_RenovateNet_Fine(
        512, n_class=num_classes, ...,
        n_class_coarse=num_coarse_classes)
    
    self.tree_loss_rgb = TreeLoss(num_actions=num_classes, num_bodies=num_coarse_classes)
    self.tree_loss_pose = TreeLoss(num_actions=num_classes, num_bodies=num_coarse_classes)
```

---

## ğŸ“ å®Œæ•´çš„ä»£ç ä¿®æ”¹æ¸…å•ï¼ˆç¬¬3ç‰ˆ - æœ€ç»ˆç‰ˆï¼‰

ç”±äºæˆ‘çœ‹ä¸åˆ°ä½ æœåŠ¡å™¨ä¸Šçš„ä¿®æ”¹ï¼Œè®©æˆ‘ç»™å‡º**å®Œæ•´çš„**éœ€è¦ä¿®æ”¹çš„éƒ¨åˆ†ï¼š

### æ–‡ä»¶1ï¼š`mmaction/models/heads/rgbpose_head.py`

#### ä½ç½®1ï¼šç¬¬17-32è¡Œï¼ˆæ·»åŠ NTU-60æ˜ å°„ï¼‰

```python
def action2body(x):
    """MA-52: 0-51 â†’ 0-6"""
    if x <= 4:
        return 0
    elif 5 <= x <= 10:
        return 1
    elif 11 <= x <= 23:
        return 2
    elif 24 <= x <= 31:
        return 3
    elif 32 <= x <= 37:
        return 4
    elif 38 <= x <= 47:
        return 5
    else:
        return 6

def action2body_ntu60(x):
    """NTU-60: 0-59 â†’ 0-7"""
    x = int(x)
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)
```

#### ä½ç½®2ï¼šç¬¬35-64è¡Œï¼ˆä¿®æ”¹TreeLossï¼‰

```python
class TreeLoss(nn.Module):
    def __init__(self, num_actions=52, num_bodies=7):
        super(TreeLoss, self).__init__()
        self.num_actions = num_actions
        self.num_bodies = num_bodies
        self.stateSpace = self.generateStateSpace().cuda()
        self.sig = nn.Sigmoid()

    def forward(self, pred_body, pred_action, labels_body, labels_action):
        pred_body = self.sig(pred_body)
        pred_action = self.sig(pred_action)
        pred_fusion = torch.cat((pred_body, pred_action), dim=1)
        labels_action = labels_action + self.num_bodies  # â† æ”¹ï¼šä½¿ç”¨åŠ¨æ€å€¼
        index = torch.mm(self.stateSpace.to(torch.float32), pred_fusion.T)
        joint = torch.exp(index)
        z = torch.sum(joint, dim=0)
        loss = torch.zeros(pred_fusion.shape[0], dtype=torch.float64).cuda()
        for i in range(len(labels_action)):
            marginal = torch.sum(torch.index_select(
                joint[:, i], 0, torch.where(self.stateSpace[:, labels_action[i]] > 0)[0]))
            loss[i] = -torch.log(marginal / z[i])
        return torch.mean(loss)

    def generateStateSpace(self):
        total_size = self.num_bodies + self.num_actions
        stat_list = np.eye(total_size)
        
        for i in range(self.num_bodies, total_size):
            temp = stat_list[i]
            index = np.where(temp > 0)[0]
            action_id = int(index) - self.num_bodies
            
            # æ ¹æ®åŠ¨ä½œæ•°åˆ¤æ–­æ•°æ®é›†
            if self.num_actions == 60:
                coarse = action2body_ntu60(action_id)
            else:
                coarse = action2body(action_id)
            
            stat_list[i][coarse] = 1
        
        stateSpace = torch.tensor(stat_list)
        return stateSpace
```

#### ä½ç½®3ï¼šç¬¬68-89è¡Œï¼ˆä¿®æ”¹RenovateNet_Fineï¼‰

```python
class RenovateNet_Fine(nn.Module):
    def __init__(self, n_channel, n_class, alp=0.125, tmp=0.125, mom=0.9, 
                 h_channel=None, version='V0', pred_threshold=0.0, use_p_map=True,
                 n_class_coarse=7):  # â† æ·»åŠ è¿™ä¸ªå‚æ•°
        super(RenovateNet_Fine, self).__init__()
        self.n_channel = n_channel
        self.h_channel = n_channel if h_channel is None else h_channel
        self.n_class = n_class
        self.n_class_coarse = n_class_coarse  # â† ä½¿ç”¨å‚æ•°å€¼

        self.alp = alp
        self.tmp = tmp
        self.mom = mom

        self.avg_f = nn.Parameter(torch.randn(
            h_channel, n_class), requires_grad=False)
        self.cl_fc = nn.Linear(self.n_channel, self.h_channel)

        self.loss = nn.CrossEntropyLoss(reduction='none')
        self.version = version
        self.pred_threshold = pred_threshold
        self.use_p_map = use_p_map
```

#### ä½ç½®4ï¼šç¬¬510-575è¡Œï¼ˆä¿®æ”¹RGBPoseHead.__init__ï¼‰

```python
def __init__(self,
             num_classes: int,
             in_channels: Tuple[int],
             loss_cls: Dict = dict(type='CrossEntropyLoss'),
             loss_components: List[str] = ['rgb', 'pose'],
             loss_weights: Union[float, Tuple[float]] = 1.,
             dropout: float = 0.5,
             init_std: float = 0.01,
             num_coarse_classes: int = 7,  # â† æ·»åŠ è¿™ä¸ªå‚æ•°ï¼
             **kwargs) -> None:
    
    super().__init__(num_classes, in_channels, loss_cls, **kwargs)
    
    # å¤„ç†dropout
    if isinstance(dropout, float):
        self.dropout = {'rgb': dropout, 'pose': dropout}
    else:
        self.dropout = dropout

    # å¤„ç†loss_weights
    if not isinstance(loss_weights, (tuple, list)):
        loss_weights = (loss_weights, ) * len(loss_components)
    assert len(loss_weights) == len(loss_components)
    self.loss_components = loss_components
    self.loss_weights = loss_weights

    self.dropout_rgb = nn.Dropout(p=self.dropout['rgb'])
    self.dropout_pose = nn.Dropout(p=self.dropout['pose'])
    self.init_std = init_std

    # ========== å…³é”®ï¼šä½¿ç”¨num_coarse_classes ==========
    self.fc_rgb = nn.Linear(self.in_channels[0], num_classes)
    self.fc_pose = nn.Linear(self.in_channels[1], num_classes)
    self.fc_rgb_coarse = nn.Linear(self.in_channels[0], num_coarse_classes)
    self.fc_pose_coarse = nn.Linear(self.in_channels[1], num_coarse_classes)
    
    self.avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))
    self.avg_pool2d = nn.AdaptiveAvgPool2d((1, 1))

    self.fr_coarse_rgb = ST_RenovateNet(
        2048, 8, n_class=num_coarse_classes, h_channel=128, version='V0', use_p_map=True)
    self.fr_coarse_pose = ST_RenovateNet(
        512, 32, n_class=num_coarse_classes, h_channel=128, version='V0', use_p_map=True)

    self.fr_rgb = ST_RenovateNet_Fine(
        2048, n_class=num_classes, version='V0', use_p_map=True,
        n_class_coarse=num_coarse_classes)
    self.fr_pose = ST_RenovateNet_Fine(
        512, n_class=num_classes, version='V0', use_p_map=True,
        n_class_coarse=num_coarse_classes)

    self.tree_loss_rgb = TreeLoss(num_actions=num_classes, num_bodies=num_coarse_classes)
    self.tree_loss_pose = TreeLoss(num_actions=num_classes, num_bodies=num_coarse_classes)
```

#### ä½ç½®5ï¼šç¬¬663-714è¡Œï¼ˆå®Œæ•´çš„loss_by_featï¼‰

```python
def loss_by_feat(self, cls_scores: Dict[str, torch.Tensor],
                 data_samples: SampleList) -> Dict:
    """Calculate the loss based on the features extracted by the head."""
    labels = torch.stack([x.gt_labels.item for x in data_samples])
    labels = labels.squeeze()

    if labels.shape == torch.Size([]):
        labels = labels.unsqueeze(0)
    elif labels.dim() == 1 and labels.size()[0] == self.num_classes \
            and cls_scores.size()[0] == 1:
        labels = labels.unsqueeze(0)

    # åˆ¤æ–­æ•°æ®é›†ç±»å‹ï¼ˆåœ¨å¾ªç¯å‰ï¼‰
    max_label = int(labels.max().item())
    is_ntu60 = (max_label >= 52)

    losses = dict()
    for loss_name, weight in zip(self.loss_components, self.loss_weights):
        cls_score1 = cls_scores[loss_name]
        loss_cls = self.loss_by_scores(cls_score1, labels)
        loss_cls = {loss_name + '_' + k: v for k, v in loss_cls.items()}
        loss_cls[f'{loss_name}_loss_cls'] *= weight
        losses.update(loss_cls)

        # è®¡ç®—ç²—åˆ†ç±»æ ‡ç­¾
        labels_body = labels.cpu().numpy()
        if is_ntu60:
            labels_body = np.array([action2body_ntu60(int(i)) for i in labels_body])
        else:
            labels_body = np.array([action2body(int(i)) for i in labels_body])
        labels_body = torch.tensor(labels_body, dtype=torch.long).cuda()

        cls_score2 = cls_scores[loss_name+'_coarse']
        loss_name_coarse = loss_name+'_coarse'
        loss_cls = self.loss_by_scores(cls_score2, labels_body)
        loss_cls = {loss_name_coarse + '_' + k: v for k, v in loss_cls.items()}
        loss_cls[f'{loss_name_coarse}_loss_cls'] *= weight
        losses.update(loss_cls)

    if self.training:
        losses['rgb_fr_coarse_loss'] = cls_scores['fr_loss_rgb_coarse'] / 5
        losses['pose_fr_coarse_loss'] = cls_scores['fr_loss_pose_coarse'] / 5
        losses['rgb_fr_loss'] = cls_scores['fr_loss_rgb']/5
        losses['pose_fr_loss'] = cls_scores['fr_loss_pose']/5
        losses['hierarchy_rgb_loss'] = cls_scores['hierarchy_loss_rgb']
        losses['hierarchy_pose_loss'] = cls_scores['hierarchy_loss_pose']
    return losses
```

---

## ğŸ“ é…ç½®æ–‡ä»¶æœ€ç»ˆç‰ˆæœ¬

å®Œæ•´çš„ `configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py`ï¼š

```python
_base_ = '../../../_base_/default_runtime.py'

# ==========================================
# æ¨¡å‹é…ç½®
# ==========================================
backbone_cfg = dict(
    type='RGBPoseConv3D',
    speed_ratio=4,
    channel_ratio=4,
    rgb_pathway=dict(
        num_stages=4,
        lateral=True,
        lateral_infl=1,
        lateral_activate=[0, 0, 1, 1],
        fusion_kernel=7,
        base_channels=64,
        conv1_kernel=(1, 7, 7),
        inflate=(0, 0, 1, 1),
        with_pool2=False),
    pose_pathway=dict(
        num_stages=3,
        stage_blocks=(4, 6, 3),
        lateral=True,
        lateral_inv=True,
        lateral_infl=16,
        lateral_activate=(0, 1, 1),
        fusion_kernel=7,
        in_channels=17,  # NTU-60 2Déª¨æ¶
        base_channels=32,
        out_indices=(2, ),
        conv1_kernel=(1, 7, 7),
        conv1_stride_s=1,
        conv1_stride_t=1,
        pool1_stride_s=1,
        pool1_stride_t=1,
        inflate=(0, 1, 1),
        spatial_strides=(2, 2, 2),
        temporal_strides=(1, 1, 1),
        dilations=(1, 1, 1),
        with_pool2=False))

head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,  # â† NTU-60çš„60ç±»
    num_coarse_classes=8,  # â† NTU-60çš„8ä¸ªç²—ç±»
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose', 'rgb_coarse', 'pose_coarse'],
    loss_weights=[1., 1., 0.5, 0.5],
    average_clips='prob')

data_preprocessor = dict(
    type='MultiModalDataPreprocessor',
    preprocessors=dict(
        imgs=dict(
            type='ActionDataPreprocessor',
            mean=[123.675, 116.28, 103.53],
            std=[58.395, 57.12, 57.375],
            format_shape='NCTHW'),
        heatmap_imgs=dict(type='ActionDataPreprocessor')))

model = dict(
    type='MMRecognizer3D',
    backbone=backbone_cfg,
    cls_head=head_cfg,
    data_preprocessor=data_preprocessor)

# ==========================================
# æ•°æ®é…ç½®
# ==========================================
dataset_type = 'PoseDataset'
data_root = '/home/zh/ChCode/codes01/mmaction2/data/nturgbd_videos/'
ann_file = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub.pkl'
ann_file_val = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub.pkl'
ann_file_test = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub.pkl'

left_kp = [1, 3, 5, 7, 9, 11, 13, 15]
right_kp = [2, 4, 6, 8, 10, 12, 14, 16]

train_pipeline = [
    dict(type='MMUniformSampleFrames', clip_len=dict(RGB=8, Pose=32), num_clips=1),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(type='RandomResizedCrop', area_range=(0.56, 1.0)),
    dict(type='Resize', scale=(224, 224), keep_ratio=False),
    dict(type='Flip', flip_ratio=0.5, left_kp=left_kp, right_kp=right_kp),
    dict(type='GeneratePoseTarget', sigma=0.7, use_score=True, 
         with_kp=True, with_limb=False, scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

val_pipeline = [
    dict(type='MMUniformSampleFrames', clip_len=dict(RGB=8, Pose=32), 
         num_clips=1, test_mode=True),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(type='GeneratePoseTarget', sigma=0.7, use_score=True,
         with_kp=True, with_limb=False, scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

test_pipeline = [
    dict(type='MMUniformSampleFrames', clip_len=dict(RGB=8, Pose=32),
         num_clips=10, test_mode=True),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(type='GeneratePoseTarget', sigma=0.7, use_score=True,
         with_kp=True, with_limb=False, scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

train_dataloader = dict(
    batch_size=10,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=True),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file,
        data_prefix=dict(video=data_root),
        split='xsub_train',
        pipeline=train_pipeline))

val_dataloader = dict(
    batch_size=1,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_val,
        data_prefix=dict(video=data_root),
        split='xsub_val',
        pipeline=val_pipeline,
        test_mode=True))

test_dataloader = dict(
    batch_size=1,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_test,
        data_prefix=dict(video=data_root),
        split='xsub_val',
        pipeline=test_pipeline,
        test_mode=True))

val_evaluator = [dict(type='AccMetric')]
test_evaluator = val_evaluator

train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=30, val_begin=3, val_interval=1)
val_cfg = dict(type='ValLoop')
test_cfg = dict(type='TestLoop')

optim_wrapper = dict(
    optimizer=dict(type='SGD', lr=0.0075, momentum=0.9, weight_decay=0.0001),
    clip_grad=dict(max_norm=40, norm_type=2))

param_scheduler = [
    dict(type='MultiStepLR', begin=0, end=30, by_epoch=True,
         milestones=[10, 20], gamma=0.1)
]

load_from = None

auto_scale_lr = dict(enable=False, base_batch_size=40)
```

---

## ğŸ¯ æœ€ç»ˆéªŒè¯ï¼ˆè¿è¡Œè¿™ä¸ªï¼‰

```bash
cd /home/zh/ChCode/codes01/mmaction2

# å®Œæ•´éªŒè¯è„šæœ¬
python << 'EOF'
import torch
from mmengine.config import Config
from mmaction.registry import MODELS
import sys
sys.path.insert(0, '.')
import mmaction

print("="*60)
print("æœ€ç»ˆéªŒè¯")
print("="*60)

# 1. åŠ è½½é…ç½®
cfg = Config.fromfile('configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py')
print(f"\n1. é…ç½®æ–‡ä»¶:")
print(f"   num_classes: {cfg.model.cls_head.num_classes}")
print(f"   num_coarse_classes: {cfg.model.cls_head.get('num_coarse_classes', 'æœªè®¾ç½®!!!')}")

if cfg.model.cls_head.get('num_coarse_classes') != 8:
    print(f"   âœ— é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘num_coarse_classes=8")
    print(f"   è¯·åœ¨head_cfgä¸­æ·»åŠ ï¼š num_coarse_classes=8,")
    exit(1)

# 2. æ„å»ºæ¨¡å‹
print(f"\n2. æ„å»ºæ¨¡å‹...")
cfg.load_from = None  # ä¸åŠ è½½checkpoint
model = MODELS.build(cfg.model)

print(f"   âœ“ æ¨¡å‹æ„å»ºæˆåŠŸ")
print(f"\n3. æ£€æŸ¥åˆ†ç±»å™¨ç»´åº¦:")
print(f"   fc_rgb: {model.cls_head.fc_rgb.weight.shape[0]}ç±»")
print(f"   fc_pose: {model.cls_head.fc_pose.weight.shape[0]}ç±»")
print(f"   fc_rgb_coarse: {model.cls_head.fc_rgb_coarse.weight.shape[0]}ç±»")
print(f"   fc_pose_coarse: {model.cls_head.fc_pose_coarse.weight.shape[0]}ç±»")

if model.cls_head.fc_rgb.weight.shape[0] != 60:
    print(f"   âœ— é”™è¯¯ï¼šfc_rgbåº”è¯¥æ˜¯60ç»´ï¼")
    exit(1)
if model.cls_head.fc_rgb_coarse.weight.shape[0] != 8:
    print(f"   âœ— é”™è¯¯ï¼šfc_rgb_coarseåº”è¯¥æ˜¯8ç»´ï¼")
    exit(1)

print(f"\n4. æ£€æŸ¥åŸå‹ç»´åº¦:")
print(f"   fr_rgb.avg_f: {model.cls_head.fr_rgb.spatio_cl_net.avg_f.shape}")
print(f"   fr_coarse_rgb.avg_f: {model.cls_head.fr_coarse_rgb.spatio_cl_net.avg_f.shape}")

if model.cls_head.fr_rgb.spatio_cl_net.avg_f.shape[1] != 60:
    print(f"   âœ— é”™è¯¯ï¼šç»†åˆ†ç±»åŸå‹åº”è¯¥æ˜¯60ç±»ï¼")
    exit(1)
if model.cls_head.fr_coarse_rgb.spatio_cl_net.avg_f.shape[1] != 8:
    print(f"   âœ— é”™è¯¯ï¼šç²—åˆ†ç±»åŸå‹åº”è¯¥æ˜¯8ç±»ï¼")
    exit(1)

print(f"\n5. æ¨¡æ‹Ÿå‰å‘ä¼ æ’­...")
# æ¨¡æ‹Ÿæ•°æ®
batch_size = 2
x_rgb = torch.randn(batch_size, 2048, 8, 1, 1).cuda()
x_pose = torch.randn(batch_size, 512, 32, 1, 1).cuda()
x_rgb_mid = torch.randn(batch_size, 2048, 7, 7).cuda()
x_pose_mid = torch.randn(batch_size, 512, 7, 7).cuda()
gt = torch.tensor([10, 45], dtype=torch.long).cuda()
gt_coarse = torch.tensor([1, 5], dtype=torch.long).cuda()

x = [x_rgb, x_pose, x_rgb_mid, x_pose_mid, gt, gt_coarse]

model = model.cuda()
model.train()

try:
    with torch.no_grad():
        outputs = model.cls_head(x)
    print(f"   âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
    print(f"   è¾“å‡ºkeys: {list(outputs.keys())}")
except Exception as e:
    print(f"   âœ— å‰å‘ä¼ æ’­å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

print("\n" + "="*60)
print("âœ“ æ‰€æœ‰éªŒè¯é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒï¼")
print("="*60)
EOF
```

**å¦‚æœè¿™ä¸ªè„šæœ¬é€šè¿‡äº†ï¼Œå°±å¯ä»¥æ­£å¸¸è®­ç»ƒã€‚å¦‚æœå¤±è´¥ï¼ŒæŠŠå®Œæ•´è¾“å‡ºå‘ç»™æˆ‘ã€‚**

è¿è¡Œç»“æœæ˜¯ä»€ä¹ˆï¼Ÿç‰¹åˆ«å…³æ³¨ï¼š
1. `num_coarse_classes`æ˜¯å¦ä¸º8
2. `fc_rgb`ç»´åº¦æ˜¯å¦ä¸º60
3. `fc_rgb_coarse`ç»´åº¦æ˜¯å¦ä¸º8

æŠŠéªŒè¯è„šæœ¬çš„è¾“å‡ºå‘Šè¯‰æˆ‘ï¼ğŸ”

```shellscript
cd /home/zh/ChCode/codes01/mmaction2

python << 'EOF'
import torch
from mmengine.config import Config
from mmaction.registry import MODELS

print("æ£€æŸ¥æ¨¡å‹ç»´åº¦...")

# åŠ è½½é…ç½®
cfg = Config.fromfile('configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py')

print(f"é…ç½®ä¸­çš„num_classes: {cfg.model.cls_head.num_classes}")
print(f"é…ç½®ä¸­çš„num_coarse_classes: {cfg.model.cls_head.get('num_coarse_classes', 'æœªè®¾ç½®')}")

# æ„å»ºæ¨¡å‹
import sys
sys.path.insert(0, '.')
import mmaction

try:
    model = MODELS.build(cfg.model)
    
    # æ£€æŸ¥åˆ†ç±»å™¨ç»´åº¦
    print(f"\nå®é™…æ¨¡å‹ç»´åº¦:")
    print(f"  fc_rgbè¾“å‡º: {model.cls_head.fc_rgb.out_features}")
    print(f"  fc_poseè¾“å‡º: {model.cls_head.fc_pose.out_features}")
    print(f"  fc_rgb_coarseè¾“å‡º: {model.cls_head.fc_rgb_coarse.out_features}")
    print(f"  fc_pose_coarseè¾“å‡º: {model.cls_head.fc_pose_coarse.out_features}")
    
    # æ£€æŸ¥åŸå‹ç»´åº¦
    print(f"\nåŸå‹ç»´åº¦:")
    print(f"  fr_rgb.avg_f: {model.cls_head.fr_rgb.spatio_cl_net.avg_f.shape}")
    print(f"  fr_pose.avg_f: {model.cls_head.fr_pose.spatio_cl_net.avg_f.shape}")
    
    if model.cls_head.fc_rgb.out_features != 60:
        print(f"\nâœ— é”™è¯¯ï¼šfc_rgbåº”è¯¥æ˜¯60ç»´ï¼Œä½†å®é™…æ˜¯{model.cls_head.fc_rgb.out_features}ç»´ï¼")
        print("  é…ç½®æ–‡ä»¶çš„num_classesæ²¡æœ‰ç”Ÿæ•ˆ")
    else:
        print(f"\nâœ“ åˆ†ç±»å™¨ç»´åº¦æ­£ç¡®")
        
except Exception as e:
    print(f"âœ— æ„å»ºæ¨¡å‹å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
EOF
```

```python
head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,  # â† å¿…é¡»æœ‰
    num_coarse_classes=8,  # â† å¿…é¡»æ·»åŠ è¿™ä¸ªï¼
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose', 'rgb_coarse', 'pose_coarse'],
    loss_weights=[1., 1., 0.5, 0.5],
    average_clips='prob')
```

```python
def __init__(self,
             num_classes: int,
             in_channels: Tuple[int],
             loss_cls: Dict = dict(type='CrossEntropyLoss'),
             loss_components: List[str] = ['rgb', 'pose'],
             loss_weights: Union[float, Tuple[float]] = 1.,
             dropout: float = 0.5,
             init_std: float = 0.01,
             num_coarse_classes: int = 7,  # â† å¿…é¡»æ·»åŠ è¿™ä¸ªå‚æ•°ï¼
             **kwargs) -> None:
    
    super().__init__(num_classes, in_channels, loss_cls, **kwargs)
    
    # ... ä¸­é—´ä»£ç  ...
    
    # ä½¿ç”¨num_coarse_classesè€Œä¸æ˜¯ç¡¬ç¼–ç çš„7
    self.fc_rgb_coarse = nn.Linear(self.in_channels[0], num_coarse_classes)
    self.fc_pose_coarse = nn.Linear(self.in_channels[1], num_coarse_classes)
    
    self.fr_coarse_rgb = ST_RenovateNet(
        2048, 8, n_class=num_coarse_classes, h_channel=128, ...)
    self.fr_coarse_pose = ST_RenovateNet(
        512, 32, n_class=num_coarse_classes, h_channel=128, ...)
    
    self.fr_rgb = ST_RenovateNet_Fine(
        2048, n_class=num_classes, ..., 
        n_class_coarse=num_coarse_classes)  # â† ä¼ é€’ç»™RenovateNet_Fine
    self.fr_pose = ST_RenovateNet_Fine(
        512, n_class=num_classes, ...,
        n_class_coarse=num_coarse_classes)
    
    self.tree_loss_rgb = TreeLoss(num_actions=num_classes, num_bodies=num_coarse_classes)
    self.tree_loss_pose = TreeLoss(num_actions=num_classes, num_bodies=num_coarse_classes)
```

```python
def action2body(x):
    """MA-52: 0-51 â†’ 0-6"""
    if x <= 4:
        return 0
    elif 5 <= x <= 10:
        return 1
    elif 11 <= x <= 23:
        return 2
    elif 24 <= x <= 31:
        return 3
    elif 32 <= x <= 37:
        return 4
    elif 38 <= x <= 47:
        return 5
    else:
        return 6

def action2body_ntu60(x):
    """NTU-60: 0-59 â†’ 0-7"""
    x = int(x)
    if x < 0 or x > 59:
        return 0
    return min(x // 8, 7)
```

```python
class TreeLoss(nn.Module):
    def __init__(self, num_actions=52, num_bodies=7):
        super(TreeLoss, self).__init__()
        self.num_actions = num_actions
        self.num_bodies = num_bodies
        self.stateSpace = self.generateStateSpace().cuda()
        self.sig = nn.Sigmoid()

    def forward(self, pred_body, pred_action, labels_body, labels_action):
        pred_body = self.sig(pred_body)
        pred_action = self.sig(pred_action)
        pred_fusion = torch.cat((pred_body, pred_action), dim=1)
        labels_action = labels_action + self.num_bodies  # â† æ”¹ï¼šä½¿ç”¨åŠ¨æ€å€¼
        index = torch.mm(self.stateSpace.to(torch.float32), pred_fusion.T)
        joint = torch.exp(index)
        z = torch.sum(joint, dim=0)
        loss = torch.zeros(pred_fusion.shape[0], dtype=torch.float64).cuda()
        for i in range(len(labels_action)):
            marginal = torch.sum(torch.index_select(
                joint[:, i], 0, torch.where(self.stateSpace[:, labels_action[i]] > 0)[0]))
            loss[i] = -torch.log(marginal / z[i])
        return torch.mean(loss)

    def generateStateSpace(self):
        total_size = self.num_bodies + self.num_actions
        stat_list = np.eye(total_size)
        
        for i in range(self.num_bodies, total_size):
            temp = stat_list[i]
            index = np.where(temp > 0)[0]
            action_id = int(index) - self.num_bodies
            
            # æ ¹æ®åŠ¨ä½œæ•°åˆ¤æ–­æ•°æ®é›†
            if self.num_actions == 60:
                coarse = action2body_ntu60(action_id)
            else:
                coarse = action2body(action_id)
            
            stat_list[i][coarse] = 1
        
        stateSpace = torch.tensor(stat_list)
        return stateSpace
```

```python
class RenovateNet_Fine(nn.Module):
    def __init__(self, n_channel, n_class, alp=0.125, tmp=0.125, mom=0.9, 
                 h_channel=None, version='V0', pred_threshold=0.0, use_p_map=True,
                 n_class_coarse=7):  # â† æ·»åŠ è¿™ä¸ªå‚æ•°
        super(RenovateNet_Fine, self).__init__()
        self.n_channel = n_channel
        self.h_channel = n_channel if h_channel is None else h_channel
        self.n_class = n_class
        self.n_class_coarse = n_class_coarse  # â† ä½¿ç”¨å‚æ•°å€¼

        self.alp = alp
        self.tmp = tmp
        self.mom = mom

        self.avg_f = nn.Parameter(torch.randn(
            h_channel, n_class), requires_grad=False)
        self.cl_fc = nn.Linear(self.n_channel, self.h_channel)

        self.loss = nn.CrossEntropyLoss(reduction='none')
        self.version = version
        self.pred_threshold = pred_threshold
        self.use_p_map = use_p_map
```

```python
def __init__(self,
             num_classes: int,
             in_channels: Tuple[int],
             loss_cls: Dict = dict(type='CrossEntropyLoss'),
             loss_components: List[str] = ['rgb', 'pose'],
             loss_weights: Union[float, Tuple[float]] = 1.,
             dropout: float = 0.5,
             init_std: float = 0.01,
             num_coarse_classes: int = 7,  # â† æ·»åŠ è¿™ä¸ªå‚æ•°ï¼
             **kwargs) -> None:
    
    super().__init__(num_classes, in_channels, loss_cls, **kwargs)
    
    # å¤„ç†dropout
    if isinstance(dropout, float):
        self.dropout = {'rgb': dropout, 'pose': dropout}
    else:
        self.dropout = dropout

    # å¤„ç†loss_weights
    if not isinstance(loss_weights, (tuple, list)):
        loss_weights = (loss_weights, ) * len(loss_components)
    assert len(loss_weights) == len(loss_components)
    self.loss_components = loss_components
    self.loss_weights = loss_weights

    self.dropout_rgb = nn.Dropout(p=self.dropout['rgb'])
    self.dropout_pose = nn.Dropout(p=self.dropout['pose'])
    self.init_std = init_std

    # ========== å…³é”®ï¼šä½¿ç”¨num_coarse_classes ==========
    self.fc_rgb = nn.Linear(self.in_channels[0], num_classes)
    self.fc_pose = nn.Linear(self.in_channels[1], num_classes)
    self.fc_rgb_coarse = nn.Linear(self.in_channels[0], num_coarse_classes)
    self.fc_pose_coarse = nn.Linear(self.in_channels[1], num_coarse_classes)
    
    self.avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))
    self.avg_pool2d = nn.AdaptiveAvgPool2d((1, 1))

    self.fr_coarse_rgb = ST_RenovateNet(
        2048, 8, n_class=num_coarse_classes, h_channel=128, version='V0', use_p_map=True)
    self.fr_coarse_pose = ST_RenovateNet(
        512, 32, n_class=num_coarse_classes, h_channel=128, version='V0', use_p_map=True)

    self.fr_rgb = ST_RenovateNet_Fine(
        2048, n_class=num_classes, version='V0', use_p_map=True,
        n_class_coarse=num_coarse_classes)
    self.fr_pose = ST_RenovateNet_Fine(
        512, n_class=num_classes, version='V0', use_p_map=True,
        n_class_coarse=num_coarse_classes)

    self.tree_loss_rgb = TreeLoss(num_actions=num_classes, num_bodies=num_coarse_classes)
    self.tree_loss_pose = TreeLoss(num_actions=num_classes, num_bodies=num_coarse_classes)
```

```python
def loss_by_feat(self, cls_scores: Dict[str, torch.Tensor],
                 data_samples: SampleList) -> Dict:
    """Calculate the loss based on the features extracted by the head."""
    labels = torch.stack([x.gt_labels.item for x in data_samples])
    labels = labels.squeeze()

    if labels.shape == torch.Size([]):
        labels = labels.unsqueeze(0)
    elif labels.dim() == 1 and labels.size()[0] == self.num_classes \
            and cls_scores.size()[0] == 1:
        labels = labels.unsqueeze(0)

    # åˆ¤æ–­æ•°æ®é›†ç±»å‹ï¼ˆåœ¨å¾ªç¯å‰ï¼‰
    max_label = int(labels.max().item())
    is_ntu60 = (max_label >= 52)

    losses = dict()
    for loss_name, weight in zip(self.loss_components, self.loss_weights):
        cls_score1 = cls_scores[loss_name]
        loss_cls = self.loss_by_scores(cls_score1, labels)
        loss_cls = {loss_name + '_' + k: v for k, v in loss_cls.items()}
        loss_cls[f'{loss_name}_loss_cls'] *= weight
        losses.update(loss_cls)

        # è®¡ç®—ç²—åˆ†ç±»æ ‡ç­¾
        labels_body = labels.cpu().numpy()
        if is_ntu60:
            labels_body = np.array([action2body_ntu60(int(i)) for i in labels_body])
        else:
            labels_body = np.array([action2body(int(i)) for i in labels_body])
        labels_body = torch.tensor(labels_body, dtype=torch.long).cuda()

        cls_score2 = cls_scores[loss_name+'_coarse']
        loss_name_coarse = loss_name+'_coarse'
        loss_cls = self.loss_by_scores(cls_score2, labels_body)
        loss_cls = {loss_name_coarse + '_' + k: v for k, v in loss_cls.items()}
        loss_cls[f'{loss_name_coarse}_loss_cls'] *= weight
        losses.update(loss_cls)

    if self.training:
        losses['rgb_fr_coarse_loss'] = cls_scores['fr_loss_rgb_coarse'] / 5
        losses['pose_fr_coarse_loss'] = cls_scores['fr_loss_pose_coarse'] / 5
        losses['rgb_fr_loss'] = cls_scores['fr_loss_rgb']/5
        losses['pose_fr_loss'] = cls_scores['fr_loss_pose']/5
        losses['hierarchy_rgb_loss'] = cls_scores['hierarchy_loss_rgb']
        losses['hierarchy_pose_loss'] = cls_scores['hierarchy_loss_pose']
    return losses
```

```python
_base_ = '../../../_base_/default_runtime.py'

# ==========================================
# æ¨¡å‹é…ç½®
# ==========================================
backbone_cfg = dict(
    type='RGBPoseConv3D',
    speed_ratio=4,
    channel_ratio=4,
    rgb_pathway=dict(
        num_stages=4,
        lateral=True,
        lateral_infl=1,
        lateral_activate=[0, 0, 1, 1],
        fusion_kernel=7,
        base_channels=64,
        conv1_kernel=(1, 7, 7),
        inflate=(0, 0, 1, 1),
        with_pool2=False),
    pose_pathway=dict(
        num_stages=3,
        stage_blocks=(4, 6, 3),
        lateral=True,
        lateral_inv=True,
        lateral_infl=16,
        lateral_activate=(0, 1, 1),
        fusion_kernel=7,
        in_channels=17,  # NTU-60 2Déª¨æ¶
        base_channels=32,
        out_indices=(2, ),
        conv1_kernel=(1, 7, 7),
        conv1_stride_s=1,
        conv1_stride_t=1,
        pool1_stride_s=1,
        pool1_stride_t=1,
        inflate=(0, 1, 1),
        spatial_strides=(2, 2, 2),
        temporal_strides=(1, 1, 1),
        dilations=(1, 1, 1),
        with_pool2=False))

head_cfg = dict(
    type='RGBPoseHead',
    num_classes=60,  # â† NTU-60çš„60ç±»
    num_coarse_classes=8,  # â† NTU-60çš„8ä¸ªç²—ç±»
    in_channels=[2048, 512],
    loss_components=['rgb', 'pose', 'rgb_coarse', 'pose_coarse'],
    loss_weights=[1., 1., 0.5, 0.5],
    average_clips='prob')

data_preprocessor = dict(
    type='MultiModalDataPreprocessor',
    preprocessors=dict(
        imgs=dict(
            type='ActionDataPreprocessor',
            mean=[123.675, 116.28, 103.53],
            std=[58.395, 57.12, 57.375],
            format_shape='NCTHW'),
        heatmap_imgs=dict(type='ActionDataPreprocessor')))

model = dict(
    type='MMRecognizer3D',
    backbone=backbone_cfg,
    cls_head=head_cfg,
    data_preprocessor=data_preprocessor)

# ==========================================
# æ•°æ®é…ç½®
# ==========================================
dataset_type = 'PoseDataset'
data_root = '/home/zh/ChCode/codes01/mmaction2/data/nturgbd_videos/'
ann_file = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub.pkl'
ann_file_val = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub.pkl'
ann_file_test = '/home/zh/ChCode/codes01/mmaction2/data/skeleton/ntu60_xsub.pkl'

left_kp = [1, 3, 5, 7, 9, 11, 13, 15]
right_kp = [2, 4, 6, 8, 10, 12, 14, 16]

train_pipeline = [
    dict(type='MMUniformSampleFrames', clip_len=dict(RGB=8, Pose=32), num_clips=1),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(type='RandomResizedCrop', area_range=(0.56, 1.0)),
    dict(type='Resize', scale=(224, 224), keep_ratio=False),
    dict(type='Flip', flip_ratio=0.5, left_kp=left_kp, right_kp=right_kp),
    dict(type='GeneratePoseTarget', sigma=0.7, use_score=True, 
         with_kp=True, with_limb=False, scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

val_pipeline = [
    dict(type='MMUniformSampleFrames', clip_len=dict(RGB=8, Pose=32), 
         num_clips=1, test_mode=True),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(type='GeneratePoseTarget', sigma=0.7, use_score=True,
         with_kp=True, with_limb=False, scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

test_pipeline = [
    dict(type='MMUniformSampleFrames', clip_len=dict(RGB=8, Pose=32),
         num_clips=10, test_mode=True),
    dict(type='MMDecode'),
    dict(type='MMCompact', hw_ratio=1., allow_imgpad=True),
    dict(type='Resize', scale=(256, 256), keep_ratio=False),
    dict(type='GeneratePoseTarget', sigma=0.7, use_score=True,
         with_kp=True, with_limb=False, scaling=0.25),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs', collect_keys=('imgs', 'heatmap_imgs'))
]

train_dataloader = dict(
    batch_size=10,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=True),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file,
        data_prefix=dict(video=data_root),
        split='xsub_train',
        pipeline=train_pipeline))

val_dataloader = dict(
    batch_size=1,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_val,
        data_prefix=dict(video=data_root),
        split='xsub_val',
        pipeline=val_pipeline,
        test_mode=True))

test_dataloader = dict(
    batch_size=1,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_test,
        data_prefix=dict(video=data_root),
        split='xsub_val',
        pipeline=test_pipeline,
        test_mode=True))

val_evaluator = [dict(type='AccMetric')]
test_evaluator = val_evaluator

train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=30, val_begin=3, val_interval=1)
val_cfg = dict(type='ValLoop')
test_cfg = dict(type='TestLoop')

optim_wrapper = dict(
    optimizer=dict(type='SGD', lr=0.0075, momentum=0.9, weight_decay=0.0001),
    clip_grad=dict(max_norm=40, norm_type=2))

param_scheduler = [
    dict(type='MultiStepLR', begin=0, end=30, by_epoch=True,
         milestones=[10, 20], gamma=0.1)
]

load_from = None

auto_scale_lr = dict(enable=False, base_batch_size=40)
```

```shellscript
cd /home/zh/ChCode/codes01/mmaction2

# å®Œæ•´éªŒè¯è„šæœ¬
python << 'EOF'
import torch
from mmengine.config import Config
from mmaction.registry import MODELS
import sys
sys.path.insert(0, '.')
import mmaction

print("="*60)
print("æœ€ç»ˆéªŒè¯")
print("="*60)

# 1. åŠ è½½é…ç½®
cfg = Config.fromfile('configs/skeleton/posec3d/rgbpose_conv3d/pcan_ntu60.py')
print(f"\n1. é…ç½®æ–‡ä»¶:")
print(f"   num_classes: {cfg.model.cls_head.num_classes}")
print(f"   num_coarse_classes: {cfg.model.cls_head.get('num_coarse_classes', 'æœªè®¾ç½®!!!')}")

if cfg.model.cls_head.get('num_coarse_classes') != 8:
    print(f"   âœ— é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘num_coarse_classes=8")
    print(f"   è¯·åœ¨head_cfgä¸­æ·»åŠ ï¼š num_coarse_classes=8,")
    exit(1)

# 2. æ„å»ºæ¨¡å‹
print(f"\n2. æ„å»ºæ¨¡å‹...")
cfg.load_from = None  # ä¸åŠ è½½checkpoint
model = MODELS.build(cfg.model)

print(f"   âœ“ æ¨¡å‹æ„å»ºæˆåŠŸ")
print(f"\n3. æ£€æŸ¥åˆ†ç±»å™¨ç»´åº¦:")
print(f"   fc_rgb: {model.cls_head.fc_rgb.weight.shape[0]}ç±»")
print(f"   fc_pose: {model.cls_head.fc_pose.weight.shape[0]}ç±»")
print(f"   fc_rgb_coarse: {model.cls_head.fc_rgb_coarse.weight.shape[0]}ç±»")
print(f"   fc_pose_coarse: {model.cls_head.fc_pose_coarse.weight.shape[0]}ç±»")

if model.cls_head.fc_rgb.weight.shape[0] != 60:
    print(f"   âœ— é”™è¯¯ï¼šfc_rgbåº”è¯¥æ˜¯60ç»´ï¼")
    exit(1)
if model.cls_head.fc_rgb_coarse.weight.shape[0] != 8:
    print(f"   âœ— é”™è¯¯ï¼šfc_rgb_coarseåº”è¯¥æ˜¯8ç»´ï¼")
    exit(1)

print(f"\n4. æ£€æŸ¥åŸå‹ç»´åº¦:")
print(f"   fr_rgb.avg_f: {model.cls_head.fr_rgb.spatio_cl_net.avg_f.shape}")
print(f"   fr_coarse_rgb.avg_f: {model.cls_head.fr_coarse_rgb.spatio_cl_net.avg_f.shape}")

if model.cls_head.fr_rgb.spatio_cl_net.avg_f.shape[1] != 60:
    print(f"   âœ— é”™è¯¯ï¼šç»†åˆ†ç±»åŸå‹åº”è¯¥æ˜¯60ç±»ï¼")
    exit(1)
if model.cls_head.fr_coarse_rgb.spatio_cl_net.avg_f.shape[1] != 8:
    print(f"   âœ— é”™è¯¯ï¼šç²—åˆ†ç±»åŸå‹åº”è¯¥æ˜¯8ç±»ï¼")
    exit(1)

print(f"\n5. æ¨¡æ‹Ÿå‰å‘ä¼ æ’­...")
# æ¨¡æ‹Ÿæ•°æ®
batch_size = 2
x_rgb = torch.randn(batch_size, 2048, 8, 1, 1).cuda()
x_pose = torch.randn(batch_size, 512, 32, 1, 1).cuda()
x_rgb_mid = torch.randn(batch_size, 2048, 7, 7).cuda()
x_pose_mid = torch.randn(batch_size, 512, 7, 7).cuda()
gt = torch.tensor([10, 45], dtype=torch.long).cuda()
gt_coarse = torch.tensor([1, 5], dtype=torch.long).cuda()

x = [x_rgb, x_pose, x_rgb_mid, x_pose_mid, gt, gt_coarse]

model = model.cuda()
model.train()

try:
    with torch.no_grad():
        outputs = model.cls_head(x)
    print(f"   âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
    print(f"   è¾“å‡ºkeys: {list(outputs.keys())}")
except Exception as e:
    print(f"   âœ— å‰å‘ä¼ æ’­å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

print("\n" + "="*60)
print("âœ“ æ‰€æœ‰éªŒè¯é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒï¼")
print("="*60)
EOF
```

